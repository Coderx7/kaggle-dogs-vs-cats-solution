I1112 16:54:27.326295  3366 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': /media/myuser/120Gb/DIGITS/digits/jobs/20161112-165425-bd40/solver.prototxt
I1112 16:54:27.326596  3366 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W1112 16:54:27.326611  3366 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I1112 16:54:27.552579  3366 caffe.cpp:197] Using GPUs 0
I1112 16:54:27.552870  3366 caffe.cpp:202] GPU 0: GeForce GTX 1070
I1112 16:54:28.094269  3366 solver.cpp:48] Initializing solver from parameters:
test_iter: 79
test_interval: 313
base_lr: 0.005
display: 39
max_iter: 9390
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 5e-05
snapshot: 313
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
iter_size: 4
type: "SGD"
I1112 16:54:28.094440  3366 solver.cpp:91] Creating training net from net file: train_val.prototxt
I1112 16:54:28.095765  3366 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer val-data
I1112 16:54:28.095811  3366 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1112 16:54:28.096108  3366 net.cpp:52] Initializing net from parameters:
state {
phase: TRAIN
}
layer {
name: "train-data"
type: "Data"
top: "data"
top: "label"
include {
phase: TRAIN
}
transform_param {
mirror: true
crop_size: 227
mean_file: "/media/myuser/120Gb/DIGITS/digits/jobs/20160917-133511-8c62/mean.binaryproto"
}
data_param {
source: "/media/myuser/120Gb/DIGITS/digits/jobs/20160917-133511-8c62/train_db"
batch_size: 64
backend: LMDB
}
}
layer {
name: "conv1"
type: "Convolution"
bottom: "data"
top: "conv1"
convolution_param {
num_output: 64
kernel_size: 3
stride: 2
weight_filler {
type: "xavier"
}
}
}
layer {
name: "relu_conv1"
type: "ReLU"
bottom: "conv1"
top: "conv1"
}
layer {
name: "pool1"
type: "Pooling"
bottom: "conv1"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fire2/squeeze1x1"
type: "Convolution"
bottom: "pool1"
top: "fire2/squeeze1x1"
convolution_param {
num_output: 16
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire2/relu_squeeze1x1"
type: "ReLU"
bottom: "fire2/squeeze1x1"
top: "fire2/squeeze1x1"
}
layer {
name: "fire2/expand1x1"
type: "Convolution"
bottom: "fire2/squeeze1x1"
top: "fire2/expand1x1"
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire2/relu_expand1x1"
type: "ReLU"
bottom: "fire2/expand1x1"
top: "fire2/expand1x1"
}
layer {
name: "fire2/expand3x3"
type: "Convolution"
bottom: "fire2/squeeze1x1"
top: "fire2/expand3x3"
convolution_param {
num_output: 64
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire2/relu_expand3x3"
type: "ReLU"
bottom: "fire2/expand3x3"
top: "fire2/expand3x3"
}
layer {
name: "fire2/concat"
type: "Concat"
bottom: "fire2/expand1x1"
bottom: "fire2/expand3x3"
top: "fire2/concat"
}
layer {
name: "fire3/squeeze1x1"
type: "Convolution"
bottom: "fire2/concat"
top: "fire3/squeeze1x1"
convolution_param {
num_output: 16
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire3/relu_squeeze1x1"
type: "ReLU"
bottom: "fire3/squeeze1x1"
top: "fire3/squeeze1x1"
}
layer {
name: "fire3/expand1x1"
type: "Convolution"
bottom: "fire3/squeeze1x1"
top: "fire3/expand1x1"
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire3/relu_expand1x1"
type: "ReLU"
bottom: "fire3/expand1x1"
top: "fire3/expand1x1"
}
layer {
name: "fire3/expand3x3"
type: "Convolution"
bottom: "fire3/squeeze1x1"
top: "fire3/expand3x3"
convolution_param {
num_output: 64
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire3/relu_expand3x3"
type: "ReLU"
bottom: "fire3/expand3x3"
top: "fire3/expand3x3"
}
layer {
name: "fire3/concat"
type: "Concat"
bottom: "fire3/expand1x1"
bottom: "fire3/expand3x3"
top: "fire3/concat"
}
layer {
name: "pool3"
type: "Pooling"
bottom: "fire3/concat"
top: "pool3"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fire4/squeeze1x1"
type: "Convolution"
bottom: "pool3"
top: "fire4/squeeze1x1"
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire4/relu_squeeze1x1"
type: "ReLU"
bottom: "fire4/squeeze1x1"
top: "fire4/squeeze1x1"
}
layer {
name: "fire4/expand1x1"
type: "Convolution"
bottom: "fire4/squeeze1x1"
top: "fire4/expand1x1"
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire4/relu_expand1x1"
type: "ReLU"
bottom: "fire4/expand1x1"
top: "fire4/expand1x1"
}
layer {
name: "fire4/expand3x3"
type: "Convolution"
bottom: "fire4/squeeze1x1"
top: "fire4/expand3x3"
convolution_param {
num_output: 128
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire4/relu_expand3x3"
type: "ReLU"
bottom: "fire4/expand3x3"
top: "fire4/expand3x3"
}
layer {
name: "fire4/concat"
type: "Concat"
bottom: "fire4/expand1x1"
bottom: "fire4/expand3x3"
top: "fire4/concat"
}
layer {
name: "fire5/squeeze1x1"
type: "Convolution"
bottom: "fire4/concat"
top: "fire5/squeeze1x1"
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire5/relu_squeeze1x1"
type: "ReLU"
bottom: "fire5/squeeze1x1"
top: "fire5/squeeze1x1"
}
layer {
name: "fire5/expand1x1"
type: "Convolution"
bottom: "fire5/squeeze1x1"
top: "fire5/expand1x1"
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire5/relu_expand1x1"
type: "ReLU"
bottom: "fire5/expand1x1"
top: "fire5/expand1x1"
}
layer {
name: "fire5/expand3x3"
type: "Convolution"
bottom: "fire5/squeeze1x1"
top: "fire5/expand3x3"
convolution_param {
num_output: 128
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire5/relu_expand3x3"
type: "ReLU"
bottom: "fire5/expand3x3"
top: "fire5/expand3x3"
}
layer {
name: "fire5/concat"
type: "Concat"
bottom: "fire5/expand1x1"
bottom: "fire5/expand3x3"
top: "fire5/concat"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "fire5/concat"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fire6/squeeze1x1"
type: "Convolution"
bottom: "pool5"
top: "fire6/squeeze1x1"
convolution_param {
num_output: 48
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire6/relu_squeeze1x1"
type: "ReLU"
bottom: "fire6/squeeze1x1"
top: "fire6/squeeze1x1"
}
layer {
name: "fire6/expand1x1"
type: "Convolution"
bottom: "fire6/squeeze1x1"
top: "fire6/expand1x1"
convolution_param {
num_output: 192
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire6/relu_expand1x1"
type: "ReLU"
bottom: "fire6/expand1x1"
top: "fire6/expand1x1"
}
layer {
name: "fire6/expand3x3"
type: "Convolution"
bottom: "fire6/squeeze1x1"
top: "fire6/expand3x3"
convolution_param {
num_output: 192
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire6/relu_expand3x3"
type: "ReLU"
bottom: "fire6/expand3x3"
top: "fire6/expand3x3"
}
layer {
name: "fire6/concat"
type: "Concat"
bottom: "fire6/expand1x1"
bottom: "fire6/expand3x3"
top: "fire6/concat"
}
layer {
name: "fire7/squeeze1x1"
type: "Convolution"
bottom: "fire6/concat"
top: "fire7/squeeze1x1"
convolution_param {
num_output: 48
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire7/relu_squeeze1x1"
type: "ReLU"
bottom: "fire7/squeeze1x1"
top: "fire7/squeeze1x1"
}
layer {
name: "fire7/expand1x1"
type: "Convolution"
bottom: "fire7/squeeze1x1"
top: "fire7/expand1x1"
convolution_param {
num_output: 192
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire7/relu_expand1x1"
type: "ReLU"
bottom: "fire7/expand1x1"
top: "fire7/expand1x1"
}
layer {
name: "fire7/expand3x3"
type: "Convolution"
bottom: "fire7/squeeze1x1"
top: "fire7/expand3x3"
convolution_param {
num_output: 192
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire7/relu_expand3x3"
type: "ReLU"
bottom: "fire7/expand3x3"
top: "fire7/expand3x3"
}
layer {
name: "fire7/concat"
type: "Concat"
bottom: "fire7/expand1x1"
bottom: "fire7/expand3x3"
top: "fire7/concat"
}
layer {
name: "fire8/squeeze1x1"
type: "Convolution"
bottom: "fire7/concat"
top: "fire8/squeeze1x1"
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire8/relu_squeeze1x1"
type: "ReLU"
bottom: "fire8/squeeze1x1"
top: "fire8/squeeze1x1"
}
layer {
name: "fire8/expand1x1"
type: "Convolution"
bottom: "fire8/squeeze1x1"
top: "fire8/expand1x1"
convolution_param {
num_output: 256
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire8/relu_expand1x1"
type: "ReLU"
bottom: "fire8/expand1x1"
top: "fire8/expand1x1"
}
layer {
name: "fire8/expand3x3"
type: "Convolution"
bottom: "fire8/squeeze1x1"
top: "fire8/expand3x3"
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire8/relu_expand3x3"
type: "ReLU"
bottom: "fire8/expand3x3"
top: "fire8/expand3x3"
}
layer {
name: "fire8/concat"
type: "Concat"
bottom: "fire8/expand1x1"
bottom: "fire8/expand3x3"
top: "fire8/concat"
}
layer {
name: "fire9/squeeze1x1"
type: "Convolution"
bottom: "fire8/concat"
top: "fire9/squeeze1x1"
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire9/relu_squeeze1x1"
type: "ReLU"
bottom: "fire9/squeeze1x1"
top: "fire9/squeeze1x1"
}
layer {
name: "fire9/expand1x1"
type: "Convolution"
bottom: "fire9/squeeze1x1"
top: "fire9/expand1x1"
convolution_param {
num_output: 256
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire9/relu_expand1x1"
type: "ReLU"
bottom: "fire9/expand1x1"
top: "fire9/expand1x1"
}
layer {
name: "fire9/expand3x3"
type: "Convolution"
bottom: "fire9/squeeze1x1"
top: "fire9/expand3x3"
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire9/relu_expand3x3"
type: "ReLU"
bottom: "fire9/expand3x3"
top: "fire9/expand3x3"
}
layer {
name: "fire9/concat"
type: "Concat"
bottom: "fire9/expand1x1"
bottom: "fire9/expand3x3"
top: "fire9/concat"
}
layer {
name: "drop9"
type: "Dropout"
bottom: "fire9/concat"
top: "fire9/concat"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "conv10"
type: "Convolution"
bottom: "fire9/concat"
top: "conv10"
convolution_param {
num_output: 2
kernel_size: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.01
}
}
}
layer {
name: "relu_conv10"
type: "ReLU"
bottom: "conv10"
top: "conv10"
}
layer {
name: "pool10"
type: "Pooling"
bottom: "conv10"
top: "pool10"
pooling_param {
pool: AVE
global_pooling: true
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "pool10"
bottom: "label"
top: "loss"
}
I1112 16:54:28.096431  3366 layer_factory.hpp:77] Creating layer train-data
I1112 16:54:28.097326  3366 net.cpp:94] Creating Layer train-data
I1112 16:54:28.097347  3366 net.cpp:409] train-data -> data
I1112 16:54:28.097396  3366 net.cpp:409] train-data -> label
I1112 16:54:28.097419  3366 data_transformer.cpp:25] Loading mean file from: /media/myuser/120Gb/DIGITS/digits/jobs/20160917-133511-8c62/mean.binaryproto
I1112 16:54:28.098618  3373 db_lmdb.cpp:35] Opened lmdb /media/myuser/120Gb/DIGITS/digits/jobs/20160917-133511-8c62/train_db
I1112 16:54:28.106511  3366 data_layer.cpp:76] output data size: 64,3,227,227
I1112 16:54:28.236836  3366 net.cpp:144] Setting up train-data
I1112 16:54:28.236874  3366 net.cpp:151] Top shape: 64 3 227 227 (9893568)
I1112 16:54:28.236886  3366 net.cpp:151] Top shape: 64 (64)
I1112 16:54:28.236893  3366 net.cpp:159] Memory required for data: 39574528
I1112 16:54:28.236909  3366 layer_factory.hpp:77] Creating layer conv1
I1112 16:54:28.236937  3366 net.cpp:94] Creating Layer conv1
I1112 16:54:28.236948  3366 net.cpp:435] conv1 <- data
I1112 16:54:28.236966  3366 net.cpp:409] conv1 -> conv1
I1112 16:54:28.449759  3366 net.cpp:144] Setting up conv1
I1112 16:54:28.449786  3366 net.cpp:151] Top shape: 64 64 113 113 (52301824)
I1112 16:54:28.449795  3366 net.cpp:159] Memory required for data: 248781824
I1112 16:54:28.449817  3366 layer_factory.hpp:77] Creating layer relu_conv1
I1112 16:54:28.449833  3366 net.cpp:94] Creating Layer relu_conv1
I1112 16:54:28.449842  3366 net.cpp:435] relu_conv1 <- conv1
I1112 16:54:28.449852  3366 net.cpp:396] relu_conv1 -> conv1 (in-place)
I1112 16:54:28.449887  3366 net.cpp:144] Setting up relu_conv1
I1112 16:54:28.449897  3366 net.cpp:151] Top shape: 64 64 113 113 (52301824)
I1112 16:54:28.449903  3366 net.cpp:159] Memory required for data: 457989120
I1112 16:54:28.449926  3366 layer_factory.hpp:77] Creating layer pool1
I1112 16:54:28.449939  3366 net.cpp:94] Creating Layer pool1
I1112 16:54:28.449946  3366 net.cpp:435] pool1 <- conv1
I1112 16:54:28.449956  3366 net.cpp:409] pool1 -> pool1
I1112 16:54:28.450050  3366 net.cpp:144] Setting up pool1
I1112 16:54:28.450062  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:28.450068  3366 net.cpp:159] Memory required for data: 509369344
I1112 16:54:28.450076  3366 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1112 16:54:28.450091  3366 net.cpp:94] Creating Layer fire2/squeeze1x1
I1112 16:54:28.450099  3366 net.cpp:435] fire2/squeeze1x1 <- pool1
I1112 16:54:28.450109  3366 net.cpp:409] fire2/squeeze1x1 -> fire2/squeeze1x1
I1112 16:54:28.476946  3366 net.cpp:144] Setting up fire2/squeeze1x1
I1112 16:54:28.476980  3366 net.cpp:151] Top shape: 64 16 56 56 (3211264)
I1112 16:54:28.476989  3366 net.cpp:159] Memory required for data: 522214400
I1112 16:54:28.477010  3366 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1112 16:54:28.477025  3366 net.cpp:94] Creating Layer fire2/relu_squeeze1x1
I1112 16:54:28.477035  3366 net.cpp:435] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1112 16:54:28.477044  3366 net.cpp:396] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1112 16:54:28.477061  3366 net.cpp:144] Setting up fire2/relu_squeeze1x1
I1112 16:54:28.477071  3366 net.cpp:151] Top shape: 64 16 56 56 (3211264)
I1112 16:54:28.477077  3366 net.cpp:159] Memory required for data: 535059456
I1112 16:54:28.477085  3366 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1112 16:54:28.477102  3366 net.cpp:94] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1112 16:54:28.477110  3366 net.cpp:435] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1112 16:54:28.477120  3366 net.cpp:409] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1112 16:54:28.477133  3366 net.cpp:409] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1112 16:54:28.477211  3366 net.cpp:144] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1112 16:54:28.477221  3366 net.cpp:151] Top shape: 64 16 56 56 (3211264)
I1112 16:54:28.477231  3366 net.cpp:151] Top shape: 64 16 56 56 (3211264)
I1112 16:54:28.477237  3366 net.cpp:159] Memory required for data: 560749568
I1112 16:54:28.477278  3366 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1112 16:54:28.477296  3366 net.cpp:94] Creating Layer fire2/expand1x1
I1112 16:54:28.477304  3366 net.cpp:435] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1112 16:54:28.477314  3366 net.cpp:409] fire2/expand1x1 -> fire2/expand1x1
I1112 16:54:28.496393  3366 net.cpp:144] Setting up fire2/expand1x1
I1112 16:54:28.496428  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:28.496436  3366 net.cpp:159] Memory required for data: 612129792
I1112 16:54:28.496455  3366 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1112 16:54:28.496472  3366 net.cpp:94] Creating Layer fire2/relu_expand1x1
I1112 16:54:28.496481  3366 net.cpp:435] fire2/relu_expand1x1 <- fire2/expand1x1
I1112 16:54:28.496491  3366 net.cpp:396] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1112 16:54:28.496508  3366 net.cpp:144] Setting up fire2/relu_expand1x1
I1112 16:54:28.496517  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:28.496525  3366 net.cpp:159] Memory required for data: 663510016
I1112 16:54:28.496531  3366 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1112 16:54:28.496547  3366 net.cpp:94] Creating Layer fire2/expand3x3
I1112 16:54:28.496556  3366 net.cpp:435] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1112 16:54:28.496565  3366 net.cpp:409] fire2/expand3x3 -> fire2/expand3x3
I1112 16:54:28.526010  3366 net.cpp:144] Setting up fire2/expand3x3
I1112 16:54:28.526046  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:28.526054  3366 net.cpp:159] Memory required for data: 714890240
I1112 16:54:28.526070  3366 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1112 16:54:28.526084  3366 net.cpp:94] Creating Layer fire2/relu_expand3x3
I1112 16:54:28.526093  3366 net.cpp:435] fire2/relu_expand3x3 <- fire2/expand3x3
I1112 16:54:28.526104  3366 net.cpp:396] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1112 16:54:28.526120  3366 net.cpp:144] Setting up fire2/relu_expand3x3
I1112 16:54:28.526129  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:28.526136  3366 net.cpp:159] Memory required for data: 766270464
I1112 16:54:28.526144  3366 layer_factory.hpp:77] Creating layer fire2/concat
I1112 16:54:28.526154  3366 net.cpp:94] Creating Layer fire2/concat
I1112 16:54:28.526162  3366 net.cpp:435] fire2/concat <- fire2/expand1x1
I1112 16:54:28.526170  3366 net.cpp:435] fire2/concat <- fire2/expand3x3
I1112 16:54:28.526180  3366 net.cpp:409] fire2/concat -> fire2/concat
I1112 16:54:28.526248  3366 net.cpp:144] Setting up fire2/concat
I1112 16:54:28.526258  3366 net.cpp:151] Top shape: 64 128 56 56 (25690112)
I1112 16:54:28.526267  3366 net.cpp:159] Memory required for data: 869030912
I1112 16:54:28.526273  3366 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1112 16:54:28.526288  3366 net.cpp:94] Creating Layer fire3/squeeze1x1
I1112 16:54:28.526295  3366 net.cpp:435] fire3/squeeze1x1 <- fire2/concat
I1112 16:54:28.526306  3366 net.cpp:409] fire3/squeeze1x1 -> fire3/squeeze1x1
I1112 16:54:28.546085  3366 net.cpp:144] Setting up fire3/squeeze1x1
I1112 16:54:28.546123  3366 net.cpp:151] Top shape: 64 16 56 56 (3211264)
I1112 16:54:28.546130  3366 net.cpp:159] Memory required for data: 881875968
I1112 16:54:28.546152  3366 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1112 16:54:28.546166  3366 net.cpp:94] Creating Layer fire3/relu_squeeze1x1
I1112 16:54:28.546175  3366 net.cpp:435] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1112 16:54:28.546186  3366 net.cpp:396] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1112 16:54:28.546202  3366 net.cpp:144] Setting up fire3/relu_squeeze1x1
I1112 16:54:28.546211  3366 net.cpp:151] Top shape: 64 16 56 56 (3211264)
I1112 16:54:28.546218  3366 net.cpp:159] Memory required for data: 894721024
I1112 16:54:28.546226  3366 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1112 16:54:28.546236  3366 net.cpp:94] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1112 16:54:28.546273  3366 net.cpp:435] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1112 16:54:28.546283  3366 net.cpp:409] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1112 16:54:28.546295  3366 net.cpp:409] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1112 16:54:28.546380  3366 net.cpp:144] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1112 16:54:28.546389  3366 net.cpp:151] Top shape: 64 16 56 56 (3211264)
I1112 16:54:28.546398  3366 net.cpp:151] Top shape: 64 16 56 56 (3211264)
I1112 16:54:28.546406  3366 net.cpp:159] Memory required for data: 920411136
I1112 16:54:28.546412  3366 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1112 16:54:28.546428  3366 net.cpp:94] Creating Layer fire3/expand1x1
I1112 16:54:28.546437  3366 net.cpp:435] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1112 16:54:28.546447  3366 net.cpp:409] fire3/expand1x1 -> fire3/expand1x1
I1112 16:54:28.556872  3366 net.cpp:144] Setting up fire3/expand1x1
I1112 16:54:28.556915  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:28.556923  3366 net.cpp:159] Memory required for data: 971791360
I1112 16:54:28.556942  3366 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1112 16:54:28.556973  3366 net.cpp:94] Creating Layer fire3/relu_expand1x1
I1112 16:54:28.556984  3366 net.cpp:435] fire3/relu_expand1x1 <- fire3/expand1x1
I1112 16:54:28.556999  3366 net.cpp:396] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1112 16:54:28.557018  3366 net.cpp:144] Setting up fire3/relu_expand1x1
I1112 16:54:28.557027  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:28.557034  3366 net.cpp:159] Memory required for data: 1023171584
I1112 16:54:28.557041  3366 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1112 16:54:28.557059  3366 net.cpp:94] Creating Layer fire3/expand3x3
I1112 16:54:28.557066  3366 net.cpp:435] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1112 16:54:28.557076  3366 net.cpp:409] fire3/expand3x3 -> fire3/expand3x3
I1112 16:54:28.580938  3366 net.cpp:144] Setting up fire3/expand3x3
I1112 16:54:28.580974  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:28.580982  3366 net.cpp:159] Memory required for data: 1074551808
I1112 16:54:28.580998  3366 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1112 16:54:28.581012  3366 net.cpp:94] Creating Layer fire3/relu_expand3x3
I1112 16:54:28.581022  3366 net.cpp:435] fire3/relu_expand3x3 <- fire3/expand3x3
I1112 16:54:28.581032  3366 net.cpp:396] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1112 16:54:28.581049  3366 net.cpp:144] Setting up fire3/relu_expand3x3
I1112 16:54:28.581058  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:28.581065  3366 net.cpp:159] Memory required for data: 1125932032
I1112 16:54:28.581073  3366 layer_factory.hpp:77] Creating layer fire3/concat
I1112 16:54:28.581084  3366 net.cpp:94] Creating Layer fire3/concat
I1112 16:54:28.581092  3366 net.cpp:435] fire3/concat <- fire3/expand1x1
I1112 16:54:28.581100  3366 net.cpp:435] fire3/concat <- fire3/expand3x3
I1112 16:54:28.581110  3366 net.cpp:409] fire3/concat -> fire3/concat
I1112 16:54:28.581188  3366 net.cpp:144] Setting up fire3/concat
I1112 16:54:28.581198  3366 net.cpp:151] Top shape: 64 128 56 56 (25690112)
I1112 16:54:28.581207  3366 net.cpp:159] Memory required for data: 1228692480
I1112 16:54:28.581213  3366 layer_factory.hpp:77] Creating layer pool3
I1112 16:54:28.581228  3366 net.cpp:94] Creating Layer pool3
I1112 16:54:28.581234  3366 net.cpp:435] pool3 <- fire3/concat
I1112 16:54:28.581244  3366 net.cpp:409] pool3 -> pool3
I1112 16:54:28.581300  3366 net.cpp:144] Setting up pool3
I1112 16:54:28.581311  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:28.581320  3366 net.cpp:159] Memory required for data: 1254382592
I1112 16:54:28.581326  3366 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1112 16:54:28.581380  3366 net.cpp:94] Creating Layer fire4/squeeze1x1
I1112 16:54:28.581388  3366 net.cpp:435] fire4/squeeze1x1 <- pool3
I1112 16:54:28.581398  3366 net.cpp:409] fire4/squeeze1x1 -> fire4/squeeze1x1
I1112 16:54:28.588055  3366 net.cpp:144] Setting up fire4/squeeze1x1
I1112 16:54:28.588081  3366 net.cpp:151] Top shape: 64 32 28 28 (1605632)
I1112 16:54:28.588088  3366 net.cpp:159] Memory required for data: 1260805120
I1112 16:54:28.588102  3366 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1112 16:54:28.588115  3366 net.cpp:94] Creating Layer fire4/relu_squeeze1x1
I1112 16:54:28.588124  3366 net.cpp:435] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1112 16:54:28.588135  3366 net.cpp:396] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1112 16:54:28.588150  3366 net.cpp:144] Setting up fire4/relu_squeeze1x1
I1112 16:54:28.588158  3366 net.cpp:151] Top shape: 64 32 28 28 (1605632)
I1112 16:54:28.588165  3366 net.cpp:159] Memory required for data: 1267227648
I1112 16:54:28.588172  3366 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1112 16:54:28.588182  3366 net.cpp:94] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1112 16:54:28.588191  3366 net.cpp:435] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1112 16:54:28.588199  3366 net.cpp:409] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1112 16:54:28.588212  3366 net.cpp:409] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1112 16:54:28.588268  3366 net.cpp:144] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1112 16:54:28.588277  3366 net.cpp:151] Top shape: 64 32 28 28 (1605632)
I1112 16:54:28.588286  3366 net.cpp:151] Top shape: 64 32 28 28 (1605632)
I1112 16:54:28.588294  3366 net.cpp:159] Memory required for data: 1280072704
I1112 16:54:28.588301  3366 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1112 16:54:28.588315  3366 net.cpp:94] Creating Layer fire4/expand1x1
I1112 16:54:28.588323  3366 net.cpp:435] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1112 16:54:28.588335  3366 net.cpp:409] fire4/expand1x1 -> fire4/expand1x1
I1112 16:54:28.594715  3366 net.cpp:144] Setting up fire4/expand1x1
I1112 16:54:28.594744  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:28.594751  3366 net.cpp:159] Memory required for data: 1305762816
I1112 16:54:28.594774  3366 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1112 16:54:28.594786  3366 net.cpp:94] Creating Layer fire4/relu_expand1x1
I1112 16:54:28.594796  3366 net.cpp:435] fire4/relu_expand1x1 <- fire4/expand1x1
I1112 16:54:28.594806  3366 net.cpp:396] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1112 16:54:28.594821  3366 net.cpp:144] Setting up fire4/relu_expand1x1
I1112 16:54:28.594830  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:28.594837  3366 net.cpp:159] Memory required for data: 1331452928
I1112 16:54:28.594846  3366 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1112 16:54:28.594861  3366 net.cpp:94] Creating Layer fire4/expand3x3
I1112 16:54:28.594868  3366 net.cpp:435] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1112 16:54:28.594879  3366 net.cpp:409] fire4/expand3x3 -> fire4/expand3x3
I1112 16:54:28.628726  3366 net.cpp:144] Setting up fire4/expand3x3
I1112 16:54:28.628751  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:28.628759  3366 net.cpp:159] Memory required for data: 1357143040
I1112 16:54:28.628774  3366 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1112 16:54:28.628788  3366 net.cpp:94] Creating Layer fire4/relu_expand3x3
I1112 16:54:28.628798  3366 net.cpp:435] fire4/relu_expand3x3 <- fire4/expand3x3
I1112 16:54:28.628808  3366 net.cpp:396] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1112 16:54:28.628823  3366 net.cpp:144] Setting up fire4/relu_expand3x3
I1112 16:54:28.628832  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:28.628862  3366 net.cpp:159] Memory required for data: 1382833152
I1112 16:54:28.628870  3366 layer_factory.hpp:77] Creating layer fire4/concat
I1112 16:54:28.628881  3366 net.cpp:94] Creating Layer fire4/concat
I1112 16:54:28.628888  3366 net.cpp:435] fire4/concat <- fire4/expand1x1
I1112 16:54:28.628896  3366 net.cpp:435] fire4/concat <- fire4/expand3x3
I1112 16:54:28.628906  3366 net.cpp:409] fire4/concat -> fire4/concat
I1112 16:54:28.628963  3366 net.cpp:144] Setting up fire4/concat
I1112 16:54:28.628973  3366 net.cpp:151] Top shape: 64 256 28 28 (12845056)
I1112 16:54:28.628980  3366 net.cpp:159] Memory required for data: 1434213376
I1112 16:54:28.628988  3366 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1112 16:54:28.629003  3366 net.cpp:94] Creating Layer fire5/squeeze1x1
I1112 16:54:28.629010  3366 net.cpp:435] fire5/squeeze1x1 <- fire4/concat
I1112 16:54:28.629020  3366 net.cpp:409] fire5/squeeze1x1 -> fire5/squeeze1x1
I1112 16:54:28.639461  3366 net.cpp:144] Setting up fire5/squeeze1x1
I1112 16:54:28.639492  3366 net.cpp:151] Top shape: 64 32 28 28 (1605632)
I1112 16:54:28.639499  3366 net.cpp:159] Memory required for data: 1440635904
I1112 16:54:28.639515  3366 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1112 16:54:28.639528  3366 net.cpp:94] Creating Layer fire5/relu_squeeze1x1
I1112 16:54:28.639777  3366 net.cpp:435] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1112 16:54:28.639791  3366 net.cpp:396] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1112 16:54:28.639806  3366 net.cpp:144] Setting up fire5/relu_squeeze1x1
I1112 16:54:28.639816  3366 net.cpp:151] Top shape: 64 32 28 28 (1605632)
I1112 16:54:28.639823  3366 net.cpp:159] Memory required for data: 1447058432
I1112 16:54:28.639830  3366 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1112 16:54:28.639840  3366 net.cpp:94] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1112 16:54:28.639848  3366 net.cpp:435] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1112 16:54:28.639858  3366 net.cpp:409] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1112 16:54:28.639869  3366 net.cpp:409] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1112 16:54:28.639945  3366 net.cpp:144] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1112 16:54:28.639955  3366 net.cpp:151] Top shape: 64 32 28 28 (1605632)
I1112 16:54:28.639964  3366 net.cpp:151] Top shape: 64 32 28 28 (1605632)
I1112 16:54:28.639971  3366 net.cpp:159] Memory required for data: 1459903488
I1112 16:54:28.639978  3366 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1112 16:54:28.640002  3366 net.cpp:94] Creating Layer fire5/expand1x1
I1112 16:54:28.640010  3366 net.cpp:435] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1112 16:54:28.640020  3366 net.cpp:409] fire5/expand1x1 -> fire5/expand1x1
I1112 16:54:28.646097  3366 net.cpp:144] Setting up fire5/expand1x1
I1112 16:54:28.646124  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:28.646132  3366 net.cpp:159] Memory required for data: 1485593600
I1112 16:54:28.646147  3366 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1112 16:54:28.646162  3366 net.cpp:94] Creating Layer fire5/relu_expand1x1
I1112 16:54:28.646172  3366 net.cpp:435] fire5/relu_expand1x1 <- fire5/expand1x1
I1112 16:54:28.646181  3366 net.cpp:396] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1112 16:54:28.646198  3366 net.cpp:144] Setting up fire5/relu_expand1x1
I1112 16:54:28.646206  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:28.646214  3366 net.cpp:159] Memory required for data: 1511283712
I1112 16:54:28.646221  3366 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1112 16:54:28.646235  3366 net.cpp:94] Creating Layer fire5/expand3x3
I1112 16:54:28.646245  3366 net.cpp:435] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1112 16:54:28.646287  3366 net.cpp:409] fire5/expand3x3 -> fire5/expand3x3
I1112 16:54:28.662256  3366 net.cpp:144] Setting up fire5/expand3x3
I1112 16:54:28.662292  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:28.662299  3366 net.cpp:159] Memory required for data: 1536973824
I1112 16:54:28.662315  3366 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1112 16:54:28.662330  3366 net.cpp:94] Creating Layer fire5/relu_expand3x3
I1112 16:54:28.662339  3366 net.cpp:435] fire5/relu_expand3x3 <- fire5/expand3x3
I1112 16:54:28.662350  3366 net.cpp:396] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1112 16:54:28.662367  3366 net.cpp:144] Setting up fire5/relu_expand3x3
I1112 16:54:28.662375  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:28.662382  3366 net.cpp:159] Memory required for data: 1562663936
I1112 16:54:28.662389  3366 layer_factory.hpp:77] Creating layer fire5/concat
I1112 16:54:28.662400  3366 net.cpp:94] Creating Layer fire5/concat
I1112 16:54:28.662407  3366 net.cpp:435] fire5/concat <- fire5/expand1x1
I1112 16:54:28.662415  3366 net.cpp:435] fire5/concat <- fire5/expand3x3
I1112 16:54:28.662425  3366 net.cpp:409] fire5/concat -> fire5/concat
I1112 16:54:28.662499  3366 net.cpp:144] Setting up fire5/concat
I1112 16:54:28.662509  3366 net.cpp:151] Top shape: 64 256 28 28 (12845056)
I1112 16:54:28.662516  3366 net.cpp:159] Memory required for data: 1614044160
I1112 16:54:28.662523  3366 layer_factory.hpp:77] Creating layer pool5
I1112 16:54:28.662535  3366 net.cpp:94] Creating Layer pool5
I1112 16:54:28.662542  3366 net.cpp:435] pool5 <- fire5/concat
I1112 16:54:28.662551  3366 net.cpp:409] pool5 -> pool5
I1112 16:54:28.662601  3366 net.cpp:144] Setting up pool5
I1112 16:54:28.662611  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:28.662618  3366 net.cpp:159] Memory required for data: 1626889216
I1112 16:54:28.662626  3366 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1112 16:54:28.662639  3366 net.cpp:94] Creating Layer fire6/squeeze1x1
I1112 16:54:28.662647  3366 net.cpp:435] fire6/squeeze1x1 <- pool5
I1112 16:54:28.662657  3366 net.cpp:409] fire6/squeeze1x1 -> fire6/squeeze1x1
I1112 16:54:28.667923  3366 net.cpp:144] Setting up fire6/squeeze1x1
I1112 16:54:28.667948  3366 net.cpp:151] Top shape: 64 48 14 14 (602112)
I1112 16:54:28.667955  3366 net.cpp:159] Memory required for data: 1629297664
I1112 16:54:28.667968  3366 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1112 16:54:28.667981  3366 net.cpp:94] Creating Layer fire6/relu_squeeze1x1
I1112 16:54:28.667989  3366 net.cpp:435] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1112 16:54:28.667999  3366 net.cpp:396] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1112 16:54:28.668012  3366 net.cpp:144] Setting up fire6/relu_squeeze1x1
I1112 16:54:28.668021  3366 net.cpp:151] Top shape: 64 48 14 14 (602112)
I1112 16:54:28.668027  3366 net.cpp:159] Memory required for data: 1631706112
I1112 16:54:28.668035  3366 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1112 16:54:28.668045  3366 net.cpp:94] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1112 16:54:28.668052  3366 net.cpp:435] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1112 16:54:28.668061  3366 net.cpp:409] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1112 16:54:28.668072  3366 net.cpp:409] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1112 16:54:28.668140  3366 net.cpp:144] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1112 16:54:28.668150  3366 net.cpp:151] Top shape: 64 48 14 14 (602112)
I1112 16:54:28.668159  3366 net.cpp:151] Top shape: 64 48 14 14 (602112)
I1112 16:54:28.668166  3366 net.cpp:159] Memory required for data: 1636523008
I1112 16:54:28.668174  3366 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1112 16:54:28.668187  3366 net.cpp:94] Creating Layer fire6/expand1x1
I1112 16:54:28.668195  3366 net.cpp:435] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1112 16:54:28.668232  3366 net.cpp:409] fire6/expand1x1 -> fire6/expand1x1
I1112 16:54:28.676406  3366 net.cpp:144] Setting up fire6/expand1x1
I1112 16:54:28.676429  3366 net.cpp:151] Top shape: 64 192 14 14 (2408448)
I1112 16:54:28.676437  3366 net.cpp:159] Memory required for data: 1646156800
I1112 16:54:28.676451  3366 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1112 16:54:28.676465  3366 net.cpp:94] Creating Layer fire6/relu_expand1x1
I1112 16:54:28.676475  3366 net.cpp:435] fire6/relu_expand1x1 <- fire6/expand1x1
I1112 16:54:28.676484  3366 net.cpp:396] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1112 16:54:28.676499  3366 net.cpp:144] Setting up fire6/relu_expand1x1
I1112 16:54:28.676508  3366 net.cpp:151] Top shape: 64 192 14 14 (2408448)
I1112 16:54:28.676515  3366 net.cpp:159] Memory required for data: 1655790592
I1112 16:54:28.676522  3366 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1112 16:54:28.676537  3366 net.cpp:94] Creating Layer fire6/expand3x3
I1112 16:54:28.676544  3366 net.cpp:435] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1112 16:54:28.676554  3366 net.cpp:409] fire6/expand3x3 -> fire6/expand3x3
I1112 16:54:28.695250  3366 net.cpp:144] Setting up fire6/expand3x3
I1112 16:54:28.695281  3366 net.cpp:151] Top shape: 64 192 14 14 (2408448)
I1112 16:54:28.695287  3366 net.cpp:159] Memory required for data: 1665424384
I1112 16:54:28.695303  3366 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1112 16:54:28.695317  3366 net.cpp:94] Creating Layer fire6/relu_expand3x3
I1112 16:54:28.695327  3366 net.cpp:435] fire6/relu_expand3x3 <- fire6/expand3x3
I1112 16:54:28.695338  3366 net.cpp:396] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1112 16:54:28.695354  3366 net.cpp:144] Setting up fire6/relu_expand3x3
I1112 16:54:28.695363  3366 net.cpp:151] Top shape: 64 192 14 14 (2408448)
I1112 16:54:28.695370  3366 net.cpp:159] Memory required for data: 1675058176
I1112 16:54:28.695377  3366 layer_factory.hpp:77] Creating layer fire6/concat
I1112 16:54:28.695387  3366 net.cpp:94] Creating Layer fire6/concat
I1112 16:54:28.695394  3366 net.cpp:435] fire6/concat <- fire6/expand1x1
I1112 16:54:28.695402  3366 net.cpp:435] fire6/concat <- fire6/expand3x3
I1112 16:54:28.695412  3366 net.cpp:409] fire6/concat -> fire6/concat
I1112 16:54:28.695480  3366 net.cpp:144] Setting up fire6/concat
I1112 16:54:28.695490  3366 net.cpp:151] Top shape: 64 384 14 14 (4816896)
I1112 16:54:28.695497  3366 net.cpp:159] Memory required for data: 1694325760
I1112 16:54:28.695504  3366 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1112 16:54:28.695519  3366 net.cpp:94] Creating Layer fire7/squeeze1x1
I1112 16:54:28.695526  3366 net.cpp:435] fire7/squeeze1x1 <- fire6/concat
I1112 16:54:28.695538  3366 net.cpp:409] fire7/squeeze1x1 -> fire7/squeeze1x1
I1112 16:54:28.701603  3366 net.cpp:144] Setting up fire7/squeeze1x1
I1112 16:54:28.701627  3366 net.cpp:151] Top shape: 64 48 14 14 (602112)
I1112 16:54:28.701634  3366 net.cpp:159] Memory required for data: 1696734208
I1112 16:54:28.701659  3366 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1112 16:54:28.701673  3366 net.cpp:94] Creating Layer fire7/relu_squeeze1x1
I1112 16:54:28.701680  3366 net.cpp:435] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1112 16:54:28.701690  3366 net.cpp:396] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1112 16:54:28.701704  3366 net.cpp:144] Setting up fire7/relu_squeeze1x1
I1112 16:54:28.701714  3366 net.cpp:151] Top shape: 64 48 14 14 (602112)
I1112 16:54:28.701720  3366 net.cpp:159] Memory required for data: 1699142656
I1112 16:54:28.701727  3366 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1112 16:54:28.701737  3366 net.cpp:94] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1112 16:54:28.701745  3366 net.cpp:435] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1112 16:54:28.701755  3366 net.cpp:409] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1112 16:54:28.701793  3366 net.cpp:409] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1112 16:54:28.701864  3366 net.cpp:144] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1112 16:54:28.701874  3366 net.cpp:151] Top shape: 64 48 14 14 (602112)
I1112 16:54:28.701882  3366 net.cpp:151] Top shape: 64 48 14 14 (602112)
I1112 16:54:28.701889  3366 net.cpp:159] Memory required for data: 1703959552
I1112 16:54:28.701896  3366 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1112 16:54:28.701927  3366 net.cpp:94] Creating Layer fire7/expand1x1
I1112 16:54:28.701936  3366 net.cpp:435] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1112 16:54:28.701946  3366 net.cpp:409] fire7/expand1x1 -> fire7/expand1x1
I1112 16:54:28.706464  3366 net.cpp:144] Setting up fire7/expand1x1
I1112 16:54:28.706490  3366 net.cpp:151] Top shape: 64 192 14 14 (2408448)
I1112 16:54:28.706496  3366 net.cpp:159] Memory required for data: 1713593344
I1112 16:54:28.706511  3366 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1112 16:54:28.706524  3366 net.cpp:94] Creating Layer fire7/relu_expand1x1
I1112 16:54:28.706533  3366 net.cpp:435] fire7/relu_expand1x1 <- fire7/expand1x1
I1112 16:54:28.706543  3366 net.cpp:396] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1112 16:54:28.706558  3366 net.cpp:144] Setting up fire7/relu_expand1x1
I1112 16:54:28.706568  3366 net.cpp:151] Top shape: 64 192 14 14 (2408448)
I1112 16:54:28.706574  3366 net.cpp:159] Memory required for data: 1723227136
I1112 16:54:28.706581  3366 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1112 16:54:28.706596  3366 net.cpp:94] Creating Layer fire7/expand3x3
I1112 16:54:28.706604  3366 net.cpp:435] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1112 16:54:28.706614  3366 net.cpp:409] fire7/expand3x3 -> fire7/expand3x3
I1112 16:54:28.717196  3366 net.cpp:144] Setting up fire7/expand3x3
I1112 16:54:28.717231  3366 net.cpp:151] Top shape: 64 192 14 14 (2408448)
I1112 16:54:28.717239  3366 net.cpp:159] Memory required for data: 1732860928
I1112 16:54:28.717255  3366 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1112 16:54:28.717270  3366 net.cpp:94] Creating Layer fire7/relu_expand3x3
I1112 16:54:28.717280  3366 net.cpp:435] fire7/relu_expand3x3 <- fire7/expand3x3
I1112 16:54:28.717291  3366 net.cpp:396] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1112 16:54:28.717309  3366 net.cpp:144] Setting up fire7/relu_expand3x3
I1112 16:54:28.717319  3366 net.cpp:151] Top shape: 64 192 14 14 (2408448)
I1112 16:54:28.717326  3366 net.cpp:159] Memory required for data: 1742494720
I1112 16:54:28.717337  3366 layer_factory.hpp:77] Creating layer fire7/concat
I1112 16:54:28.717350  3366 net.cpp:94] Creating Layer fire7/concat
I1112 16:54:28.717358  3366 net.cpp:435] fire7/concat <- fire7/expand1x1
I1112 16:54:28.717366  3366 net.cpp:435] fire7/concat <- fire7/expand3x3
I1112 16:54:28.717377  3366 net.cpp:409] fire7/concat -> fire7/concat
I1112 16:54:28.717463  3366 net.cpp:144] Setting up fire7/concat
I1112 16:54:28.717473  3366 net.cpp:151] Top shape: 64 384 14 14 (4816896)
I1112 16:54:28.717478  3366 net.cpp:159] Memory required for data: 1761762304
I1112 16:54:28.717486  3366 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1112 16:54:28.717500  3366 net.cpp:94] Creating Layer fire8/squeeze1x1
I1112 16:54:28.717509  3366 net.cpp:435] fire8/squeeze1x1 <- fire7/concat
I1112 16:54:28.717519  3366 net.cpp:409] fire8/squeeze1x1 -> fire8/squeeze1x1
I1112 16:54:28.723830  3366 net.cpp:144] Setting up fire8/squeeze1x1
I1112 16:54:28.723857  3366 net.cpp:151] Top shape: 64 64 14 14 (802816)
I1112 16:54:28.723865  3366 net.cpp:159] Memory required for data: 1764973568
I1112 16:54:28.723878  3366 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1112 16:54:28.723891  3366 net.cpp:94] Creating Layer fire8/relu_squeeze1x1
I1112 16:54:28.723899  3366 net.cpp:435] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1112 16:54:28.723938  3366 net.cpp:396] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1112 16:54:28.723953  3366 net.cpp:144] Setting up fire8/relu_squeeze1x1
I1112 16:54:28.723963  3366 net.cpp:151] Top shape: 64 64 14 14 (802816)
I1112 16:54:28.723969  3366 net.cpp:159] Memory required for data: 1768184832
I1112 16:54:28.723976  3366 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1112 16:54:28.723986  3366 net.cpp:94] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1112 16:54:28.723994  3366 net.cpp:435] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1112 16:54:28.724004  3366 net.cpp:409] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1112 16:54:28.724014  3366 net.cpp:409] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1112 16:54:28.724092  3366 net.cpp:144] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1112 16:54:28.724102  3366 net.cpp:151] Top shape: 64 64 14 14 (802816)
I1112 16:54:28.724110  3366 net.cpp:151] Top shape: 64 64 14 14 (802816)
I1112 16:54:28.724117  3366 net.cpp:159] Memory required for data: 1774607360
I1112 16:54:28.724125  3366 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1112 16:54:28.724138  3366 net.cpp:94] Creating Layer fire8/expand1x1
I1112 16:54:28.724146  3366 net.cpp:435] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1112 16:54:28.724156  3366 net.cpp:409] fire8/expand1x1 -> fire8/expand1x1
I1112 16:54:28.729286  3366 net.cpp:144] Setting up fire8/expand1x1
I1112 16:54:28.729310  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:28.729317  3366 net.cpp:159] Memory required for data: 1787452416
I1112 16:54:28.729331  3366 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1112 16:54:28.729343  3366 net.cpp:94] Creating Layer fire8/relu_expand1x1
I1112 16:54:28.729352  3366 net.cpp:435] fire8/relu_expand1x1 <- fire8/expand1x1
I1112 16:54:28.729362  3366 net.cpp:396] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1112 16:54:28.729377  3366 net.cpp:144] Setting up fire8/relu_expand1x1
I1112 16:54:28.729385  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:28.729393  3366 net.cpp:159] Memory required for data: 1800297472
I1112 16:54:28.729399  3366 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1112 16:54:28.729414  3366 net.cpp:94] Creating Layer fire8/expand3x3
I1112 16:54:28.729421  3366 net.cpp:435] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1112 16:54:28.729432  3366 net.cpp:409] fire8/expand3x3 -> fire8/expand3x3
I1112 16:54:28.755496  3366 net.cpp:144] Setting up fire8/expand3x3
I1112 16:54:28.755530  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:28.755537  3366 net.cpp:159] Memory required for data: 1813142528
I1112 16:54:28.755553  3366 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1112 16:54:28.755568  3366 net.cpp:94] Creating Layer fire8/relu_expand3x3
I1112 16:54:28.755576  3366 net.cpp:435] fire8/relu_expand3x3 <- fire8/expand3x3
I1112 16:54:28.755587  3366 net.cpp:396] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1112 16:54:28.755604  3366 net.cpp:144] Setting up fire8/relu_expand3x3
I1112 16:54:28.755612  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:28.755620  3366 net.cpp:159] Memory required for data: 1825987584
I1112 16:54:28.755626  3366 layer_factory.hpp:77] Creating layer fire8/concat
I1112 16:54:28.755637  3366 net.cpp:94] Creating Layer fire8/concat
I1112 16:54:28.755645  3366 net.cpp:435] fire8/concat <- fire8/expand1x1
I1112 16:54:28.755652  3366 net.cpp:435] fire8/concat <- fire8/expand3x3
I1112 16:54:28.755662  3366 net.cpp:409] fire8/concat -> fire8/concat
I1112 16:54:28.755746  3366 net.cpp:144] Setting up fire8/concat
I1112 16:54:28.755755  3366 net.cpp:151] Top shape: 64 512 14 14 (6422528)
I1112 16:54:28.755762  3366 net.cpp:159] Memory required for data: 1851677696
I1112 16:54:28.755797  3366 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1112 16:54:28.755811  3366 net.cpp:94] Creating Layer fire9/squeeze1x1
I1112 16:54:28.755820  3366 net.cpp:435] fire9/squeeze1x1 <- fire8/concat
I1112 16:54:28.755830  3366 net.cpp:409] fire9/squeeze1x1 -> fire9/squeeze1x1
I1112 16:54:28.765470  3366 net.cpp:144] Setting up fire9/squeeze1x1
I1112 16:54:28.765501  3366 net.cpp:151] Top shape: 64 64 14 14 (802816)
I1112 16:54:28.765507  3366 net.cpp:159] Memory required for data: 1854888960
I1112 16:54:28.765522  3366 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1112 16:54:28.765537  3366 net.cpp:94] Creating Layer fire9/relu_squeeze1x1
I1112 16:54:28.765545  3366 net.cpp:435] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1112 16:54:28.765557  3366 net.cpp:396] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1112 16:54:28.765571  3366 net.cpp:144] Setting up fire9/relu_squeeze1x1
I1112 16:54:28.765580  3366 net.cpp:151] Top shape: 64 64 14 14 (802816)
I1112 16:54:28.765588  3366 net.cpp:159] Memory required for data: 1858100224
I1112 16:54:28.765594  3366 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1112 16:54:28.765620  3366 net.cpp:94] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1112 16:54:28.765628  3366 net.cpp:435] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1112 16:54:28.765638  3366 net.cpp:409] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1112 16:54:28.765650  3366 net.cpp:409] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1112 16:54:28.765729  3366 net.cpp:144] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1112 16:54:28.765739  3366 net.cpp:151] Top shape: 64 64 14 14 (802816)
I1112 16:54:28.765748  3366 net.cpp:151] Top shape: 64 64 14 14 (802816)
I1112 16:54:28.765754  3366 net.cpp:159] Memory required for data: 1864522752
I1112 16:54:28.765763  3366 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1112 16:54:28.765777  3366 net.cpp:94] Creating Layer fire9/expand1x1
I1112 16:54:28.765784  3366 net.cpp:435] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1112 16:54:28.765795  3366 net.cpp:409] fire9/expand1x1 -> fire9/expand1x1
I1112 16:54:28.773036  3366 net.cpp:144] Setting up fire9/expand1x1
I1112 16:54:28.773066  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:28.773072  3366 net.cpp:159] Memory required for data: 1877367808
I1112 16:54:28.773087  3366 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1112 16:54:28.773102  3366 net.cpp:94] Creating Layer fire9/relu_expand1x1
I1112 16:54:28.773111  3366 net.cpp:435] fire9/relu_expand1x1 <- fire9/expand1x1
I1112 16:54:28.773123  3366 net.cpp:396] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1112 16:54:28.773138  3366 net.cpp:144] Setting up fire9/relu_expand1x1
I1112 16:54:28.773147  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:28.773154  3366 net.cpp:159] Memory required for data: 1890212864
I1112 16:54:28.773161  3366 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1112 16:54:28.773176  3366 net.cpp:94] Creating Layer fire9/expand3x3
I1112 16:54:28.773185  3366 net.cpp:435] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1112 16:54:28.773195  3366 net.cpp:409] fire9/expand3x3 -> fire9/expand3x3
I1112 16:54:28.793794  3366 net.cpp:144] Setting up fire9/expand3x3
I1112 16:54:28.793823  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:28.793830  3366 net.cpp:159] Memory required for data: 1903057920
I1112 16:54:28.793846  3366 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1112 16:54:28.793860  3366 net.cpp:94] Creating Layer fire9/relu_expand3x3
I1112 16:54:28.793870  3366 net.cpp:435] fire9/relu_expand3x3 <- fire9/expand3x3
I1112 16:54:28.793880  3366 net.cpp:396] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1112 16:54:28.793896  3366 net.cpp:144] Setting up fire9/relu_expand3x3
I1112 16:54:28.793941  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:28.793947  3366 net.cpp:159] Memory required for data: 1915902976
I1112 16:54:28.793956  3366 layer_factory.hpp:77] Creating layer fire9/concat
I1112 16:54:28.793965  3366 net.cpp:94] Creating Layer fire9/concat
I1112 16:54:28.793973  3366 net.cpp:435] fire9/concat <- fire9/expand1x1
I1112 16:54:28.793982  3366 net.cpp:435] fire9/concat <- fire9/expand3x3
I1112 16:54:28.793992  3366 net.cpp:409] fire9/concat -> fire9/concat
I1112 16:54:28.794067  3366 net.cpp:144] Setting up fire9/concat
I1112 16:54:28.794077  3366 net.cpp:151] Top shape: 64 512 14 14 (6422528)
I1112 16:54:28.794085  3366 net.cpp:159] Memory required for data: 1941593088
I1112 16:54:28.794091  3366 layer_factory.hpp:77] Creating layer drop9
I1112 16:54:28.794103  3366 net.cpp:94] Creating Layer drop9
I1112 16:54:28.794111  3366 net.cpp:435] drop9 <- fire9/concat
I1112 16:54:28.794121  3366 net.cpp:396] drop9 -> fire9/concat (in-place)
I1112 16:54:28.794160  3366 net.cpp:144] Setting up drop9
I1112 16:54:28.794170  3366 net.cpp:151] Top shape: 64 512 14 14 (6422528)
I1112 16:54:28.794178  3366 net.cpp:159] Memory required for data: 1967283200
I1112 16:54:28.794184  3366 layer_factory.hpp:77] Creating layer conv10
I1112 16:54:28.794198  3366 net.cpp:94] Creating Layer conv10
I1112 16:54:28.794205  3366 net.cpp:435] conv10 <- fire9/concat
I1112 16:54:28.794216  3366 net.cpp:409] conv10 -> conv10
I1112 16:54:28.803333  3366 net.cpp:144] Setting up conv10
I1112 16:54:28.803364  3366 net.cpp:151] Top shape: 64 2 14 14 (25088)
I1112 16:54:28.803372  3366 net.cpp:159] Memory required for data: 1967383552
I1112 16:54:28.803388  3366 layer_factory.hpp:77] Creating layer relu_conv10
I1112 16:54:28.803402  3366 net.cpp:94] Creating Layer relu_conv10
I1112 16:54:28.803412  3366 net.cpp:435] relu_conv10 <- conv10
I1112 16:54:28.803423  3366 net.cpp:396] relu_conv10 -> conv10 (in-place)
I1112 16:54:28.803442  3366 net.cpp:144] Setting up relu_conv10
I1112 16:54:28.803450  3366 net.cpp:151] Top shape: 64 2 14 14 (25088)
I1112 16:54:28.803457  3366 net.cpp:159] Memory required for data: 1967483904
I1112 16:54:28.803464  3366 layer_factory.hpp:77] Creating layer pool10
I1112 16:54:28.803478  3366 net.cpp:94] Creating Layer pool10
I1112 16:54:28.803485  3366 net.cpp:435] pool10 <- conv10
I1112 16:54:28.803496  3366 net.cpp:409] pool10 -> pool10
I1112 16:54:28.803596  3366 net.cpp:144] Setting up pool10
I1112 16:54:28.803606  3366 net.cpp:151] Top shape: 64 2 1 1 (128)
I1112 16:54:28.803614  3366 net.cpp:159] Memory required for data: 1967484416
I1112 16:54:28.803622  3366 layer_factory.hpp:77] Creating layer loss
I1112 16:54:28.803645  3366 net.cpp:94] Creating Layer loss
I1112 16:54:28.803653  3366 net.cpp:435] loss <- pool10
I1112 16:54:28.803661  3366 net.cpp:435] loss <- label
I1112 16:54:28.803673  3366 net.cpp:409] loss -> loss
I1112 16:54:28.803688  3366 layer_factory.hpp:77] Creating layer loss
I1112 16:54:28.803838  3366 net.cpp:144] Setting up loss
I1112 16:54:28.803848  3366 net.cpp:151] Top shape: (1)
I1112 16:54:28.803855  3366 net.cpp:154]     with loss weight 1
I1112 16:54:28.803884  3366 net.cpp:159] Memory required for data: 1967484420
I1112 16:54:28.803890  3366 net.cpp:220] loss needs backward computation.
I1112 16:54:28.803899  3366 net.cpp:220] pool10 needs backward computation.
I1112 16:54:28.803905  3366 net.cpp:220] relu_conv10 needs backward computation.
I1112 16:54:28.803912  3366 net.cpp:220] conv10 needs backward computation.
I1112 16:54:28.803920  3366 net.cpp:220] drop9 needs backward computation.
I1112 16:54:28.803927  3366 net.cpp:220] fire9/concat needs backward computation.
I1112 16:54:28.803936  3366 net.cpp:220] fire9/relu_expand3x3 needs backward computation.
I1112 16:54:28.803942  3366 net.cpp:220] fire9/expand3x3 needs backward computation.
I1112 16:54:28.803949  3366 net.cpp:220] fire9/relu_expand1x1 needs backward computation.
I1112 16:54:28.803958  3366 net.cpp:220] fire9/expand1x1 needs backward computation.
I1112 16:54:28.803998  3366 net.cpp:220] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1112 16:54:28.804006  3366 net.cpp:220] fire9/relu_squeeze1x1 needs backward computation.
I1112 16:54:28.804013  3366 net.cpp:220] fire9/squeeze1x1 needs backward computation.
I1112 16:54:28.804020  3366 net.cpp:220] fire8/concat needs backward computation.
I1112 16:54:28.804028  3366 net.cpp:220] fire8/relu_expand3x3 needs backward computation.
I1112 16:54:28.804035  3366 net.cpp:220] fire8/expand3x3 needs backward computation.
I1112 16:54:28.804042  3366 net.cpp:220] fire8/relu_expand1x1 needs backward computation.
I1112 16:54:28.804049  3366 net.cpp:220] fire8/expand1x1 needs backward computation.
I1112 16:54:28.804056  3366 net.cpp:220] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1112 16:54:28.804064  3366 net.cpp:220] fire8/relu_squeeze1x1 needs backward computation.
I1112 16:54:28.804071  3366 net.cpp:220] fire8/squeeze1x1 needs backward computation.
I1112 16:54:28.804078  3366 net.cpp:220] fire7/concat needs backward computation.
I1112 16:54:28.804085  3366 net.cpp:220] fire7/relu_expand3x3 needs backward computation.
I1112 16:54:28.804092  3366 net.cpp:220] fire7/expand3x3 needs backward computation.
I1112 16:54:28.804100  3366 net.cpp:220] fire7/relu_expand1x1 needs backward computation.
I1112 16:54:28.804106  3366 net.cpp:220] fire7/expand1x1 needs backward computation.
I1112 16:54:28.804113  3366 net.cpp:220] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1112 16:54:28.804121  3366 net.cpp:220] fire7/relu_squeeze1x1 needs backward computation.
I1112 16:54:28.804129  3366 net.cpp:220] fire7/squeeze1x1 needs backward computation.
I1112 16:54:28.804136  3366 net.cpp:220] fire6/concat needs backward computation.
I1112 16:54:28.804144  3366 net.cpp:220] fire6/relu_expand3x3 needs backward computation.
I1112 16:54:28.804150  3366 net.cpp:220] fire6/expand3x3 needs backward computation.
I1112 16:54:28.804158  3366 net.cpp:220] fire6/relu_expand1x1 needs backward computation.
I1112 16:54:28.804164  3366 net.cpp:220] fire6/expand1x1 needs backward computation.
I1112 16:54:28.804172  3366 net.cpp:220] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1112 16:54:28.804179  3366 net.cpp:220] fire6/relu_squeeze1x1 needs backward computation.
I1112 16:54:28.804186  3366 net.cpp:220] fire6/squeeze1x1 needs backward computation.
I1112 16:54:28.804194  3366 net.cpp:220] pool5 needs backward computation.
I1112 16:54:28.804201  3366 net.cpp:220] fire5/concat needs backward computation.
I1112 16:54:28.804209  3366 net.cpp:220] fire5/relu_expand3x3 needs backward computation.
I1112 16:54:28.804215  3366 net.cpp:220] fire5/expand3x3 needs backward computation.
I1112 16:54:28.804224  3366 net.cpp:220] fire5/relu_expand1x1 needs backward computation.
I1112 16:54:28.804230  3366 net.cpp:220] fire5/expand1x1 needs backward computation.
I1112 16:54:28.804237  3366 net.cpp:220] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1112 16:54:28.804244  3366 net.cpp:220] fire5/relu_squeeze1x1 needs backward computation.
I1112 16:54:28.804251  3366 net.cpp:220] fire5/squeeze1x1 needs backward computation.
I1112 16:54:28.804258  3366 net.cpp:220] fire4/concat needs backward computation.
I1112 16:54:28.804266  3366 net.cpp:220] fire4/relu_expand3x3 needs backward computation.
I1112 16:54:28.804273  3366 net.cpp:220] fire4/expand3x3 needs backward computation.
I1112 16:54:28.804280  3366 net.cpp:220] fire4/relu_expand1x1 needs backward computation.
I1112 16:54:28.804287  3366 net.cpp:220] fire4/expand1x1 needs backward computation.
I1112 16:54:28.804294  3366 net.cpp:220] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1112 16:54:28.804302  3366 net.cpp:220] fire4/relu_squeeze1x1 needs backward computation.
I1112 16:54:28.804309  3366 net.cpp:220] fire4/squeeze1x1 needs backward computation.
I1112 16:54:28.804316  3366 net.cpp:220] pool3 needs backward computation.
I1112 16:54:28.804323  3366 net.cpp:220] fire3/concat needs backward computation.
I1112 16:54:28.804338  3366 net.cpp:220] fire3/relu_expand3x3 needs backward computation.
I1112 16:54:28.804347  3366 net.cpp:220] fire3/expand3x3 needs backward computation.
I1112 16:54:28.804353  3366 net.cpp:220] fire3/relu_expand1x1 needs backward computation.
I1112 16:54:28.804360  3366 net.cpp:220] fire3/expand1x1 needs backward computation.
I1112 16:54:28.804368  3366 net.cpp:220] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1112 16:54:28.804375  3366 net.cpp:220] fire3/relu_squeeze1x1 needs backward computation.
I1112 16:54:28.804383  3366 net.cpp:220] fire3/squeeze1x1 needs backward computation.
I1112 16:54:28.804389  3366 net.cpp:220] fire2/concat needs backward computation.
I1112 16:54:28.804397  3366 net.cpp:220] fire2/relu_expand3x3 needs backward computation.
I1112 16:54:28.804404  3366 net.cpp:220] fire2/expand3x3 needs backward computation.
I1112 16:54:28.804411  3366 net.cpp:220] fire2/relu_expand1x1 needs backward computation.
I1112 16:54:28.804419  3366 net.cpp:220] fire2/expand1x1 needs backward computation.
I1112 16:54:28.804426  3366 net.cpp:220] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1112 16:54:28.804433  3366 net.cpp:220] fire2/relu_squeeze1x1 needs backward computation.
I1112 16:54:28.804440  3366 net.cpp:220] fire2/squeeze1x1 needs backward computation.
I1112 16:54:28.804447  3366 net.cpp:220] pool1 needs backward computation.
I1112 16:54:28.804455  3366 net.cpp:220] relu_conv1 needs backward computation.
I1112 16:54:28.804462  3366 net.cpp:220] conv1 needs backward computation.
I1112 16:54:28.804471  3366 net.cpp:222] train-data does not need backward computation.
I1112 16:54:28.804476  3366 net.cpp:264] This network produces output loss
I1112 16:54:28.804528  3366 net.cpp:284] Network initialization done.
I1112 16:54:28.805979  3366 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I1112 16:54:28.806071  3366 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer train-data
I1112 16:54:28.806387  3366 net.cpp:52] Initializing net from parameters:
state {
phase: TEST
}
layer {
name: "val-data"
type: "Data"
top: "data"
top: "label"
include {
phase: TEST
}
transform_param {
crop_size: 227
mean_file: "/media/myuser/120Gb/DIGITS/digits/jobs/20160917-133511-8c62/mean.binaryproto"
}
data_param {
source: "/media/myuser/120Gb/DIGITS/digits/jobs/20160917-133511-8c62/val_db"
batch_size: 64
backend: LMDB
}
}
layer {
name: "conv1"
type: "Convolution"
bottom: "data"
top: "conv1"
convolution_param {
num_output: 64
kernel_size: 3
stride: 2
weight_filler {
type: "xavier"
}
}
}
layer {
name: "relu_conv1"
type: "ReLU"
bottom: "conv1"
top: "conv1"
}
layer {
name: "pool1"
type: "Pooling"
bottom: "conv1"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fire2/squeeze1x1"
type: "Convolution"
bottom: "pool1"
top: "fire2/squeeze1x1"
convolution_param {
num_output: 16
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire2/relu_squeeze1x1"
type: "ReLU"
bottom: "fire2/squeeze1x1"
top: "fire2/squeeze1x1"
}
layer {
name: "fire2/expand1x1"
type: "Convolution"
bottom: "fire2/squeeze1x1"
top: "fire2/expand1x1"
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire2/relu_expand1x1"
type: "ReLU"
bottom: "fire2/expand1x1"
top: "fire2/expand1x1"
}
layer {
name: "fire2/expand3x3"
type: "Convolution"
bottom: "fire2/squeeze1x1"
top: "fire2/expand3x3"
convolution_param {
num_output: 64
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire2/relu_expand3x3"
type: "ReLU"
bottom: "fire2/expand3x3"
top: "fire2/expand3x3"
}
layer {
name: "fire2/concat"
type: "Concat"
bottom: "fire2/expand1x1"
bottom: "fire2/expand3x3"
top: "fire2/concat"
}
layer {
name: "fire3/squeeze1x1"
type: "Convolution"
bottom: "fire2/concat"
top: "fire3/squeeze1x1"
convolution_param {
num_output: 16
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire3/relu_squeeze1x1"
type: "ReLU"
bottom: "fire3/squeeze1x1"
top: "fire3/squeeze1x1"
}
layer {
name: "fire3/expand1x1"
type: "Convolution"
bottom: "fire3/squeeze1x1"
top: "fire3/expand1x1"
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire3/relu_expand1x1"
type: "ReLU"
bottom: "fire3/expand1x1"
top: "fire3/expand1x1"
}
layer {
name: "fire3/expand3x3"
type: "Convolution"
bottom: "fire3/squeeze1x1"
top: "fire3/expand3x3"
convolution_param {
num_output: 64
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire3/relu_expand3x3"
type: "ReLU"
bottom: "fire3/expand3x3"
top: "fire3/expand3x3"
}
layer {
name: "fire3/concat"
type: "Concat"
bottom: "fire3/expand1x1"
bottom: "fire3/expand3x3"
top: "fire3/concat"
}
layer {
name: "pool3"
type: "Pooling"
bottom: "fire3/concat"
top: "pool3"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fire4/squeeze1x1"
type: "Convolution"
bottom: "pool3"
top: "fire4/squeeze1x1"
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire4/relu_squeeze1x1"
type: "ReLU"
bottom: "fire4/squeeze1x1"
top: "fire4/squeeze1x1"
}
layer {
name: "fire4/expand1x1"
type: "Convolution"
bottom: "fire4/squeeze1x1"
top: "fire4/expand1x1"
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire4/relu_expand1x1"
type: "ReLU"
bottom: "fire4/expand1x1"
top: "fire4/expand1x1"
}
layer {
name: "fire4/expand3x3"
type: "Convolution"
bottom: "fire4/squeeze1x1"
top: "fire4/expand3x3"
convolution_param {
num_output: 128
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire4/relu_expand3x3"
type: "ReLU"
bottom: "fire4/expand3x3"
top: "fire4/expand3x3"
}
layer {
name: "fire4/concat"
type: "Concat"
bottom: "fire4/expand1x1"
bottom: "fire4/expand3x3"
top: "fire4/concat"
}
layer {
name: "fire5/squeeze1x1"
type: "Convolution"
bottom: "fire4/concat"
top: "fire5/squeeze1x1"
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire5/relu_squeeze1x1"
type: "ReLU"
bottom: "fire5/squeeze1x1"
top: "fire5/squeeze1x1"
}
layer {
name: "fire5/expand1x1"
type: "Convolution"
bottom: "fire5/squeeze1x1"
top: "fire5/expand1x1"
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire5/relu_expand1x1"
type: "ReLU"
bottom: "fire5/expand1x1"
top: "fire5/expand1x1"
}
layer {
name: "fire5/expand3x3"
type: "Convolution"
bottom: "fire5/squeeze1x1"
top: "fire5/expand3x3"
convolution_param {
num_output: 128
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire5/relu_expand3x3"
type: "ReLU"
bottom: "fire5/expand3x3"
top: "fire5/expand3x3"
}
layer {
name: "fire5/concat"
type: "Concat"
bottom: "fire5/expand1x1"
bottom: "fire5/expand3x3"
top: "fire5/concat"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "fire5/concat"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fire6/squeeze1x1"
type: "Convolution"
bottom: "pool5"
top: "fire6/squeeze1x1"
convolution_param {
num_output: 48
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire6/relu_squeeze1x1"
type: "ReLU"
bottom: "fire6/squeeze1x1"
top: "fire6/squeeze1x1"
}
layer {
name: "fire6/expand1x1"
type: "Convolution"
bottom: "fire6/squeeze1x1"
top: "fire6/expand1x1"
convolution_param {
num_output: 192
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire6/relu_expand1x1"
type: "ReLU"
bottom: "fire6/expand1x1"
top: "fire6/expand1x1"
}
layer {
name: "fire6/expand3x3"
type: "Convolution"
bottom: "fire6/squeeze1x1"
top: "fire6/expand3x3"
convolution_param {
num_output: 192
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire6/relu_expand3x3"
type: "ReLU"
bottom: "fire6/expand3x3"
top: "fire6/expand3x3"
}
layer {
name: "fire6/concat"
type: "Concat"
bottom: "fire6/expand1x1"
bottom: "fire6/expand3x3"
top: "fire6/concat"
}
layer {
name: "fire7/squeeze1x1"
type: "Convolution"
bottom: "fire6/concat"
top: "fire7/squeeze1x1"
convolution_param {
num_output: 48
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire7/relu_squeeze1x1"
type: "ReLU"
bottom: "fire7/squeeze1x1"
top: "fire7/squeeze1x1"
}
layer {
name: "fire7/expand1x1"
type: "Convolution"
bottom: "fire7/squeeze1x1"
top: "fire7/expand1x1"
convolution_param {
num_output: 192
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire7/relu_expand1x1"
type: "ReLU"
bottom: "fire7/expand1x1"
top: "fire7/expand1x1"
}
layer {
name: "fire7/expand3x3"
type: "Convolution"
bottom: "fire7/squeeze1x1"
top: "fire7/expand3x3"
convolution_param {
num_output: 192
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire7/relu_expand3x3"
type: "ReLU"
bottom: "fire7/expand3x3"
top: "fire7/expand3x3"
}
layer {
name: "fire7/concat"
type: "Concat"
bottom: "fire7/expand1x1"
bottom: "fire7/expand3x3"
top: "fire7/concat"
}
layer {
name: "fire8/squeeze1x1"
type: "Convolution"
bottom: "fire7/concat"
top: "fire8/squeeze1x1"
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire8/relu_squeeze1x1"
type: "ReLU"
bottom: "fire8/squeeze1x1"
top: "fire8/squeeze1x1"
}
layer {
name: "fire8/expand1x1"
type: "Convolution"
bottom: "fire8/squeeze1x1"
top: "fire8/expand1x1"
convolution_param {
num_output: 256
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire8/relu_expand1x1"
type: "ReLU"
bottom: "fire8/expand1x1"
top: "fire8/expand1x1"
}
layer {
name: "fire8/expand3x3"
type: "Convolution"
bottom: "fire8/squeeze1x1"
top: "fire8/expand3x3"
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire8/relu_expand3x3"
type: "ReLU"
bottom: "fire8/expand3x3"
top: "fire8/expand3x3"
}
layer {
name: "fire8/concat"
type: "Concat"
bottom: "fire8/expand1x1"
bottom: "fire8/expand3x3"
top: "fire8/concat"
}
layer {
name: "fire9/squeeze1x1"
type: "Convolution"
bottom: "fire8/concat"
top: "fire9/squeeze1x1"
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire9/relu_squeeze1x1"
type: "ReLU"
bottom: "fire9/squeeze1x1"
top: "fire9/squeeze1x1"
}
layer {
name: "fire9/expand1x1"
type: "Convolution"
bottom: "fire9/squeeze1x1"
top: "fire9/expand1x1"
convolution_param {
num_output: 256
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire9/relu_expand1x1"
type: "ReLU"
bottom: "fire9/expand1x1"
top: "fire9/expand1x1"
}
layer {
name: "fire9/expand3x3"
type: "Convolution"
bottom: "fire9/squeeze1x1"
top: "fire9/expand3x3"
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire9/relu_expand3x3"
type: "ReLU"
bottom: "fire9/expand3x3"
top: "fire9/expand3x3"
}
layer {
name: "fire9/concat"
type: "Concat"
bottom: "fire9/expand1x1"
bottom: "fire9/expand3x3"
top: "fire9/concat"
}
layer {
name: "drop9"
type: "Dropout"
bottom: "fire9/concat"
top: "fire9/concat"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "conv10"
type: "Convolution"
bottom: "fire9/concat"
top: "conv10"
convolution_param {
num_output: 2
kernel_size: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.01
}
}
}
layer {
name: "relu_conv10"
type: "ReLU"
bottom: "conv10"
top: "conv10"
}
layer {
name: "pool10"
type: "Pooling"
bottom: "conv10"
top: "pool10"
pooling_param {
pool: AVE
global_pooling: true
}
}
layer {
name: "accuracy"
type: "Accuracy"
bottom: "pool10"
bottom: "label"
top: "accuracy"
include {
phase: TEST
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "pool10"
bottom: "label"
top: "loss"
}
I1112 16:54:28.806704  3366 layer_factory.hpp:77] Creating layer val-data
I1112 16:54:28.806851  3366 net.cpp:94] Creating Layer val-data
I1112 16:54:28.806862  3366 net.cpp:409] val-data -> data
I1112 16:54:28.806875  3366 net.cpp:409] val-data -> label
I1112 16:54:28.806888  3366 data_transformer.cpp:25] Loading mean file from: /media/myuser/120Gb/DIGITS/digits/jobs/20160917-133511-8c62/mean.binaryproto
I1112 16:54:28.816511  3377 db_lmdb.cpp:35] Opened lmdb /media/myuser/120Gb/DIGITS/digits/jobs/20160917-133511-8c62/val_db
I1112 16:54:28.819941  3366 data_layer.cpp:76] output data size: 64,3,227,227
I1112 16:54:28.954008  3366 net.cpp:144] Setting up val-data
I1112 16:54:28.954049  3366 net.cpp:151] Top shape: 64 3 227 227 (9893568)
I1112 16:54:28.954061  3366 net.cpp:151] Top shape: 64 (64)
I1112 16:54:28.954068  3366 net.cpp:159] Memory required for data: 39574528
I1112 16:54:28.954079  3366 layer_factory.hpp:77] Creating layer label_val-data_1_split
I1112 16:54:28.954098  3366 net.cpp:94] Creating Layer label_val-data_1_split
I1112 16:54:28.954107  3366 net.cpp:435] label_val-data_1_split <- label
I1112 16:54:28.954119  3366 net.cpp:409] label_val-data_1_split -> label_val-data_1_split_0
I1112 16:54:28.954134  3366 net.cpp:409] label_val-data_1_split -> label_val-data_1_split_1
I1112 16:54:28.954222  3366 net.cpp:144] Setting up label_val-data_1_split
I1112 16:54:28.954233  3366 net.cpp:151] Top shape: 64 (64)
I1112 16:54:28.954242  3366 net.cpp:151] Top shape: 64 (64)
I1112 16:54:28.954249  3366 net.cpp:159] Memory required for data: 39575040
I1112 16:54:28.954257  3366 layer_factory.hpp:77] Creating layer conv1
I1112 16:54:28.954274  3366 net.cpp:94] Creating Layer conv1
I1112 16:54:28.954282  3366 net.cpp:435] conv1 <- data
I1112 16:54:28.954293  3366 net.cpp:409] conv1 -> conv1
I1112 16:54:28.988842  3366 net.cpp:144] Setting up conv1
I1112 16:54:28.988886  3366 net.cpp:151] Top shape: 64 64 113 113 (52301824)
I1112 16:54:28.988895  3366 net.cpp:159] Memory required for data: 248782336
I1112 16:54:28.988916  3366 layer_factory.hpp:77] Creating layer relu_conv1
I1112 16:54:28.988931  3366 net.cpp:94] Creating Layer relu_conv1
I1112 16:54:28.988940  3366 net.cpp:435] relu_conv1 <- conv1
I1112 16:54:28.988951  3366 net.cpp:396] relu_conv1 -> conv1 (in-place)
I1112 16:54:28.988970  3366 net.cpp:144] Setting up relu_conv1
I1112 16:54:28.988978  3366 net.cpp:151] Top shape: 64 64 113 113 (52301824)
I1112 16:54:28.988986  3366 net.cpp:159] Memory required for data: 457989632
I1112 16:54:28.988993  3366 layer_factory.hpp:77] Creating layer pool1
I1112 16:54:28.989008  3366 net.cpp:94] Creating Layer pool1
I1112 16:54:28.989017  3366 net.cpp:435] pool1 <- conv1
I1112 16:54:28.989027  3366 net.cpp:409] pool1 -> pool1
I1112 16:54:28.989162  3366 net.cpp:144] Setting up pool1
I1112 16:54:28.989172  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:28.989181  3366 net.cpp:159] Memory required for data: 509369856
I1112 16:54:28.989187  3366 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1112 16:54:28.989205  3366 net.cpp:94] Creating Layer fire2/squeeze1x1
I1112 16:54:28.989213  3366 net.cpp:435] fire2/squeeze1x1 <- pool1
I1112 16:54:28.989264  3366 net.cpp:409] fire2/squeeze1x1 -> fire2/squeeze1x1
I1112 16:54:28.992379  3366 net.cpp:144] Setting up fire2/squeeze1x1
I1112 16:54:28.992398  3366 net.cpp:151] Top shape: 64 16 56 56 (3211264)
I1112 16:54:28.992405  3366 net.cpp:159] Memory required for data: 522214912
I1112 16:54:28.992421  3366 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1112 16:54:28.992434  3366 net.cpp:94] Creating Layer fire2/relu_squeeze1x1
I1112 16:54:28.992441  3366 net.cpp:435] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1112 16:54:28.992451  3366 net.cpp:396] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1112 16:54:28.992465  3366 net.cpp:144] Setting up fire2/relu_squeeze1x1
I1112 16:54:28.992473  3366 net.cpp:151] Top shape: 64 16 56 56 (3211264)
I1112 16:54:28.992480  3366 net.cpp:159] Memory required for data: 535059968
I1112 16:54:28.992487  3366 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1112 16:54:28.992497  3366 net.cpp:94] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1112 16:54:28.992504  3366 net.cpp:435] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1112 16:54:28.992514  3366 net.cpp:409] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1112 16:54:28.992525  3366 net.cpp:409] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1112 16:54:28.992584  3366 net.cpp:144] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1112 16:54:28.992594  3366 net.cpp:151] Top shape: 64 16 56 56 (3211264)
I1112 16:54:28.992602  3366 net.cpp:151] Top shape: 64 16 56 56 (3211264)
I1112 16:54:28.992609  3366 net.cpp:159] Memory required for data: 560750080
I1112 16:54:28.992616  3366 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1112 16:54:28.992631  3366 net.cpp:94] Creating Layer fire2/expand1x1
I1112 16:54:28.992638  3366 net.cpp:435] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1112 16:54:28.992648  3366 net.cpp:409] fire2/expand1x1 -> fire2/expand1x1
I1112 16:54:28.995390  3366 net.cpp:144] Setting up fire2/expand1x1
I1112 16:54:28.995406  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:28.995414  3366 net.cpp:159] Memory required for data: 612130304
I1112 16:54:28.995427  3366 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1112 16:54:28.995440  3366 net.cpp:94] Creating Layer fire2/relu_expand1x1
I1112 16:54:28.995446  3366 net.cpp:435] fire2/relu_expand1x1 <- fire2/expand1x1
I1112 16:54:28.995456  3366 net.cpp:396] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1112 16:54:28.995468  3366 net.cpp:144] Setting up fire2/relu_expand1x1
I1112 16:54:28.995478  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:28.995486  3366 net.cpp:159] Memory required for data: 663510528
I1112 16:54:28.995492  3366 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1112 16:54:28.995504  3366 net.cpp:94] Creating Layer fire2/expand3x3
I1112 16:54:28.995512  3366 net.cpp:435] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1112 16:54:28.995522  3366 net.cpp:409] fire2/expand3x3 -> fire2/expand3x3
I1112 16:54:29.001922  3366 net.cpp:144] Setting up fire2/expand3x3
I1112 16:54:29.001955  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:29.001963  3366 net.cpp:159] Memory required for data: 714890752
I1112 16:54:29.001979  3366 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1112 16:54:29.001993  3366 net.cpp:94] Creating Layer fire2/relu_expand3x3
I1112 16:54:29.002002  3366 net.cpp:435] fire2/relu_expand3x3 <- fire2/expand3x3
I1112 16:54:29.002013  3366 net.cpp:396] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1112 16:54:29.002029  3366 net.cpp:144] Setting up fire2/relu_expand3x3
I1112 16:54:29.002038  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:29.002045  3366 net.cpp:159] Memory required for data: 766270976
I1112 16:54:29.002053  3366 layer_factory.hpp:77] Creating layer fire2/concat
I1112 16:54:29.002094  3366 net.cpp:94] Creating Layer fire2/concat
I1112 16:54:29.002101  3366 net.cpp:435] fire2/concat <- fire2/expand1x1
I1112 16:54:29.002110  3366 net.cpp:435] fire2/concat <- fire2/expand3x3
I1112 16:54:29.002120  3366 net.cpp:409] fire2/concat -> fire2/concat
I1112 16:54:29.002212  3366 net.cpp:144] Setting up fire2/concat
I1112 16:54:29.002221  3366 net.cpp:151] Top shape: 64 128 56 56 (25690112)
I1112 16:54:29.002229  3366 net.cpp:159] Memory required for data: 869031424
I1112 16:54:29.002236  3366 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1112 16:54:29.002252  3366 net.cpp:94] Creating Layer fire3/squeeze1x1
I1112 16:54:29.002259  3366 net.cpp:435] fire3/squeeze1x1 <- fire2/concat
I1112 16:54:29.002270  3366 net.cpp:409] fire3/squeeze1x1 -> fire3/squeeze1x1
I1112 16:54:29.006400  3366 net.cpp:144] Setting up fire3/squeeze1x1
I1112 16:54:29.006425  3366 net.cpp:151] Top shape: 64 16 56 56 (3211264)
I1112 16:54:29.006433  3366 net.cpp:159] Memory required for data: 881876480
I1112 16:54:29.006453  3366 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1112 16:54:29.006464  3366 net.cpp:94] Creating Layer fire3/relu_squeeze1x1
I1112 16:54:29.006472  3366 net.cpp:435] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1112 16:54:29.006482  3366 net.cpp:396] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1112 16:54:29.006496  3366 net.cpp:144] Setting up fire3/relu_squeeze1x1
I1112 16:54:29.006505  3366 net.cpp:151] Top shape: 64 16 56 56 (3211264)
I1112 16:54:29.006512  3366 net.cpp:159] Memory required for data: 894721536
I1112 16:54:29.006520  3366 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1112 16:54:29.006530  3366 net.cpp:94] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1112 16:54:29.006536  3366 net.cpp:435] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1112 16:54:29.006546  3366 net.cpp:409] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1112 16:54:29.006557  3366 net.cpp:409] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1112 16:54:29.006639  3366 net.cpp:144] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1112 16:54:29.006649  3366 net.cpp:151] Top shape: 64 16 56 56 (3211264)
I1112 16:54:29.006657  3366 net.cpp:151] Top shape: 64 16 56 56 (3211264)
I1112 16:54:29.006664  3366 net.cpp:159] Memory required for data: 920411648
I1112 16:54:29.006671  3366 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1112 16:54:29.006690  3366 net.cpp:94] Creating Layer fire3/expand1x1
I1112 16:54:29.006697  3366 net.cpp:435] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1112 16:54:29.006708  3366 net.cpp:409] fire3/expand1x1 -> fire3/expand1x1
I1112 16:54:29.010859  3366 net.cpp:144] Setting up fire3/expand1x1
I1112 16:54:29.010880  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:29.010887  3366 net.cpp:159] Memory required for data: 971791872
I1112 16:54:29.010900  3366 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1112 16:54:29.010911  3366 net.cpp:94] Creating Layer fire3/relu_expand1x1
I1112 16:54:29.010920  3366 net.cpp:435] fire3/relu_expand1x1 <- fire3/expand1x1
I1112 16:54:29.010931  3366 net.cpp:396] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1112 16:54:29.010943  3366 net.cpp:144] Setting up fire3/relu_expand1x1
I1112 16:54:29.010952  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:29.010959  3366 net.cpp:159] Memory required for data: 1023172096
I1112 16:54:29.010967  3366 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1112 16:54:29.010979  3366 net.cpp:94] Creating Layer fire3/expand3x3
I1112 16:54:29.010987  3366 net.cpp:435] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1112 16:54:29.010998  3366 net.cpp:409] fire3/expand3x3 -> fire3/expand3x3
I1112 16:54:29.017489  3366 net.cpp:144] Setting up fire3/expand3x3
I1112 16:54:29.017545  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:29.017554  3366 net.cpp:159] Memory required for data: 1074552320
I1112 16:54:29.017568  3366 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1112 16:54:29.017581  3366 net.cpp:94] Creating Layer fire3/relu_expand3x3
I1112 16:54:29.017590  3366 net.cpp:435] fire3/relu_expand3x3 <- fire3/expand3x3
I1112 16:54:29.017601  3366 net.cpp:396] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1112 16:54:29.017614  3366 net.cpp:144] Setting up fire3/relu_expand3x3
I1112 16:54:29.017623  3366 net.cpp:151] Top shape: 64 64 56 56 (12845056)
I1112 16:54:29.017630  3366 net.cpp:159] Memory required for data: 1125932544
I1112 16:54:29.017638  3366 layer_factory.hpp:77] Creating layer fire3/concat
I1112 16:54:29.017648  3366 net.cpp:94] Creating Layer fire3/concat
I1112 16:54:29.017655  3366 net.cpp:435] fire3/concat <- fire3/expand1x1
I1112 16:54:29.017663  3366 net.cpp:435] fire3/concat <- fire3/expand3x3
I1112 16:54:29.017673  3366 net.cpp:409] fire3/concat -> fire3/concat
I1112 16:54:29.017747  3366 net.cpp:144] Setting up fire3/concat
I1112 16:54:29.017757  3366 net.cpp:151] Top shape: 64 128 56 56 (25690112)
I1112 16:54:29.017765  3366 net.cpp:159] Memory required for data: 1228692992
I1112 16:54:29.017771  3366 layer_factory.hpp:77] Creating layer pool3
I1112 16:54:29.017783  3366 net.cpp:94] Creating Layer pool3
I1112 16:54:29.017791  3366 net.cpp:435] pool3 <- fire3/concat
I1112 16:54:29.017799  3366 net.cpp:409] pool3 -> pool3
I1112 16:54:29.017855  3366 net.cpp:144] Setting up pool3
I1112 16:54:29.017865  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:29.017873  3366 net.cpp:159] Memory required for data: 1254383104
I1112 16:54:29.017879  3366 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1112 16:54:29.017892  3366 net.cpp:94] Creating Layer fire4/squeeze1x1
I1112 16:54:29.017900  3366 net.cpp:435] fire4/squeeze1x1 <- pool3
I1112 16:54:29.017926  3366 net.cpp:409] fire4/squeeze1x1 -> fire4/squeeze1x1
I1112 16:54:29.020069  3366 net.cpp:144] Setting up fire4/squeeze1x1
I1112 16:54:29.020172  3366 net.cpp:151] Top shape: 64 32 28 28 (1605632)
I1112 16:54:29.020180  3366 net.cpp:159] Memory required for data: 1260805632
I1112 16:54:29.020195  3366 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1112 16:54:29.020206  3366 net.cpp:94] Creating Layer fire4/relu_squeeze1x1
I1112 16:54:29.020215  3366 net.cpp:435] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1112 16:54:29.020226  3366 net.cpp:396] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1112 16:54:29.020239  3366 net.cpp:144] Setting up fire4/relu_squeeze1x1
I1112 16:54:29.020248  3366 net.cpp:151] Top shape: 64 32 28 28 (1605632)
I1112 16:54:29.020256  3366 net.cpp:159] Memory required for data: 1267228160
I1112 16:54:29.020263  3366 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1112 16:54:29.020273  3366 net.cpp:94] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1112 16:54:29.020280  3366 net.cpp:435] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1112 16:54:29.020289  3366 net.cpp:409] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1112 16:54:29.020301  3366 net.cpp:409] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1112 16:54:29.020385  3366 net.cpp:144] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1112 16:54:29.020395  3366 net.cpp:151] Top shape: 64 32 28 28 (1605632)
I1112 16:54:29.020402  3366 net.cpp:151] Top shape: 64 32 28 28 (1605632)
I1112 16:54:29.020409  3366 net.cpp:159] Memory required for data: 1280073216
I1112 16:54:29.020417  3366 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1112 16:54:29.020431  3366 net.cpp:94] Creating Layer fire4/expand1x1
I1112 16:54:29.020438  3366 net.cpp:435] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1112 16:54:29.020448  3366 net.cpp:409] fire4/expand1x1 -> fire4/expand1x1
I1112 16:54:29.022768  3366 net.cpp:144] Setting up fire4/expand1x1
I1112 16:54:29.022783  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:29.022790  3366 net.cpp:159] Memory required for data: 1305763328
I1112 16:54:29.022810  3366 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1112 16:54:29.022821  3366 net.cpp:94] Creating Layer fire4/relu_expand1x1
I1112 16:54:29.022830  3366 net.cpp:435] fire4/relu_expand1x1 <- fire4/expand1x1
I1112 16:54:29.022840  3366 net.cpp:396] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1112 16:54:29.022852  3366 net.cpp:144] Setting up fire4/relu_expand1x1
I1112 16:54:29.022861  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:29.022868  3366 net.cpp:159] Memory required for data: 1331453440
I1112 16:54:29.022876  3366 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1112 16:54:29.022889  3366 net.cpp:94] Creating Layer fire4/expand3x3
I1112 16:54:29.022897  3366 net.cpp:435] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1112 16:54:29.022907  3366 net.cpp:409] fire4/expand3x3 -> fire4/expand3x3
I1112 16:54:29.028236  3366 net.cpp:144] Setting up fire4/expand3x3
I1112 16:54:29.028256  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:29.028264  3366 net.cpp:159] Memory required for data: 1357143552
I1112 16:54:29.028277  3366 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1112 16:54:29.028290  3366 net.cpp:94] Creating Layer fire4/relu_expand3x3
I1112 16:54:29.028298  3366 net.cpp:435] fire4/relu_expand3x3 <- fire4/expand3x3
I1112 16:54:29.028308  3366 net.cpp:396] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1112 16:54:29.028322  3366 net.cpp:144] Setting up fire4/relu_expand3x3
I1112 16:54:29.028331  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:29.028338  3366 net.cpp:159] Memory required for data: 1382833664
I1112 16:54:29.028345  3366 layer_factory.hpp:77] Creating layer fire4/concat
I1112 16:54:29.028357  3366 net.cpp:94] Creating Layer fire4/concat
I1112 16:54:29.028363  3366 net.cpp:435] fire4/concat <- fire4/expand1x1
I1112 16:54:29.028373  3366 net.cpp:435] fire4/concat <- fire4/expand3x3
I1112 16:54:29.028383  3366 net.cpp:409] fire4/concat -> fire4/concat
I1112 16:54:29.028439  3366 net.cpp:144] Setting up fire4/concat
I1112 16:54:29.028448  3366 net.cpp:151] Top shape: 64 256 28 28 (12845056)
I1112 16:54:29.028455  3366 net.cpp:159] Memory required for data: 1434213888
I1112 16:54:29.028462  3366 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1112 16:54:29.028476  3366 net.cpp:94] Creating Layer fire5/squeeze1x1
I1112 16:54:29.028484  3366 net.cpp:435] fire5/squeeze1x1 <- fire4/concat
I1112 16:54:29.028494  3366 net.cpp:409] fire5/squeeze1x1 -> fire5/squeeze1x1
I1112 16:54:29.031188  3366 net.cpp:144] Setting up fire5/squeeze1x1
I1112 16:54:29.031203  3366 net.cpp:151] Top shape: 64 32 28 28 (1605632)
I1112 16:54:29.031209  3366 net.cpp:159] Memory required for data: 1440636416
I1112 16:54:29.031221  3366 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1112 16:54:29.032578  3366 net.cpp:94] Creating Layer fire5/relu_squeeze1x1
I1112 16:54:29.032589  3366 net.cpp:435] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1112 16:54:29.032601  3366 net.cpp:396] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1112 16:54:29.032616  3366 net.cpp:144] Setting up fire5/relu_squeeze1x1
I1112 16:54:29.032627  3366 net.cpp:151] Top shape: 64 32 28 28 (1605632)
I1112 16:54:29.032634  3366 net.cpp:159] Memory required for data: 1447058944
I1112 16:54:29.032642  3366 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1112 16:54:29.032662  3366 net.cpp:94] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1112 16:54:29.032670  3366 net.cpp:435] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1112 16:54:29.032680  3366 net.cpp:409] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1112 16:54:29.032691  3366 net.cpp:409] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1112 16:54:29.032821  3366 net.cpp:144] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1112 16:54:29.032831  3366 net.cpp:151] Top shape: 64 32 28 28 (1605632)
I1112 16:54:29.032840  3366 net.cpp:151] Top shape: 64 32 28 28 (1605632)
I1112 16:54:29.032847  3366 net.cpp:159] Memory required for data: 1459904000
I1112 16:54:29.032855  3366 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1112 16:54:29.032869  3366 net.cpp:94] Creating Layer fire5/expand1x1
I1112 16:54:29.032877  3366 net.cpp:435] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1112 16:54:29.032887  3366 net.cpp:409] fire5/expand1x1 -> fire5/expand1x1
I1112 16:54:29.039518  3366 net.cpp:144] Setting up fire5/expand1x1
I1112 16:54:29.039535  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:29.039542  3366 net.cpp:159] Memory required for data: 1485594112
I1112 16:54:29.039556  3366 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1112 16:54:29.039567  3366 net.cpp:94] Creating Layer fire5/relu_expand1x1
I1112 16:54:29.039575  3366 net.cpp:435] fire5/relu_expand1x1 <- fire5/expand1x1
I1112 16:54:29.039584  3366 net.cpp:396] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1112 16:54:29.039597  3366 net.cpp:144] Setting up fire5/relu_expand1x1
I1112 16:54:29.039607  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:29.039613  3366 net.cpp:159] Memory required for data: 1511284224
I1112 16:54:29.039620  3366 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1112 16:54:29.039633  3366 net.cpp:94] Creating Layer fire5/expand3x3
I1112 16:54:29.039641  3366 net.cpp:435] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1112 16:54:29.039651  3366 net.cpp:409] fire5/expand3x3 -> fire5/expand3x3
I1112 16:54:29.045665  3366 net.cpp:144] Setting up fire5/expand3x3
I1112 16:54:29.045691  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:29.045698  3366 net.cpp:159] Memory required for data: 1536974336
I1112 16:54:29.045713  3366 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1112 16:54:29.045727  3366 net.cpp:94] Creating Layer fire5/relu_expand3x3
I1112 16:54:29.045735  3366 net.cpp:435] fire5/relu_expand3x3 <- fire5/expand3x3
I1112 16:54:29.045747  3366 net.cpp:396] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1112 16:54:29.045761  3366 net.cpp:144] Setting up fire5/relu_expand3x3
I1112 16:54:29.045770  3366 net.cpp:151] Top shape: 64 128 28 28 (6422528)
I1112 16:54:29.045778  3366 net.cpp:159] Memory required for data: 1562664448
I1112 16:54:29.045784  3366 layer_factory.hpp:77] Creating layer fire5/concat
I1112 16:54:29.045795  3366 net.cpp:94] Creating Layer fire5/concat
I1112 16:54:29.045802  3366 net.cpp:435] fire5/concat <- fire5/expand1x1
I1112 16:54:29.045810  3366 net.cpp:435] fire5/concat <- fire5/expand3x3
I1112 16:54:29.045820  3366 net.cpp:409] fire5/concat -> fire5/concat
I1112 16:54:29.045895  3366 net.cpp:144] Setting up fire5/concat
I1112 16:54:29.045924  3366 net.cpp:151] Top shape: 64 256 28 28 (12845056)
I1112 16:54:29.045933  3366 net.cpp:159] Memory required for data: 1614044672
I1112 16:54:29.045940  3366 layer_factory.hpp:77] Creating layer pool5
I1112 16:54:29.045953  3366 net.cpp:94] Creating Layer pool5
I1112 16:54:29.045959  3366 net.cpp:435] pool5 <- fire5/concat
I1112 16:54:29.045969  3366 net.cpp:409] pool5 -> pool5
I1112 16:54:29.046026  3366 net.cpp:144] Setting up pool5
I1112 16:54:29.046036  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:29.046043  3366 net.cpp:159] Memory required for data: 1626889728
I1112 16:54:29.046051  3366 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1112 16:54:29.046064  3366 net.cpp:94] Creating Layer fire6/squeeze1x1
I1112 16:54:29.046072  3366 net.cpp:435] fire6/squeeze1x1 <- pool5
I1112 16:54:29.046082  3366 net.cpp:409] fire6/squeeze1x1 -> fire6/squeeze1x1
I1112 16:54:29.048208  3366 net.cpp:144] Setting up fire6/squeeze1x1
I1112 16:54:29.048226  3366 net.cpp:151] Top shape: 64 48 14 14 (602112)
I1112 16:54:29.048259  3366 net.cpp:159] Memory required for data: 1629298176
I1112 16:54:29.048271  3366 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1112 16:54:29.048281  3366 net.cpp:94] Creating Layer fire6/relu_squeeze1x1
I1112 16:54:29.048290  3366 net.cpp:435] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1112 16:54:29.048298  3366 net.cpp:396] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1112 16:54:29.048311  3366 net.cpp:144] Setting up fire6/relu_squeeze1x1
I1112 16:54:29.048321  3366 net.cpp:151] Top shape: 64 48 14 14 (602112)
I1112 16:54:29.048327  3366 net.cpp:159] Memory required for data: 1631706624
I1112 16:54:29.048334  3366 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1112 16:54:29.048343  3366 net.cpp:94] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1112 16:54:29.048352  3366 net.cpp:435] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1112 16:54:29.048360  3366 net.cpp:409] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1112 16:54:29.048372  3366 net.cpp:409] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1112 16:54:29.048444  3366 net.cpp:144] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1112 16:54:29.048454  3366 net.cpp:151] Top shape: 64 48 14 14 (602112)
I1112 16:54:29.048462  3366 net.cpp:151] Top shape: 64 48 14 14 (602112)
I1112 16:54:29.048468  3366 net.cpp:159] Memory required for data: 1636523520
I1112 16:54:29.048476  3366 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1112 16:54:29.048488  3366 net.cpp:94] Creating Layer fire6/expand1x1
I1112 16:54:29.048496  3366 net.cpp:435] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1112 16:54:29.048506  3366 net.cpp:409] fire6/expand1x1 -> fire6/expand1x1
I1112 16:54:29.050629  3366 net.cpp:144] Setting up fire6/expand1x1
I1112 16:54:29.050642  3366 net.cpp:151] Top shape: 64 192 14 14 (2408448)
I1112 16:54:29.050649  3366 net.cpp:159] Memory required for data: 1646157312
I1112 16:54:29.050660  3366 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1112 16:54:29.050670  3366 net.cpp:94] Creating Layer fire6/relu_expand1x1
I1112 16:54:29.050678  3366 net.cpp:435] fire6/relu_expand1x1 <- fire6/expand1x1
I1112 16:54:29.050688  3366 net.cpp:396] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1112 16:54:29.050698  3366 net.cpp:144] Setting up fire6/relu_expand1x1
I1112 16:54:29.050707  3366 net.cpp:151] Top shape: 64 192 14 14 (2408448)
I1112 16:54:29.050714  3366 net.cpp:159] Memory required for data: 1655791104
I1112 16:54:29.050721  3366 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1112 16:54:29.050734  3366 net.cpp:94] Creating Layer fire6/expand3x3
I1112 16:54:29.050741  3366 net.cpp:435] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1112 16:54:29.050751  3366 net.cpp:409] fire6/expand3x3 -> fire6/expand3x3
I1112 16:54:29.055785  3366 net.cpp:144] Setting up fire6/expand3x3
I1112 16:54:29.055812  3366 net.cpp:151] Top shape: 64 192 14 14 (2408448)
I1112 16:54:29.055819  3366 net.cpp:159] Memory required for data: 1665424896
I1112 16:54:29.055833  3366 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1112 16:54:29.055846  3366 net.cpp:94] Creating Layer fire6/relu_expand3x3
I1112 16:54:29.055855  3366 net.cpp:435] fire6/relu_expand3x3 <- fire6/expand3x3
I1112 16:54:29.055866  3366 net.cpp:396] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1112 16:54:29.055879  3366 net.cpp:144] Setting up fire6/relu_expand3x3
I1112 16:54:29.055888  3366 net.cpp:151] Top shape: 64 192 14 14 (2408448)
I1112 16:54:29.055896  3366 net.cpp:159] Memory required for data: 1675058688
I1112 16:54:29.055902  3366 layer_factory.hpp:77] Creating layer fire6/concat
I1112 16:54:29.055912  3366 net.cpp:94] Creating Layer fire6/concat
I1112 16:54:29.055920  3366 net.cpp:435] fire6/concat <- fire6/expand1x1
I1112 16:54:29.055928  3366 net.cpp:435] fire6/concat <- fire6/expand3x3
I1112 16:54:29.055963  3366 net.cpp:409] fire6/concat -> fire6/concat
I1112 16:54:29.056025  3366 net.cpp:144] Setting up fire6/concat
I1112 16:54:29.056035  3366 net.cpp:151] Top shape: 64 384 14 14 (4816896)
I1112 16:54:29.056042  3366 net.cpp:159] Memory required for data: 1694326272
I1112 16:54:29.056049  3366 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1112 16:54:29.056062  3366 net.cpp:94] Creating Layer fire7/squeeze1x1
I1112 16:54:29.056071  3366 net.cpp:435] fire7/squeeze1x1 <- fire6/concat
I1112 16:54:29.056080  3366 net.cpp:409] fire7/squeeze1x1 -> fire7/squeeze1x1
I1112 16:54:29.058879  3366 net.cpp:144] Setting up fire7/squeeze1x1
I1112 16:54:29.058900  3366 net.cpp:151] Top shape: 64 48 14 14 (602112)
I1112 16:54:29.058908  3366 net.cpp:159] Memory required for data: 1696734720
I1112 16:54:29.058931  3366 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1112 16:54:29.058944  3366 net.cpp:94] Creating Layer fire7/relu_squeeze1x1
I1112 16:54:29.058953  3366 net.cpp:435] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1112 16:54:29.058962  3366 net.cpp:396] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1112 16:54:29.058976  3366 net.cpp:144] Setting up fire7/relu_squeeze1x1
I1112 16:54:29.058985  3366 net.cpp:151] Top shape: 64 48 14 14 (602112)
I1112 16:54:29.058992  3366 net.cpp:159] Memory required for data: 1699143168
I1112 16:54:29.059000  3366 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1112 16:54:29.059010  3366 net.cpp:94] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1112 16:54:29.059016  3366 net.cpp:435] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1112 16:54:29.059026  3366 net.cpp:409] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1112 16:54:29.059037  3366 net.cpp:409] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1112 16:54:29.059109  3366 net.cpp:144] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1112 16:54:29.059119  3366 net.cpp:151] Top shape: 64 48 14 14 (602112)
I1112 16:54:29.059128  3366 net.cpp:151] Top shape: 64 48 14 14 (602112)
I1112 16:54:29.059134  3366 net.cpp:159] Memory required for data: 1703960064
I1112 16:54:29.059141  3366 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1112 16:54:29.059155  3366 net.cpp:94] Creating Layer fire7/expand1x1
I1112 16:54:29.059162  3366 net.cpp:435] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1112 16:54:29.059172  3366 net.cpp:409] fire7/expand1x1 -> fire7/expand1x1
I1112 16:54:29.062919  3366 net.cpp:144] Setting up fire7/expand1x1
I1112 16:54:29.062935  3366 net.cpp:151] Top shape: 64 192 14 14 (2408448)
I1112 16:54:29.062943  3366 net.cpp:159] Memory required for data: 1713593856
I1112 16:54:29.062955  3366 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1112 16:54:29.062965  3366 net.cpp:94] Creating Layer fire7/relu_expand1x1
I1112 16:54:29.062973  3366 net.cpp:435] fire7/relu_expand1x1 <- fire7/expand1x1
I1112 16:54:29.062983  3366 net.cpp:396] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1112 16:54:29.062995  3366 net.cpp:144] Setting up fire7/relu_expand1x1
I1112 16:54:29.063004  3366 net.cpp:151] Top shape: 64 192 14 14 (2408448)
I1112 16:54:29.063011  3366 net.cpp:159] Memory required for data: 1723227648
I1112 16:54:29.063019  3366 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1112 16:54:29.063031  3366 net.cpp:94] Creating Layer fire7/expand3x3
I1112 16:54:29.063040  3366 net.cpp:435] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1112 16:54:29.063050  3366 net.cpp:409] fire7/expand3x3 -> fire7/expand3x3
I1112 16:54:29.069340  3366 net.cpp:144] Setting up fire7/expand3x3
I1112 16:54:29.069368  3366 net.cpp:151] Top shape: 64 192 14 14 (2408448)
I1112 16:54:29.069375  3366 net.cpp:159] Memory required for data: 1732861440
I1112 16:54:29.069389  3366 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1112 16:54:29.069429  3366 net.cpp:94] Creating Layer fire7/relu_expand3x3
I1112 16:54:29.069438  3366 net.cpp:435] fire7/relu_expand3x3 <- fire7/expand3x3
I1112 16:54:29.069448  3366 net.cpp:396] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1112 16:54:29.069463  3366 net.cpp:144] Setting up fire7/relu_expand3x3
I1112 16:54:29.069473  3366 net.cpp:151] Top shape: 64 192 14 14 (2408448)
I1112 16:54:29.069479  3366 net.cpp:159] Memory required for data: 1742495232
I1112 16:54:29.069486  3366 layer_factory.hpp:77] Creating layer fire7/concat
I1112 16:54:29.069496  3366 net.cpp:94] Creating Layer fire7/concat
I1112 16:54:29.069504  3366 net.cpp:435] fire7/concat <- fire7/expand1x1
I1112 16:54:29.069514  3366 net.cpp:435] fire7/concat <- fire7/expand3x3
I1112 16:54:29.069522  3366 net.cpp:409] fire7/concat -> fire7/concat
I1112 16:54:29.069584  3366 net.cpp:144] Setting up fire7/concat
I1112 16:54:29.069594  3366 net.cpp:151] Top shape: 64 384 14 14 (4816896)
I1112 16:54:29.069602  3366 net.cpp:159] Memory required for data: 1761762816
I1112 16:54:29.069608  3366 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1112 16:54:29.069622  3366 net.cpp:94] Creating Layer fire8/squeeze1x1
I1112 16:54:29.069629  3366 net.cpp:435] fire8/squeeze1x1 <- fire7/concat
I1112 16:54:29.069639  3366 net.cpp:409] fire8/squeeze1x1 -> fire8/squeeze1x1
I1112 16:54:29.072079  3366 net.cpp:144] Setting up fire8/squeeze1x1
I1112 16:54:29.072098  3366 net.cpp:151] Top shape: 64 64 14 14 (802816)
I1112 16:54:29.072104  3366 net.cpp:159] Memory required for data: 1764974080
I1112 16:54:29.072118  3366 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1112 16:54:29.072129  3366 net.cpp:94] Creating Layer fire8/relu_squeeze1x1
I1112 16:54:29.072136  3366 net.cpp:435] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1112 16:54:29.072146  3366 net.cpp:396] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1112 16:54:29.072160  3366 net.cpp:144] Setting up fire8/relu_squeeze1x1
I1112 16:54:29.072168  3366 net.cpp:151] Top shape: 64 64 14 14 (802816)
I1112 16:54:29.072175  3366 net.cpp:159] Memory required for data: 1768185344
I1112 16:54:29.072182  3366 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1112 16:54:29.072191  3366 net.cpp:94] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1112 16:54:29.072199  3366 net.cpp:435] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1112 16:54:29.072208  3366 net.cpp:409] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1112 16:54:29.072219  3366 net.cpp:409] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1112 16:54:29.072283  3366 net.cpp:144] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1112 16:54:29.072293  3366 net.cpp:151] Top shape: 64 64 14 14 (802816)
I1112 16:54:29.072301  3366 net.cpp:151] Top shape: 64 64 14 14 (802816)
I1112 16:54:29.072309  3366 net.cpp:159] Memory required for data: 1774607872
I1112 16:54:29.072316  3366 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1112 16:54:29.072329  3366 net.cpp:94] Creating Layer fire8/expand1x1
I1112 16:54:29.072337  3366 net.cpp:435] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1112 16:54:29.072347  3366 net.cpp:409] fire8/expand1x1 -> fire8/expand1x1
I1112 16:54:29.075848  3366 net.cpp:144] Setting up fire8/expand1x1
I1112 16:54:29.075873  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:29.075881  3366 net.cpp:159] Memory required for data: 1787452928
I1112 16:54:29.075894  3366 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1112 16:54:29.075906  3366 net.cpp:94] Creating Layer fire8/relu_expand1x1
I1112 16:54:29.075916  3366 net.cpp:435] fire8/relu_expand1x1 <- fire8/expand1x1
I1112 16:54:29.075925  3366 net.cpp:396] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1112 16:54:29.075939  3366 net.cpp:144] Setting up fire8/relu_expand1x1
I1112 16:54:29.075948  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:29.075981  3366 net.cpp:159] Memory required for data: 1800297984
I1112 16:54:29.075989  3366 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1112 16:54:29.076004  3366 net.cpp:94] Creating Layer fire8/expand3x3
I1112 16:54:29.076011  3366 net.cpp:435] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1112 16:54:29.076021  3366 net.cpp:409] fire8/expand3x3 -> fire8/expand3x3
I1112 16:54:29.090353  3366 net.cpp:144] Setting up fire8/expand3x3
I1112 16:54:29.090389  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:29.090395  3366 net.cpp:159] Memory required for data: 1813143040
I1112 16:54:29.090411  3366 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1112 16:54:29.090426  3366 net.cpp:94] Creating Layer fire8/relu_expand3x3
I1112 16:54:29.090436  3366 net.cpp:435] fire8/relu_expand3x3 <- fire8/expand3x3
I1112 16:54:29.090447  3366 net.cpp:396] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1112 16:54:29.090462  3366 net.cpp:144] Setting up fire8/relu_expand3x3
I1112 16:54:29.090471  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:29.090478  3366 net.cpp:159] Memory required for data: 1825988096
I1112 16:54:29.090486  3366 layer_factory.hpp:77] Creating layer fire8/concat
I1112 16:54:29.090497  3366 net.cpp:94] Creating Layer fire8/concat
I1112 16:54:29.090503  3366 net.cpp:435] fire8/concat <- fire8/expand1x1
I1112 16:54:29.090512  3366 net.cpp:435] fire8/concat <- fire8/expand3x3
I1112 16:54:29.090522  3366 net.cpp:409] fire8/concat -> fire8/concat
I1112 16:54:29.090616  3366 net.cpp:144] Setting up fire8/concat
I1112 16:54:29.090626  3366 net.cpp:151] Top shape: 64 512 14 14 (6422528)
I1112 16:54:29.090634  3366 net.cpp:159] Memory required for data: 1851678208
I1112 16:54:29.090641  3366 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1112 16:54:29.090656  3366 net.cpp:94] Creating Layer fire9/squeeze1x1
I1112 16:54:29.090663  3366 net.cpp:435] fire9/squeeze1x1 <- fire8/concat
I1112 16:54:29.090673  3366 net.cpp:409] fire9/squeeze1x1 -> fire9/squeeze1x1
I1112 16:54:29.093482  3366 net.cpp:144] Setting up fire9/squeeze1x1
I1112 16:54:29.093500  3366 net.cpp:151] Top shape: 64 64 14 14 (802816)
I1112 16:54:29.093508  3366 net.cpp:159] Memory required for data: 1854889472
I1112 16:54:29.093520  3366 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1112 16:54:29.093549  3366 net.cpp:94] Creating Layer fire9/relu_squeeze1x1
I1112 16:54:29.093556  3366 net.cpp:435] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1112 16:54:29.093567  3366 net.cpp:396] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1112 16:54:29.093581  3366 net.cpp:144] Setting up fire9/relu_squeeze1x1
I1112 16:54:29.093590  3366 net.cpp:151] Top shape: 64 64 14 14 (802816)
I1112 16:54:29.093597  3366 net.cpp:159] Memory required for data: 1858100736
I1112 16:54:29.093605  3366 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1112 16:54:29.093616  3366 net.cpp:94] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1112 16:54:29.093622  3366 net.cpp:435] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1112 16:54:29.093632  3366 net.cpp:409] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1112 16:54:29.093643  3366 net.cpp:409] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1112 16:54:29.093719  3366 net.cpp:144] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1112 16:54:29.093729  3366 net.cpp:151] Top shape: 64 64 14 14 (802816)
I1112 16:54:29.093739  3366 net.cpp:151] Top shape: 64 64 14 14 (802816)
I1112 16:54:29.093745  3366 net.cpp:159] Memory required for data: 1864523264
I1112 16:54:29.093752  3366 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1112 16:54:29.093766  3366 net.cpp:94] Creating Layer fire9/expand1x1
I1112 16:54:29.093775  3366 net.cpp:435] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1112 16:54:29.093801  3366 net.cpp:409] fire9/expand1x1 -> fire9/expand1x1
I1112 16:54:29.096376  3366 net.cpp:144] Setting up fire9/expand1x1
I1112 16:54:29.096390  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:29.096397  3366 net.cpp:159] Memory required for data: 1877368320
I1112 16:54:29.096410  3366 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1112 16:54:29.096420  3366 net.cpp:94] Creating Layer fire9/relu_expand1x1
I1112 16:54:29.096427  3366 net.cpp:435] fire9/relu_expand1x1 <- fire9/expand1x1
I1112 16:54:29.096436  3366 net.cpp:396] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1112 16:54:29.096449  3366 net.cpp:144] Setting up fire9/relu_expand1x1
I1112 16:54:29.096458  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:29.096465  3366 net.cpp:159] Memory required for data: 1890213376
I1112 16:54:29.096472  3366 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1112 16:54:29.096484  3366 net.cpp:94] Creating Layer fire9/expand3x3
I1112 16:54:29.096493  3366 net.cpp:435] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1112 16:54:29.096503  3366 net.cpp:409] fire9/expand3x3 -> fire9/expand3x3
I1112 16:54:29.103349  3366 net.cpp:144] Setting up fire9/expand3x3
I1112 16:54:29.103374  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:29.103381  3366 net.cpp:159] Memory required for data: 1903058432
I1112 16:54:29.103396  3366 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1112 16:54:29.103410  3366 net.cpp:94] Creating Layer fire9/relu_expand3x3
I1112 16:54:29.103418  3366 net.cpp:435] fire9/relu_expand3x3 <- fire9/expand3x3
I1112 16:54:29.103430  3366 net.cpp:396] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1112 16:54:29.103444  3366 net.cpp:144] Setting up fire9/relu_expand3x3
I1112 16:54:29.103453  3366 net.cpp:151] Top shape: 64 256 14 14 (3211264)
I1112 16:54:29.103461  3366 net.cpp:159] Memory required for data: 1915903488
I1112 16:54:29.103468  3366 layer_factory.hpp:77] Creating layer fire9/concat
I1112 16:54:29.103478  3366 net.cpp:94] Creating Layer fire9/concat
I1112 16:54:29.103487  3366 net.cpp:435] fire9/concat <- fire9/expand1x1
I1112 16:54:29.103494  3366 net.cpp:435] fire9/concat <- fire9/expand3x3
I1112 16:54:29.103504  3366 net.cpp:409] fire9/concat -> fire9/concat
I1112 16:54:29.103587  3366 net.cpp:144] Setting up fire9/concat
I1112 16:54:29.103598  3366 net.cpp:151] Top shape: 64 512 14 14 (6422528)
I1112 16:54:29.103605  3366 net.cpp:159] Memory required for data: 1941593600
I1112 16:54:29.103612  3366 layer_factory.hpp:77] Creating layer drop9
I1112 16:54:29.103623  3366 net.cpp:94] Creating Layer drop9
I1112 16:54:29.103631  3366 net.cpp:435] drop9 <- fire9/concat
I1112 16:54:29.103641  3366 net.cpp:396] drop9 -> fire9/concat (in-place)
I1112 16:54:29.103677  3366 net.cpp:144] Setting up drop9
I1112 16:54:29.103688  3366 net.cpp:151] Top shape: 64 512 14 14 (6422528)
I1112 16:54:29.103694  3366 net.cpp:159] Memory required for data: 1967283712
I1112 16:54:29.103701  3366 layer_factory.hpp:77] Creating layer conv10
I1112 16:54:29.103715  3366 net.cpp:94] Creating Layer conv10
I1112 16:54:29.103724  3366 net.cpp:435] conv10 <- fire9/concat
I1112 16:54:29.103734  3366 net.cpp:409] conv10 -> conv10
I1112 16:54:29.105569  3366 net.cpp:144] Setting up conv10
I1112 16:54:29.105582  3366 net.cpp:151] Top shape: 64 2 14 14 (25088)
I1112 16:54:29.105590  3366 net.cpp:159] Memory required for data: 1967384064
I1112 16:54:29.105602  3366 layer_factory.hpp:77] Creating layer relu_conv10
I1112 16:54:29.105612  3366 net.cpp:94] Creating Layer relu_conv10
I1112 16:54:29.105619  3366 net.cpp:435] relu_conv10 <- conv10
I1112 16:54:29.105628  3366 net.cpp:396] relu_conv10 -> conv10 (in-place)
I1112 16:54:29.105640  3366 net.cpp:144] Setting up relu_conv10
I1112 16:54:29.105649  3366 net.cpp:151] Top shape: 64 2 14 14 (25088)
I1112 16:54:29.105656  3366 net.cpp:159] Memory required for data: 1967484416
I1112 16:54:29.105664  3366 layer_factory.hpp:77] Creating layer pool10
I1112 16:54:29.105674  3366 net.cpp:94] Creating Layer pool10
I1112 16:54:29.105697  3366 net.cpp:435] pool10 <- conv10
I1112 16:54:29.105708  3366 net.cpp:409] pool10 -> pool10
I1112 16:54:29.105751  3366 net.cpp:144] Setting up pool10
I1112 16:54:29.105761  3366 net.cpp:151] Top shape: 64 2 1 1 (128)
I1112 16:54:29.105767  3366 net.cpp:159] Memory required for data: 1967484928
I1112 16:54:29.105774  3366 layer_factory.hpp:77] Creating layer pool10_pool10_0_split
I1112 16:54:29.105784  3366 net.cpp:94] Creating Layer pool10_pool10_0_split
I1112 16:54:29.105792  3366 net.cpp:435] pool10_pool10_0_split <- pool10
I1112 16:54:29.105800  3366 net.cpp:409] pool10_pool10_0_split -> pool10_pool10_0_split_0
I1112 16:54:29.105811  3366 net.cpp:409] pool10_pool10_0_split -> pool10_pool10_0_split_1
I1112 16:54:29.105865  3366 net.cpp:144] Setting up pool10_pool10_0_split
I1112 16:54:29.105875  3366 net.cpp:151] Top shape: 64 2 1 1 (128)
I1112 16:54:29.105883  3366 net.cpp:151] Top shape: 64 2 1 1 (128)
I1112 16:54:29.105890  3366 net.cpp:159] Memory required for data: 1967485952
I1112 16:54:29.105896  3366 layer_factory.hpp:77] Creating layer accuracy
I1112 16:54:29.105927  3366 net.cpp:94] Creating Layer accuracy
I1112 16:54:29.105936  3366 net.cpp:435] accuracy <- pool10_pool10_0_split_0
I1112 16:54:29.105944  3366 net.cpp:435] accuracy <- label_val-data_1_split_0
I1112 16:54:29.105954  3366 net.cpp:409] accuracy -> accuracy
I1112 16:54:29.105967  3366 net.cpp:144] Setting up accuracy
I1112 16:54:29.105976  3366 net.cpp:151] Top shape: (1)
I1112 16:54:29.105983  3366 net.cpp:159] Memory required for data: 1967485956
I1112 16:54:29.105991  3366 layer_factory.hpp:77] Creating layer loss
I1112 16:54:29.106001  3366 net.cpp:94] Creating Layer loss
I1112 16:54:29.106009  3366 net.cpp:435] loss <- pool10_pool10_0_split_1
I1112 16:54:29.106017  3366 net.cpp:435] loss <- label_val-data_1_split_1
I1112 16:54:29.106026  3366 net.cpp:409] loss -> loss
I1112 16:54:29.106040  3366 layer_factory.hpp:77] Creating layer loss
I1112 16:54:29.106174  3366 net.cpp:144] Setting up loss
I1112 16:54:29.106184  3366 net.cpp:151] Top shape: (1)
I1112 16:54:29.106191  3366 net.cpp:154]     with loss weight 1
I1112 16:54:29.106207  3366 net.cpp:159] Memory required for data: 1967485960
I1112 16:54:29.106215  3366 net.cpp:220] loss needs backward computation.
I1112 16:54:29.106222  3366 net.cpp:222] accuracy does not need backward computation.
I1112 16:54:29.106230  3366 net.cpp:220] pool10_pool10_0_split needs backward computation.
I1112 16:54:29.106237  3366 net.cpp:220] pool10 needs backward computation.
I1112 16:54:29.106245  3366 net.cpp:220] relu_conv10 needs backward computation.
I1112 16:54:29.106251  3366 net.cpp:220] conv10 needs backward computation.
I1112 16:54:29.106258  3366 net.cpp:220] drop9 needs backward computation.
I1112 16:54:29.106266  3366 net.cpp:220] fire9/concat needs backward computation.
I1112 16:54:29.106272  3366 net.cpp:220] fire9/relu_expand3x3 needs backward computation.
I1112 16:54:29.106279  3366 net.cpp:220] fire9/expand3x3 needs backward computation.
I1112 16:54:29.106287  3366 net.cpp:220] fire9/relu_expand1x1 needs backward computation.
I1112 16:54:29.106294  3366 net.cpp:220] fire9/expand1x1 needs backward computation.
I1112 16:54:29.106302  3366 net.cpp:220] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1112 16:54:29.106309  3366 net.cpp:220] fire9/relu_squeeze1x1 needs backward computation.
I1112 16:54:29.106317  3366 net.cpp:220] fire9/squeeze1x1 needs backward computation.
I1112 16:54:29.106323  3366 net.cpp:220] fire8/concat needs backward computation.
I1112 16:54:29.106331  3366 net.cpp:220] fire8/relu_expand3x3 needs backward computation.
I1112 16:54:29.106338  3366 net.cpp:220] fire8/expand3x3 needs backward computation.
I1112 16:54:29.106346  3366 net.cpp:220] fire8/relu_expand1x1 needs backward computation.
I1112 16:54:29.106353  3366 net.cpp:220] fire8/expand1x1 needs backward computation.
I1112 16:54:29.106360  3366 net.cpp:220] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1112 16:54:29.106379  3366 net.cpp:220] fire8/relu_squeeze1x1 needs backward computation.
I1112 16:54:29.106386  3366 net.cpp:220] fire8/squeeze1x1 needs backward computation.
I1112 16:54:29.106395  3366 net.cpp:220] fire7/concat needs backward computation.
I1112 16:54:29.106401  3366 net.cpp:220] fire7/relu_expand3x3 needs backward computation.
I1112 16:54:29.106410  3366 net.cpp:220] fire7/expand3x3 needs backward computation.
I1112 16:54:29.106416  3366 net.cpp:220] fire7/relu_expand1x1 needs backward computation.
I1112 16:54:29.106423  3366 net.cpp:220] fire7/expand1x1 needs backward computation.
I1112 16:54:29.106431  3366 net.cpp:220] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1112 16:54:29.106438  3366 net.cpp:220] fire7/relu_squeeze1x1 needs backward computation.
I1112 16:54:29.106446  3366 net.cpp:220] fire7/squeeze1x1 needs backward computation.
I1112 16:54:29.106452  3366 net.cpp:220] fire6/concat needs backward computation.
I1112 16:54:29.106461  3366 net.cpp:220] fire6/relu_expand3x3 needs backward computation.
I1112 16:54:29.106467  3366 net.cpp:220] fire6/expand3x3 needs backward computation.
I1112 16:54:29.106474  3366 net.cpp:220] fire6/relu_expand1x1 needs backward computation.
I1112 16:54:29.106482  3366 net.cpp:220] fire6/expand1x1 needs backward computation.
I1112 16:54:29.106488  3366 net.cpp:220] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1112 16:54:29.106495  3366 net.cpp:220] fire6/relu_squeeze1x1 needs backward computation.
I1112 16:54:29.106503  3366 net.cpp:220] fire6/squeeze1x1 needs backward computation.
I1112 16:54:29.106510  3366 net.cpp:220] pool5 needs backward computation.
I1112 16:54:29.106518  3366 net.cpp:220] fire5/concat needs backward computation.
I1112 16:54:29.106525  3366 net.cpp:220] fire5/relu_expand3x3 needs backward computation.
I1112 16:54:29.106533  3366 net.cpp:220] fire5/expand3x3 needs backward computation.
I1112 16:54:29.106539  3366 net.cpp:220] fire5/relu_expand1x1 needs backward computation.
I1112 16:54:29.106546  3366 net.cpp:220] fire5/expand1x1 needs backward computation.
I1112 16:54:29.106554  3366 net.cpp:220] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1112 16:54:29.106561  3366 net.cpp:220] fire5/relu_squeeze1x1 needs backward computation.
I1112 16:54:29.106569  3366 net.cpp:220] fire5/squeeze1x1 needs backward computation.
I1112 16:54:29.106575  3366 net.cpp:220] fire4/concat needs backward computation.
I1112 16:54:29.106583  3366 net.cpp:220] fire4/relu_expand3x3 needs backward computation.
I1112 16:54:29.106590  3366 net.cpp:220] fire4/expand3x3 needs backward computation.
I1112 16:54:29.106598  3366 net.cpp:220] fire4/relu_expand1x1 needs backward computation.
I1112 16:54:29.106604  3366 net.cpp:220] fire4/expand1x1 needs backward computation.
I1112 16:54:29.106612  3366 net.cpp:220] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1112 16:54:29.106619  3366 net.cpp:220] fire4/relu_squeeze1x1 needs backward computation.
I1112 16:54:29.106626  3366 net.cpp:220] fire4/squeeze1x1 needs backward computation.
I1112 16:54:29.106633  3366 net.cpp:220] pool3 needs backward computation.
I1112 16:54:29.106642  3366 net.cpp:220] fire3/concat needs backward computation.
I1112 16:54:29.106648  3366 net.cpp:220] fire3/relu_expand3x3 needs backward computation.
I1112 16:54:29.106655  3366 net.cpp:220] fire3/expand3x3 needs backward computation.
I1112 16:54:29.106663  3366 net.cpp:220] fire3/relu_expand1x1 needs backward computation.
I1112 16:54:29.106670  3366 net.cpp:220] fire3/expand1x1 needs backward computation.
I1112 16:54:29.106678  3366 net.cpp:220] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1112 16:54:29.106684  3366 net.cpp:220] fire3/relu_squeeze1x1 needs backward computation.
I1112 16:54:29.106691  3366 net.cpp:220] fire3/squeeze1x1 needs backward computation.
I1112 16:54:29.106699  3366 net.cpp:220] fire2/concat needs backward computation.
I1112 16:54:29.106708  3366 net.cpp:220] fire2/relu_expand3x3 needs backward computation.
I1112 16:54:29.106721  3366 net.cpp:220] fire2/expand3x3 needs backward computation.
I1112 16:54:29.106729  3366 net.cpp:220] fire2/relu_expand1x1 needs backward computation.
I1112 16:54:29.106736  3366 net.cpp:220] fire2/expand1x1 needs backward computation.
I1112 16:54:29.106745  3366 net.cpp:220] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1112 16:54:29.106752  3366 net.cpp:220] fire2/relu_squeeze1x1 needs backward computation.
I1112 16:54:29.106760  3366 net.cpp:220] fire2/squeeze1x1 needs backward computation.
I1112 16:54:29.106766  3366 net.cpp:220] pool1 needs backward computation.
I1112 16:54:29.106775  3366 net.cpp:220] relu_conv1 needs backward computation.
I1112 16:54:29.106781  3366 net.cpp:220] conv1 needs backward computation.
I1112 16:54:29.106789  3366 net.cpp:222] label_val-data_1_split does not need backward computation.
I1112 16:54:29.106797  3366 net.cpp:222] val-data does not need backward computation.
I1112 16:54:29.106804  3366 net.cpp:264] This network produces output accuracy
I1112 16:54:29.106812  3366 net.cpp:264] This network produces output loss
I1112 16:54:29.106866  3366 net.cpp:284] Network initialization done.
I1112 16:54:29.107138  3366 solver.cpp:60] Solver scaffolding done.
I1112 16:54:29.111963  3366 caffe.cpp:231] Starting Optimization
I1112 16:54:29.111980  3366 solver.cpp:304] Solving
I1112 16:54:29.111987  3366 solver.cpp:305] Learning Rate Policy: poly
I1112 16:54:29.113661  3366 solver.cpp:362] Iteration 0, Testing net (#0)
I1112 16:54:29.113673  3366 net.cpp:723] Ignoring source layer train-data
I1112 16:54:29.118635  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 16:54:44.139772  3366 solver.cpp:429]     Test net output #0: accuracy = 0.500791
I1112 16:54:44.139832  3366 solver.cpp:429]     Test net output #1: loss = 0.692555 (* 1 = 0.692555 loss)
I1112 16:54:45.716300  3366 solver.cpp:242] Iteration 0 (0 iter/s, 16.6041s/39 iter), loss = 0.692886
I1112 16:54:45.716359  3366 solver.cpp:261]     Train net output #0: loss = 0.69033 (* 1 = 0.69033 loss)
I1112 16:54:45.716387  3366 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I1112 16:55:17.881980  3366 solver.cpp:242] Iteration 39 (1.21249 iter/s, 32.1653s/39 iter), loss = 0.690169
I1112 16:55:17.882123  3366 solver.cpp:261]     Train net output #0: loss = 0.685477 (* 1 = 0.685477 loss)
I1112 16:55:17.882143  3366 sgd_solver.cpp:106] Iteration 39, lr = 0.00497923
I1112 16:55:52.467663  3366 solver.cpp:242] Iteration 78 (1.12765 iter/s, 34.5852s/39 iter), loss = 0.691828
I1112 16:55:52.467775  3366 solver.cpp:261]     Train net output #0: loss = 0.679453 (* 1 = 0.679453 loss)
I1112 16:55:52.467793  3366 sgd_solver.cpp:106] Iteration 78, lr = 0.00495847
I1112 16:56:28.106042  3366 solver.cpp:242] Iteration 117 (1.09434 iter/s, 35.6379s/39 iter), loss = 0.675495
I1112 16:56:28.106312  3366 solver.cpp:261]     Train net output #0: loss = 0.680424 (* 1 = 0.680424 loss)
I1112 16:56:28.106336  3366 sgd_solver.cpp:106] Iteration 117, lr = 0.0049377
I1112 16:57:02.877504  3366 solver.cpp:242] Iteration 156 (1.12163 iter/s, 34.7708s/39 iter), loss = 0.652317
I1112 16:57:02.881691  3366 solver.cpp:261]     Train net output #0: loss = 0.648217 (* 1 = 0.648217 loss)
I1112 16:57:02.881752  3366 sgd_solver.cpp:106] Iteration 156, lr = 0.00491693
I1112 16:57:34.707321  3366 solver.cpp:242] Iteration 195 (1.22544 iter/s, 31.8252s/39 iter), loss = 0.663068
I1112 16:57:34.707809  3366 solver.cpp:261]     Train net output #0: loss = 0.703691 (* 1 = 0.703691 loss)
I1112 16:57:34.707829  3366 sgd_solver.cpp:106] Iteration 195, lr = 0.00489617
I1112 16:58:01.931082  3366 solver.cpp:242] Iteration 234 (1.43262 iter/s, 27.2229s/39 iter), loss = 0.649791
I1112 16:58:01.931157  3366 solver.cpp:261]     Train net output #0: loss = 0.634051 (* 1 = 0.634051 loss)
I1112 16:58:01.931177  3366 sgd_solver.cpp:106] Iteration 234, lr = 0.0048754
I1112 16:58:02.854076  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 16:58:28.898361  3366 solver.cpp:242] Iteration 273 (1.44622 iter/s, 26.9668s/39 iter), loss = 0.659283
I1112 16:58:28.905988  3366 solver.cpp:261]     Train net output #0: loss = 0.707168 (* 1 = 0.707168 loss)
I1112 16:58:28.906029  3366 sgd_solver.cpp:106] Iteration 273, lr = 0.00485463
I1112 16:58:55.782346  3366 solver.cpp:242] Iteration 312 (1.45111 iter/s, 26.876s/39 iter), loss = 0.619182
I1112 16:58:55.782405  3366 solver.cpp:261]     Train net output #0: loss = 0.670626 (* 1 = 0.670626 loss)
I1112 16:58:55.782423  3366 sgd_solver.cpp:106] Iteration 312, lr = 0.00483387
I1112 16:58:55.783951  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_313.caffemodel
I1112 16:58:55.802392  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_313.solverstate
I1112 16:58:55.809731  3366 solver.cpp:362] Iteration 313, Testing net (#0)
I1112 16:58:55.809764  3366 net.cpp:723] Ignoring source layer train-data
I1112 16:59:07.254357  3366 solver.cpp:429]     Test net output #0: accuracy = 0.614122
I1112 16:59:07.256773  3366 solver.cpp:429]     Test net output #1: loss = 0.669531 (* 1 = 0.669531 loss)
I1112 16:59:34.329360  3366 solver.cpp:242] Iteration 351 (1.01177 iter/s, 38.5464s/39 iter), loss = 0.631143
I1112 16:59:34.329419  3366 solver.cpp:261]     Train net output #0: loss = 0.615727 (* 1 = 0.615727 loss)
I1112 16:59:34.329438  3366 sgd_solver.cpp:106] Iteration 351, lr = 0.0048131
I1112 17:00:01.543120  3366 solver.cpp:242] Iteration 390 (1.43312 iter/s, 27.2133s/39 iter), loss = 0.59067
I1112 17:00:01.543221  3366 solver.cpp:261]     Train net output #0: loss = 0.622727 (* 1 = 0.622727 loss)
I1112 17:00:01.543241  3366 sgd_solver.cpp:106] Iteration 390, lr = 0.00479233
I1112 17:00:28.726555  3366 solver.cpp:242] Iteration 429 (1.43472 iter/s, 27.1829s/39 iter), loss = 0.619978
I1112 17:00:28.726627  3366 solver.cpp:261]     Train net output #0: loss = 0.569977 (* 1 = 0.569977 loss)
I1112 17:00:28.726647  3366 sgd_solver.cpp:106] Iteration 429, lr = 0.00477157
I1112 17:00:56.059470  3366 solver.cpp:242] Iteration 468 (1.42688 iter/s, 27.3324s/39 iter), loss = 0.551072
I1112 17:00:56.062649  3366 solver.cpp:261]     Train net output #0: loss = 0.580458 (* 1 = 0.580458 loss)
I1112 17:00:56.069870  3366 sgd_solver.cpp:106] Iteration 468, lr = 0.0047508
I1112 17:00:56.897037  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:01:22.952837  3366 solver.cpp:242] Iteration 507 (1.45036 iter/s, 26.8898s/39 iter), loss = 0.612399
I1112 17:01:22.952899  3366 solver.cpp:261]     Train net output #0: loss = 0.572432 (* 1 = 0.572432 loss)
I1112 17:01:22.952917  3366 sgd_solver.cpp:106] Iteration 507, lr = 0.00473003
I1112 17:01:49.952853  3366 solver.cpp:242] Iteration 546 (1.44447 iter/s, 26.9995s/39 iter), loss = 0.541849
I1112 17:01:49.953086  3366 solver.cpp:261]     Train net output #0: loss = 0.550574 (* 1 = 0.550574 loss)
I1112 17:01:49.953106  3366 sgd_solver.cpp:106] Iteration 546, lr = 0.00470927
I1112 17:02:16.885370  3366 solver.cpp:242] Iteration 585 (1.4481 iter/s, 26.9319s/39 iter), loss = 0.600877
I1112 17:02:16.885429  3366 solver.cpp:261]     Train net output #0: loss = 0.498898 (* 1 = 0.498898 loss)
I1112 17:02:16.885447  3366 sgd_solver.cpp:106] Iteration 585, lr = 0.0046885
I1112 17:02:44.754869  3366 solver.cpp:242] Iteration 624 (1.3994 iter/s, 27.869s/39 iter), loss = 0.566651
I1112 17:02:44.758239  3366 solver.cpp:261]     Train net output #0: loss = 0.567918 (* 1 = 0.567918 loss)
I1112 17:02:44.758268  3366 sgd_solver.cpp:106] Iteration 624, lr = 0.00466773
I1112 17:02:45.925540  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_626.caffemodel
I1112 17:02:45.970487  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_626.solverstate
I1112 17:02:45.977390  3366 solver.cpp:362] Iteration 626, Testing net (#0)
I1112 17:02:45.977444  3366 net.cpp:723] Ignoring source layer train-data
I1112 17:02:57.304641  3366 solver.cpp:429]     Test net output #0: accuracy = 0.694818
I1112 17:02:57.304705  3366 solver.cpp:429]     Test net output #1: loss = 0.584931 (* 1 = 0.584931 loss)
I1112 17:03:23.525931  3366 solver.cpp:242] Iteration 663 (1.00601 iter/s, 38.7671s/39 iter), loss = 0.592125
I1112 17:03:23.526500  3366 solver.cpp:261]     Train net output #0: loss = 0.566732 (* 1 = 0.566732 loss)
I1112 17:03:23.526523  3366 sgd_solver.cpp:106] Iteration 663, lr = 0.00464696
I1112 17:03:51.231472  3366 solver.cpp:242] Iteration 702 (1.40771 iter/s, 27.7046s/39 iter), loss = 0.484186
I1112 17:03:51.231534  3366 solver.cpp:261]     Train net output #0: loss = 0.510253 (* 1 = 0.510253 loss)
I1112 17:03:51.231552  3366 sgd_solver.cpp:106] Iteration 702, lr = 0.0046262
I1112 17:03:52.347790  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:04:18.568976  3366 solver.cpp:242] Iteration 741 (1.42664 iter/s, 27.337s/39 iter), loss = 0.614035
I1112 17:04:18.571424  3366 solver.cpp:261]     Train net output #0: loss = 0.661304 (* 1 = 0.661304 loss)
I1112 17:04:18.571444  3366 sgd_solver.cpp:106] Iteration 741, lr = 0.00460543
I1112 17:04:45.725334  3366 solver.cpp:242] Iteration 780 (1.43628 iter/s, 27.1535s/39 iter), loss = 0.510473
I1112 17:04:45.725409  3366 solver.cpp:261]     Train net output #0: loss = 0.531563 (* 1 = 0.531563 loss)
I1112 17:04:45.725430  3366 sgd_solver.cpp:106] Iteration 780, lr = 0.00458466
I1112 17:05:13.363796  3366 solver.cpp:242] Iteration 819 (1.4111 iter/s, 27.638s/39 iter), loss = 0.629445
I1112 17:05:13.363989  3366 solver.cpp:261]     Train net output #0: loss = 0.619888 (* 1 = 0.619888 loss)
I1112 17:05:13.364009  3366 sgd_solver.cpp:106] Iteration 819, lr = 0.0045639
I1112 17:05:40.615257  3366 solver.cpp:242] Iteration 858 (1.43115 iter/s, 27.2509s/39 iter), loss = 0.51171
I1112 17:05:40.615319  3366 solver.cpp:261]     Train net output #0: loss = 0.491709 (* 1 = 0.491709 loss)
I1112 17:05:40.615339  3366 sgd_solver.cpp:106] Iteration 858, lr = 0.00454313
I1112 17:06:08.246651  3366 solver.cpp:242] Iteration 897 (1.41146 iter/s, 27.6309s/39 iter), loss = 0.582821
I1112 17:06:08.246754  3366 solver.cpp:261]     Train net output #0: loss = 0.598812 (* 1 = 0.598812 loss)
I1112 17:06:08.246773  3366 sgd_solver.cpp:106] Iteration 897, lr = 0.00452236
I1112 17:06:35.792289  3366 solver.cpp:242] Iteration 936 (1.41586 iter/s, 27.5451s/39 iter), loss = 0.493906
I1112 17:06:35.792356  3366 solver.cpp:261]     Train net output #0: loss = 0.472846 (* 1 = 0.472846 loss)
I1112 17:06:35.792376  3366 sgd_solver.cpp:106] Iteration 936, lr = 0.0045016
I1112 17:06:37.409865  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_939.caffemodel
I1112 17:06:37.426921  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_939.solverstate
I1112 17:06:37.433204  3366 solver.cpp:362] Iteration 939, Testing net (#0)
I1112 17:06:37.433244  3366 net.cpp:723] Ignoring source layer train-data
I1112 17:06:47.892130  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:06:48.595865  3366 solver.cpp:429]     Test net output #0: accuracy = 0.724684
I1112 17:06:48.595928  3366 solver.cpp:429]     Test net output #1: loss = 0.553651 (* 1 = 0.553651 loss)
I1112 17:07:14.109647  3366 solver.cpp:242] Iteration 975 (1.01783 iter/s, 38.3167s/39 iter), loss = 0.597735
I1112 17:07:14.109707  3366 solver.cpp:261]     Train net output #0: loss = 0.650001 (* 1 = 0.650001 loss)
I1112 17:07:14.109725  3366 sgd_solver.cpp:106] Iteration 975, lr = 0.00448083
I1112 17:07:41.552907  3366 solver.cpp:242] Iteration 1014 (1.42114 iter/s, 27.4428s/39 iter), loss = 0.513146
I1112 17:07:41.553030  3366 solver.cpp:261]     Train net output #0: loss = 0.486883 (* 1 = 0.486883 loss)
I1112 17:07:41.553050  3366 sgd_solver.cpp:106] Iteration 1014, lr = 0.00446006
I1112 17:08:08.481279  3366 solver.cpp:242] Iteration 1053 (1.44831 iter/s, 26.9279s/39 iter), loss = 0.570593
I1112 17:08:08.481341  3366 solver.cpp:261]     Train net output #0: loss = 0.630126 (* 1 = 0.630126 loss)
I1112 17:08:08.481360  3366 sgd_solver.cpp:106] Iteration 1053, lr = 0.0044393
I1112 17:08:35.999474  3366 solver.cpp:242] Iteration 1092 (1.41727 iter/s, 27.5177s/39 iter), loss = 0.459658
I1112 17:08:36.004487  3366 solver.cpp:261]     Train net output #0: loss = 0.426489 (* 1 = 0.426489 loss)
I1112 17:08:36.004526  3366 sgd_solver.cpp:106] Iteration 1092, lr = 0.00441853
I1112 17:09:03.117720  3366 solver.cpp:242] Iteration 1131 (1.43843 iter/s, 27.1129s/39 iter), loss = 0.536318
I1112 17:09:03.117786  3366 solver.cpp:261]     Train net output #0: loss = 0.463027 (* 1 = 0.463027 loss)
I1112 17:09:03.117806  3366 sgd_solver.cpp:106] Iteration 1131, lr = 0.00439776
I1112 17:09:30.226789  3366 solver.cpp:242] Iteration 1170 (1.43866 iter/s, 27.1086s/39 iter), loss = 0.501832
I1112 17:09:30.229579  3366 solver.cpp:261]     Train net output #0: loss = 0.484911 (* 1 = 0.484911 loss)
I1112 17:09:30.229605  3366 sgd_solver.cpp:106] Iteration 1170, lr = 0.004377
I1112 17:09:46.043578  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:09:57.682765  3366 solver.cpp:242] Iteration 1209 (1.42062 iter/s, 27.4529s/39 iter), loss = 0.532829
I1112 17:09:57.682826  3366 solver.cpp:261]     Train net output #0: loss = 0.419102 (* 1 = 0.419102 loss)
I1112 17:09:57.682843  3366 sgd_solver.cpp:106] Iteration 1209, lr = 0.00435623
I1112 17:10:24.857252  3366 solver.cpp:242] Iteration 1248 (1.43519 iter/s, 27.1741s/39 iter), loss = 0.533392
I1112 17:10:24.858557  3366 solver.cpp:261]     Train net output #0: loss = 0.582104 (* 1 = 0.582104 loss)
I1112 17:10:24.858578  3366 sgd_solver.cpp:106] Iteration 1248, lr = 0.00433546
I1112 17:10:27.162025  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_1252.caffemodel
I1112 17:10:27.191376  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1252.solverstate
I1112 17:10:27.201838  3366 solver.cpp:362] Iteration 1252, Testing net (#0)
I1112 17:10:27.201872  3366 net.cpp:723] Ignoring source layer train-data
I1112 17:10:38.346132  3366 solver.cpp:429]     Test net output #0: accuracy = 0.699367
I1112 17:10:38.346182  3366 solver.cpp:429]     Test net output #1: loss = 0.569477 (* 1 = 0.569477 loss)
I1112 17:11:03.658764  3366 solver.cpp:242] Iteration 1287 (1.00516 iter/s, 38.7997s/39 iter), loss = 0.578756
I1112 17:11:03.659682  3366 solver.cpp:261]     Train net output #0: loss = 0.590218 (* 1 = 0.590218 loss)
I1112 17:11:03.659705  3366 sgd_solver.cpp:106] Iteration 1287, lr = 0.0043147
I1112 17:11:31.051424  3366 solver.cpp:242] Iteration 1326 (1.42381 iter/s, 27.3914s/39 iter), loss = 0.568435
I1112 17:11:31.051487  3366 solver.cpp:261]     Train net output #0: loss = 0.625466 (* 1 = 0.625466 loss)
I1112 17:11:31.051506  3366 sgd_solver.cpp:106] Iteration 1326, lr = 0.00429393
I1112 17:11:58.463832  3366 solver.cpp:242] Iteration 1365 (1.42274 iter/s, 27.412s/39 iter), loss = 0.525693
I1112 17:11:58.469406  3366 solver.cpp:261]     Train net output #0: loss = 0.641701 (* 1 = 0.641701 loss)
I1112 17:11:58.469444  3366 sgd_solver.cpp:106] Iteration 1365, lr = 0.00427316
I1112 17:12:25.841989  3366 solver.cpp:242] Iteration 1404 (1.4248 iter/s, 27.3722s/39 iter), loss = 0.44992
I1112 17:12:25.842052  3366 solver.cpp:261]     Train net output #0: loss = 0.486227 (* 1 = 0.486227 loss)
I1112 17:12:25.842072  3366 sgd_solver.cpp:106] Iteration 1404, lr = 0.0042524
I1112 17:12:41.830870  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:12:52.840466  3366 solver.cpp:242] Iteration 1443 (1.44455 iter/s, 26.998s/39 iter), loss = 0.497604
I1112 17:12:52.840529  3366 solver.cpp:261]     Train net output #0: loss = 0.601173 (* 1 = 0.601173 loss)
I1112 17:12:52.840548  3366 sgd_solver.cpp:106] Iteration 1443, lr = 0.00423163
I1112 17:13:20.384676  3366 solver.cpp:242] Iteration 1482 (1.41593 iter/s, 27.5438s/39 iter), loss = 0.442563
I1112 17:13:20.384863  3366 solver.cpp:261]     Train net output #0: loss = 0.341959 (* 1 = 0.341959 loss)
I1112 17:13:20.384882  3366 sgd_solver.cpp:106] Iteration 1482, lr = 0.00421086
I1112 17:13:47.592612  3366 solver.cpp:242] Iteration 1521 (1.43343 iter/s, 27.2074s/39 iter), loss = 0.481115
I1112 17:13:47.592680  3366 solver.cpp:261]     Train net output #0: loss = 0.539155 (* 1 = 0.539155 loss)
I1112 17:13:47.592700  3366 sgd_solver.cpp:106] Iteration 1521, lr = 0.0041901
I1112 17:14:15.084873  3366 solver.cpp:242] Iteration 1560 (1.4186 iter/s, 27.4918s/39 iter), loss = 0.455463
I1112 17:14:15.090806  3366 solver.cpp:261]     Train net output #0: loss = 0.40153 (* 1 = 0.40153 loss)
I1112 17:14:15.090843  3366 sgd_solver.cpp:106] Iteration 1560, lr = 0.00416933
I1112 17:14:18.240093  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_1565.caffemodel
I1112 17:14:18.254355  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1565.solverstate
I1112 17:14:18.260777  3366 solver.cpp:362] Iteration 1565, Testing net (#0)
I1112 17:14:18.260809  3366 net.cpp:723] Ignoring source layer train-data
I1112 17:14:29.564700  3366 solver.cpp:429]     Test net output #0: accuracy = 0.760285
I1112 17:14:29.564750  3366 solver.cpp:429]     Test net output #1: loss = 0.490758 (* 1 = 0.490758 loss)
I1112 17:14:53.627486  3366 solver.cpp:242] Iteration 1599 (1.01204 iter/s, 38.5362s/39 iter), loss = 0.479309
I1112 17:14:53.627828  3366 solver.cpp:261]     Train net output #0: loss = 0.469151 (* 1 = 0.469151 loss)
I1112 17:14:53.627848  3366 sgd_solver.cpp:106] Iteration 1599, lr = 0.00414856
I1112 17:15:21.134806  3366 solver.cpp:242] Iteration 1638 (1.41784 iter/s, 27.5066s/39 iter), loss = 0.453753
I1112 17:15:21.134874  3366 solver.cpp:261]     Train net output #0: loss = 0.513436 (* 1 = 0.513436 loss)
I1112 17:15:21.134896  3366 sgd_solver.cpp:106] Iteration 1638, lr = 0.0041278
I1112 17:15:37.358697  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:15:48.331534  3366 solver.cpp:242] Iteration 1677 (1.43402 iter/s, 27.1963s/39 iter), loss = 0.510384
I1112 17:15:48.331601  3366 solver.cpp:261]     Train net output #0: loss = 0.470902 (* 1 = 0.470902 loss)
I1112 17:15:48.331619  3366 sgd_solver.cpp:106] Iteration 1677, lr = 0.00410703
I1112 17:16:15.543874  3366 solver.cpp:242] Iteration 1716 (1.4332 iter/s, 27.2119s/39 iter), loss = 0.514599
I1112 17:16:15.543987  3366 solver.cpp:261]     Train net output #0: loss = 0.506637 (* 1 = 0.506637 loss)
I1112 17:16:15.544005  3366 sgd_solver.cpp:106] Iteration 1716, lr = 0.00408626
I1112 17:16:43.132627  3366 solver.cpp:242] Iteration 1755 (1.41365 iter/s, 27.5883s/39 iter), loss = 0.478405
I1112 17:16:43.132684  3366 solver.cpp:261]     Train net output #0: loss = 0.418062 (* 1 = 0.418062 loss)
I1112 17:16:43.132704  3366 sgd_solver.cpp:106] Iteration 1755, lr = 0.00406549
I1112 17:17:10.255393  3366 solver.cpp:242] Iteration 1794 (1.43793 iter/s, 27.1223s/39 iter), loss = 0.469228
I1112 17:17:10.255674  3366 solver.cpp:261]     Train net output #0: loss = 0.473753 (* 1 = 0.473753 loss)
I1112 17:17:10.255695  3366 sgd_solver.cpp:106] Iteration 1794, lr = 0.00404473
I1112 17:17:37.414726  3366 solver.cpp:242] Iteration 1833 (1.43601 iter/s, 27.1587s/39 iter), loss = 0.464081
I1112 17:17:37.414783  3366 solver.cpp:261]     Train net output #0: loss = 0.357479 (* 1 = 0.357479 loss)
I1112 17:17:37.414801  3366 sgd_solver.cpp:106] Iteration 1833, lr = 0.00402396
I1112 17:18:05.049806  3366 solver.cpp:242] Iteration 1872 (1.41127 iter/s, 27.6346s/39 iter), loss = 0.47119
I1112 17:18:05.057021  3366 solver.cpp:261]     Train net output #0: loss = 0.376329 (* 1 = 0.376329 loss)
I1112 17:18:05.057073  3366 sgd_solver.cpp:106] Iteration 1872, lr = 0.00400319
I1112 17:18:08.734230  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_1878.caffemodel
I1112 17:18:08.748325  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1878.solverstate
I1112 17:18:08.762181  3366 solver.cpp:362] Iteration 1878, Testing net (#0)
I1112 17:18:08.762214  3366 net.cpp:723] Ignoring source layer train-data
I1112 17:18:19.922338  3366 solver.cpp:429]     Test net output #0: accuracy = 0.770965
I1112 17:18:19.922387  3366 solver.cpp:429]     Test net output #1: loss = 0.493127 (* 1 = 0.493127 loss)
I1112 17:18:33.798017  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:18:43.384204  3366 solver.cpp:242] Iteration 1911 (1.01757 iter/s, 38.3267s/39 iter), loss = 0.490236
I1112 17:18:43.384402  3366 solver.cpp:261]     Train net output #0: loss = 0.433622 (* 1 = 0.433622 loss)
I1112 17:18:43.384446  3366 sgd_solver.cpp:106] Iteration 1911, lr = 0.00398243
I1112 17:19:10.845649  3366 solver.cpp:242] Iteration 1950 (1.4202 iter/s, 27.4609s/39 iter), loss = 0.448281
I1112 17:19:10.845710  3366 solver.cpp:261]     Train net output #0: loss = 0.473125 (* 1 = 0.473125 loss)
I1112 17:19:10.845727  3366 sgd_solver.cpp:106] Iteration 1950, lr = 0.00396166
I1112 17:19:38.564268  3366 solver.cpp:242] Iteration 1989 (1.40702 iter/s, 27.7182s/39 iter), loss = 0.478474
I1112 17:19:38.565577  3366 solver.cpp:261]     Train net output #0: loss = 0.462446 (* 1 = 0.462446 loss)
I1112 17:19:38.565600  3366 sgd_solver.cpp:106] Iteration 1989, lr = 0.00394089
I1112 17:20:06.119463  3366 solver.cpp:242] Iteration 2028 (1.41543 iter/s, 27.5535s/39 iter), loss = 0.477179
I1112 17:20:06.119521  3366 solver.cpp:261]     Train net output #0: loss = 0.506691 (* 1 = 0.506691 loss)
I1112 17:20:06.119539  3366 sgd_solver.cpp:106] Iteration 2028, lr = 0.00392013
I1112 17:20:33.319042  3366 solver.cpp:242] Iteration 2067 (1.43387 iter/s, 27.1991s/39 iter), loss = 0.445185
I1112 17:20:33.319613  3366 solver.cpp:261]     Train net output #0: loss = 0.458882 (* 1 = 0.458882 loss)
I1112 17:20:33.319633  3366 sgd_solver.cpp:106] Iteration 2067, lr = 0.00389936
I1112 17:21:00.648306  3366 solver.cpp:242] Iteration 2106 (1.42709 iter/s, 27.3283s/39 iter), loss = 0.469588
I1112 17:21:00.648366  3366 solver.cpp:261]     Train net output #0: loss = 0.434883 (* 1 = 0.434883 loss)
I1112 17:21:00.648385  3366 sgd_solver.cpp:106] Iteration 2106, lr = 0.00387859
I1112 17:21:28.198000  3366 solver.cpp:242] Iteration 2145 (1.41565 iter/s, 27.5492s/39 iter), loss = 0.444526
I1112 17:21:28.198127  3366 solver.cpp:261]     Train net output #0: loss = 0.372614 (* 1 = 0.372614 loss)
I1112 17:21:28.198146  3366 sgd_solver.cpp:106] Iteration 2145, lr = 0.00385783
I1112 17:21:31.286137  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:21:55.454671  3366 solver.cpp:242] Iteration 2184 (1.43087 iter/s, 27.2562s/39 iter), loss = 0.481157
I1112 17:21:55.454813  3366 solver.cpp:261]     Train net output #0: loss = 0.374476 (* 1 = 0.374476 loss)
I1112 17:21:55.454833  3366 sgd_solver.cpp:106] Iteration 2184, lr = 0.00383706
I1112 17:21:59.824959  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_2191.caffemodel
I1112 17:21:59.841696  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2191.solverstate
I1112 17:21:59.848156  3366 solver.cpp:362] Iteration 2191, Testing net (#0)
I1112 17:21:59.848189  3366 net.cpp:723] Ignoring source layer train-data
I1112 17:22:10.936264  3366 solver.cpp:429]     Test net output #0: accuracy = 0.710641
I1112 17:22:10.936319  3366 solver.cpp:429]     Test net output #1: loss = 0.557505 (* 1 = 0.557505 loss)
I1112 17:22:34.303244  3366 solver.cpp:242] Iteration 2223 (1.00392 iter/s, 38.8479s/39 iter), loss = 0.426432
I1112 17:22:34.303359  3366 solver.cpp:261]     Train net output #0: loss = 0.437616 (* 1 = 0.437616 loss)
I1112 17:22:34.303377  3366 sgd_solver.cpp:106] Iteration 2223, lr = 0.00381629
I1112 17:23:01.577262  3366 solver.cpp:242] Iteration 2262 (1.42996 iter/s, 27.2735s/39 iter), loss = 0.506791
I1112 17:23:01.577323  3366 solver.cpp:261]     Train net output #0: loss = 0.499556 (* 1 = 0.499556 loss)
I1112 17:23:01.577342  3366 sgd_solver.cpp:106] Iteration 2262, lr = 0.00379553
I1112 17:23:29.142793  3366 solver.cpp:242] Iteration 2301 (1.41483 iter/s, 27.5651s/39 iter), loss = 0.46725
I1112 17:23:29.144904  3366 solver.cpp:261]     Train net output #0: loss = 0.516345 (* 1 = 0.516345 loss)
I1112 17:23:29.144929  3366 sgd_solver.cpp:106] Iteration 2301, lr = 0.00377476
I1112 17:23:56.592314  3366 solver.cpp:242] Iteration 2340 (1.42092 iter/s, 27.447s/39 iter), loss = 0.446676
I1112 17:23:56.592376  3366 solver.cpp:261]     Train net output #0: loss = 0.473031 (* 1 = 0.473031 loss)
I1112 17:23:56.592394  3366 sgd_solver.cpp:106] Iteration 2340, lr = 0.00375399
I1112 17:24:23.718616  3366 solver.cpp:242] Iteration 2379 (1.43774 iter/s, 27.1259s/39 iter), loss = 0.440303
I1112 17:24:23.718726  3366 solver.cpp:261]     Train net output #0: loss = 0.592298 (* 1 = 0.592298 loss)
I1112 17:24:23.718745  3366 sgd_solver.cpp:106] Iteration 2379, lr = 0.00373323
I1112 17:24:28.530419  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:24:51.440263  3366 solver.cpp:242] Iteration 2418 (1.40687 iter/s, 27.7211s/39 iter), loss = 0.434398
I1112 17:24:51.440325  3366 solver.cpp:261]     Train net output #0: loss = 0.429287 (* 1 = 0.429287 loss)
I1112 17:24:51.440342  3366 sgd_solver.cpp:106] Iteration 2418, lr = 0.00371246
I1112 17:25:18.575480  3366 solver.cpp:242] Iteration 2457 (1.43727 iter/s, 27.1348s/39 iter), loss = 0.437248
I1112 17:25:18.576772  3366 solver.cpp:261]     Train net output #0: loss = 0.488247 (* 1 = 0.488247 loss)
I1112 17:25:18.576798  3366 sgd_solver.cpp:106] Iteration 2457, lr = 0.00369169
I1112 17:25:46.096674  3366 solver.cpp:242] Iteration 2496 (1.41718 iter/s, 27.5195s/39 iter), loss = 0.591821
I1112 17:25:46.096737  3366 solver.cpp:261]     Train net output #0: loss = 0.605489 (* 1 = 0.605489 loss)
I1112 17:25:46.096757  3366 sgd_solver.cpp:106] Iteration 2496, lr = 0.00367093
I1112 17:25:51.399416  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_2504.caffemodel
I1112 17:25:51.416649  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2504.solverstate
I1112 17:25:51.426502  3366 solver.cpp:362] Iteration 2504, Testing net (#0)
I1112 17:25:51.426538  3366 net.cpp:723] Ignoring source layer train-data
I1112 17:26:02.648144  3366 solver.cpp:429]     Test net output #0: accuracy = 0.785799
I1112 17:26:02.648191  3366 solver.cpp:429]     Test net output #1: loss = 0.444737 (* 1 = 0.444737 loss)
I1112 17:26:24.915583  3366 solver.cpp:242] Iteration 2535 (1.00468 iter/s, 38.8183s/39 iter), loss = 0.44606
I1112 17:26:24.921990  3366 solver.cpp:261]     Train net output #0: loss = 0.365188 (* 1 = 0.365188 loss)
I1112 17:26:24.922027  3366 sgd_solver.cpp:106] Iteration 2535, lr = 0.00365016
I1112 17:26:52.382087  3366 solver.cpp:242] Iteration 2574 (1.42026 iter/s, 27.4597s/39 iter), loss = 0.463432
I1112 17:26:52.382153  3366 solver.cpp:261]     Train net output #0: loss = 0.49537 (* 1 = 0.49537 loss)
I1112 17:26:52.382172  3366 sgd_solver.cpp:106] Iteration 2574, lr = 0.00362939
I1112 17:27:19.850783  3366 solver.cpp:242] Iteration 2613 (1.41982 iter/s, 27.4682s/39 iter), loss = 0.381249
I1112 17:27:19.850908  3366 solver.cpp:261]     Train net output #0: loss = 0.303931 (* 1 = 0.303931 loss)
I1112 17:27:19.850929  3366 sgd_solver.cpp:106] Iteration 2613, lr = 0.00360863
I1112 17:27:25.003567  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:27:47.033182  3366 solver.cpp:242] Iteration 2652 (1.43478 iter/s, 27.1819s/39 iter), loss = 0.37345
I1112 17:27:47.033242  3366 solver.cpp:261]     Train net output #0: loss = 0.386283 (* 1 = 0.386283 loss)
I1112 17:27:47.033260  3366 sgd_solver.cpp:106] Iteration 2652, lr = 0.00358786
I1112 17:28:14.707706  3366 solver.cpp:242] Iteration 2691 (1.40926 iter/s, 27.6741s/39 iter), loss = 0.367372
I1112 17:28:14.708632  3366 solver.cpp:261]     Train net output #0: loss = 0.336177 (* 1 = 0.336177 loss)
I1112 17:28:14.708652  3366 sgd_solver.cpp:106] Iteration 2691, lr = 0.00356709
I1112 17:28:41.850793  3366 solver.cpp:242] Iteration 2730 (1.4369 iter/s, 27.1418s/39 iter), loss = 0.411216
I1112 17:28:41.850872  3366 solver.cpp:261]     Train net output #0: loss = 0.420568 (* 1 = 0.420568 loss)
I1112 17:28:41.850891  3366 sgd_solver.cpp:106] Iteration 2730, lr = 0.00354633
I1112 17:29:09.052014  3366 solver.cpp:242] Iteration 2769 (1.43378 iter/s, 27.2008s/39 iter), loss = 0.379371
I1112 17:29:09.052402  3366 solver.cpp:261]     Train net output #0: loss = 0.395266 (* 1 = 0.395266 loss)
I1112 17:29:09.052422  3366 sgd_solver.cpp:106] Iteration 2769, lr = 0.00352556
I1112 17:29:36.794822  3366 solver.cpp:242] Iteration 2808 (1.40581 iter/s, 27.742s/39 iter), loss = 0.385222
I1112 17:29:36.794879  3366 solver.cpp:261]     Train net output #0: loss = 0.269463 (* 1 = 0.269463 loss)
I1112 17:29:36.794898  3366 sgd_solver.cpp:106] Iteration 2808, lr = 0.00350479
I1112 17:29:42.777271  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_2817.caffemodel
I1112 17:29:42.794440  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2817.solverstate
I1112 17:29:42.800670  3366 solver.cpp:362] Iteration 2817, Testing net (#0)
I1112 17:29:42.800710  3366 net.cpp:723] Ignoring source layer train-data
I1112 17:29:53.925566  3366 solver.cpp:429]     Test net output #0: accuracy = 0.815665
I1112 17:29:53.925622  3366 solver.cpp:429]     Test net output #1: loss = 0.404507 (* 1 = 0.404507 loss)
I1112 17:30:15.519498  3366 solver.cpp:242] Iteration 2847 (1.00713 iter/s, 38.7241s/39 iter), loss = 0.411777
I1112 17:30:15.521208  3366 solver.cpp:261]     Train net output #0: loss = 0.481531 (* 1 = 0.481531 loss)
I1112 17:30:15.521230  3366 sgd_solver.cpp:106] Iteration 2847, lr = 0.00348403
I1112 17:30:20.475774  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:30:43.269029  3366 solver.cpp:242] Iteration 2886 (1.40554 iter/s, 27.7474s/39 iter), loss = 0.49751
I1112 17:30:43.269099  3366 solver.cpp:261]     Train net output #0: loss = 0.385217 (* 1 = 0.385217 loss)
I1112 17:30:43.269119  3366 sgd_solver.cpp:106] Iteration 2886, lr = 0.00346326
I1112 17:31:10.470731  3366 solver.cpp:242] Iteration 2925 (1.43376 iter/s, 27.2012s/39 iter), loss = 0.383801
I1112 17:31:10.472033  3366 solver.cpp:261]     Train net output #0: loss = 0.392324 (* 1 = 0.392324 loss)
I1112 17:31:10.472054  3366 sgd_solver.cpp:106] Iteration 2925, lr = 0.00344249
I1112 17:31:38.144800  3366 solver.cpp:242] Iteration 2964 (1.40935 iter/s, 27.6724s/39 iter), loss = 0.423181
I1112 17:31:38.144861  3366 solver.cpp:261]     Train net output #0: loss = 0.419583 (* 1 = 0.419583 loss)
I1112 17:31:38.144881  3366 sgd_solver.cpp:106] Iteration 2964, lr = 0.00342173
I1112 17:32:05.234882  3366 solver.cpp:242] Iteration 3003 (1.43967 iter/s, 27.0896s/39 iter), loss = 0.338815
I1112 17:32:05.235929  3366 solver.cpp:261]     Train net output #0: loss = 0.463623 (* 1 = 0.463623 loss)
I1112 17:32:05.235950  3366 sgd_solver.cpp:106] Iteration 3003, lr = 0.00340096
I1112 17:32:32.150678  3366 solver.cpp:242] Iteration 3042 (1.44904 iter/s, 26.9144s/39 iter), loss = 0.460709
I1112 17:32:32.150751  3366 solver.cpp:261]     Train net output #0: loss = 0.311173 (* 1 = 0.311173 loss)
I1112 17:32:32.150770  3366 sgd_solver.cpp:106] Iteration 3042, lr = 0.00338019
I1112 17:32:59.787066  3366 solver.cpp:242] Iteration 3081 (1.41121 iter/s, 27.6359s/39 iter), loss = 0.295525
I1112 17:32:59.792508  3366 solver.cpp:261]     Train net output #0: loss = 0.264944 (* 1 = 0.264944 loss)
I1112 17:32:59.792542  3366 sgd_solver.cpp:106] Iteration 3081, lr = 0.00335942
I1112 17:33:16.260251  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:33:26.848862  3366 solver.cpp:242] Iteration 3120 (1.44146 iter/s, 27.056s/39 iter), loss = 0.451301
I1112 17:33:26.848923  3366 solver.cpp:261]     Train net output #0: loss = 0.443115 (* 1 = 0.443115 loss)
I1112 17:33:26.848942  3366 sgd_solver.cpp:106] Iteration 3120, lr = 0.00333866
I1112 17:33:33.311247  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_3130.caffemodel
I1112 17:33:33.339431  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3130.solverstate
I1112 17:33:33.345746  3366 solver.cpp:362] Iteration 3130, Testing net (#0)
I1112 17:33:33.345787  3366 net.cpp:723] Ignoring source layer train-data
I1112 17:33:44.496335  3366 solver.cpp:429]     Test net output #0: accuracy = 0.819818
I1112 17:33:44.496383  3366 solver.cpp:429]     Test net output #1: loss = 0.386645 (* 1 = 0.386645 loss)
I1112 17:34:05.938016  3366 solver.cpp:242] Iteration 3159 (0.997735 iter/s, 39.0885s/39 iter), loss = 0.331084
I1112 17:34:05.945996  3366 solver.cpp:261]     Train net output #0: loss = 0.2985 (* 1 = 0.2985 loss)
I1112 17:34:05.946040  3366 sgd_solver.cpp:106] Iteration 3159, lr = 0.00331789
I1112 17:34:33.023367  3366 solver.cpp:242] Iteration 3198 (1.44034 iter/s, 27.077s/39 iter), loss = 0.42309
I1112 17:34:33.023432  3366 solver.cpp:261]     Train net output #0: loss = 0.44785 (* 1 = 0.44785 loss)
I1112 17:34:33.023452  3366 sgd_solver.cpp:106] Iteration 3198, lr = 0.00329712
I1112 17:35:00.515585  3366 solver.cpp:242] Iteration 3237 (1.41861 iter/s, 27.4918s/39 iter), loss = 0.425363
I1112 17:35:00.516036  3366 solver.cpp:261]     Train net output #0: loss = 0.283781 (* 1 = 0.283781 loss)
I1112 17:35:00.516057  3366 sgd_solver.cpp:106] Iteration 3237, lr = 0.00327636
I1112 17:35:27.789652  3366 solver.cpp:242] Iteration 3276 (1.42997 iter/s, 27.2732s/39 iter), loss = 0.387485
I1112 17:35:27.789716  3366 solver.cpp:261]     Train net output #0: loss = 0.419921 (* 1 = 0.419921 loss)
I1112 17:35:27.789734  3366 sgd_solver.cpp:106] Iteration 3276, lr = 0.00325559
I1112 17:35:54.962715  3366 solver.cpp:242] Iteration 3315 (1.43527 iter/s, 27.1726s/39 iter), loss = 0.400923
I1112 17:35:54.962846  3366 solver.cpp:261]     Train net output #0: loss = 0.342763 (* 1 = 0.342763 loss)
I1112 17:35:54.962863  3366 sgd_solver.cpp:106] Iteration 3315, lr = 0.00323482
I1112 17:36:12.441057  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:36:22.663035  3366 solver.cpp:242] Iteration 3354 (1.40795 iter/s, 27.6998s/39 iter), loss = 0.371062
I1112 17:36:22.663127  3366 solver.cpp:261]     Train net output #0: loss = 0.528135 (* 1 = 0.528135 loss)
I1112 17:36:22.663151  3366 sgd_solver.cpp:106] Iteration 3354, lr = 0.00321406
I1112 17:36:49.774809  3366 solver.cpp:242] Iteration 3393 (1.43851 iter/s, 27.1113s/39 iter), loss = 0.375271
I1112 17:36:49.775455  3366 solver.cpp:261]     Train net output #0: loss = 0.351895 (* 1 = 0.351895 loss)
I1112 17:36:49.775477  3366 sgd_solver.cpp:106] Iteration 3393, lr = 0.00319329
I1112 17:37:17.519278  3366 solver.cpp:242] Iteration 3432 (1.40577 iter/s, 27.7429s/39 iter), loss = 0.353675
I1112 17:37:17.519332  3366 solver.cpp:261]     Train net output #0: loss = 0.41811 (* 1 = 0.41811 loss)
I1112 17:37:17.519351  3366 sgd_solver.cpp:106] Iteration 3432, lr = 0.00317252
I1112 17:37:24.891232  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_3443.caffemodel
I1112 17:37:24.911136  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3443.solverstate
I1112 17:37:24.917577  3366 solver.cpp:362] Iteration 3443, Testing net (#0)
I1112 17:37:24.917609  3366 net.cpp:723] Ignoring source layer train-data
I1112 17:37:36.143877  3366 solver.cpp:429]     Test net output #0: accuracy = 0.827334
I1112 17:37:36.143942  3366 solver.cpp:429]     Test net output #1: loss = 0.373072 (* 1 = 0.373072 loss)
I1112 17:37:56.134950  3366 solver.cpp:242] Iteration 3471 (1.00997 iter/s, 38.6151s/39 iter), loss = 0.37509
I1112 17:37:56.135427  3366 solver.cpp:261]     Train net output #0: loss = 0.329729 (* 1 = 0.329729 loss)
I1112 17:37:56.135447  3366 sgd_solver.cpp:106] Iteration 3471, lr = 0.00315176
I1112 17:38:23.493402  3366 solver.cpp:242] Iteration 3510 (1.42556 iter/s, 27.3576s/39 iter), loss = 0.380983
I1112 17:38:23.493458  3366 solver.cpp:261]     Train net output #0: loss = 0.324487 (* 1 = 0.324487 loss)
I1112 17:38:23.493476  3366 sgd_solver.cpp:106] Iteration 3510, lr = 0.00313099
I1112 17:38:51.155544  3366 solver.cpp:242] Iteration 3549 (1.40989 iter/s, 27.6617s/39 iter), loss = 0.355253
I1112 17:38:51.159708  3366 solver.cpp:261]     Train net output #0: loss = 0.26479 (* 1 = 0.26479 loss)
I1112 17:38:51.159740  3366 sgd_solver.cpp:106] Iteration 3549, lr = 0.00311022
I1112 17:39:08.285372  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:39:18.472326  3366 solver.cpp:242] Iteration 3588 (1.42793 iter/s, 27.3122s/39 iter), loss = 0.346285
I1112 17:39:18.472384  3366 solver.cpp:261]     Train net output #0: loss = 0.418127 (* 1 = 0.418127 loss)
I1112 17:39:18.472403  3366 sgd_solver.cpp:106] Iteration 3588, lr = 0.00308946
I1112 17:39:46.105135  3366 solver.cpp:242] Iteration 3627 (1.41139 iter/s, 27.6324s/39 iter), loss = 0.342799
I1112 17:39:46.106758  3366 solver.cpp:261]     Train net output #0: loss = 0.411383 (* 1 = 0.411383 loss)
I1112 17:39:46.106780  3366 sgd_solver.cpp:106] Iteration 3627, lr = 0.00306869
I1112 17:40:13.385773  3366 solver.cpp:242] Iteration 3666 (1.42969 iter/s, 27.2786s/39 iter), loss = 0.297011
I1112 17:40:13.385840  3366 solver.cpp:261]     Train net output #0: loss = 0.350811 (* 1 = 0.350811 loss)
I1112 17:40:13.385859  3366 sgd_solver.cpp:106] Iteration 3666, lr = 0.00304792
I1112 17:40:40.370123  3366 solver.cpp:242] Iteration 3705 (1.44531 iter/s, 26.9839s/39 iter), loss = 0.378289
I1112 17:40:40.370249  3366 solver.cpp:261]     Train net output #0: loss = 0.370942 (* 1 = 0.370942 loss)
I1112 17:40:40.370272  3366 sgd_solver.cpp:106] Iteration 3705, lr = 0.00302716
I1112 17:41:08.300752  3366 solver.cpp:242] Iteration 3744 (1.39634 iter/s, 27.9301s/39 iter), loss = 0.288051
I1112 17:41:08.300814  3366 solver.cpp:261]     Train net output #0: loss = 0.164515 (* 1 = 0.164515 loss)
I1112 17:41:08.300832  3366 sgd_solver.cpp:106] Iteration 3744, lr = 0.00300639
I1112 17:41:16.327651  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_3756.caffemodel
I1112 17:41:16.350419  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3756.solverstate
I1112 17:41:16.358556  3366 solver.cpp:362] Iteration 3756, Testing net (#0)
I1112 17:41:16.358589  3366 net.cpp:723] Ignoring source layer train-data
I1112 17:41:27.485918  3366 solver.cpp:429]     Test net output #0: accuracy = 0.836432
I1112 17:41:27.485971  3366 solver.cpp:429]     Test net output #1: loss = 0.361044 (* 1 = 0.361044 loss)
I1112 17:41:46.780364  3366 solver.cpp:242] Iteration 3783 (1.01354 iter/s, 38.479s/39 iter), loss = 0.363203
I1112 17:41:46.782447  3366 solver.cpp:261]     Train net output #0: loss = 0.390673 (* 1 = 0.390673 loss)
I1112 17:41:46.782481  3366 sgd_solver.cpp:106] Iteration 3783, lr = 0.00298562
I1112 17:42:04.713738  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:42:14.350811  3366 solver.cpp:242] Iteration 3822 (1.41468 iter/s, 27.568s/39 iter), loss = 0.325244
I1112 17:42:14.350874  3366 solver.cpp:261]     Train net output #0: loss = 0.292595 (* 1 = 0.292595 loss)
I1112 17:42:14.350893  3366 sgd_solver.cpp:106] Iteration 3822, lr = 0.00296486
I1112 17:42:41.539383  3366 solver.cpp:242] Iteration 3861 (1.43445 iter/s, 27.1881s/39 iter), loss = 0.304291
I1112 17:42:41.541687  3366 solver.cpp:261]     Train net output #0: loss = 0.371643 (* 1 = 0.371643 loss)
I1112 17:42:41.541712  3366 sgd_solver.cpp:106] Iteration 3861, lr = 0.00294409
I1112 17:43:09.278777  3366 solver.cpp:242] Iteration 3900 (1.40608 iter/s, 27.7367s/39 iter), loss = 0.338625
I1112 17:43:09.278838  3366 solver.cpp:261]     Train net output #0: loss = 0.543458 (* 1 = 0.543458 loss)
I1112 17:43:09.278856  3366 sgd_solver.cpp:106] Iteration 3900, lr = 0.00292332
I1112 17:43:36.382616  3366 solver.cpp:242] Iteration 3939 (1.43893 iter/s, 27.1034s/39 iter), loss = 0.298708
I1112 17:43:36.388370  3366 solver.cpp:261]     Train net output #0: loss = 0.340806 (* 1 = 0.340806 loss)
I1112 17:43:36.388401  3366 sgd_solver.cpp:106] Iteration 3939, lr = 0.00290256
I1112 17:44:03.442019  3366 solver.cpp:242] Iteration 3978 (1.4416 iter/s, 27.0533s/39 iter), loss = 0.275234
I1112 17:44:03.442076  3366 solver.cpp:261]     Train net output #0: loss = 0.372465 (* 1 = 0.372465 loss)
I1112 17:44:03.442093  3366 sgd_solver.cpp:106] Iteration 3978, lr = 0.00288179
I1112 17:44:31.065385  3366 solver.cpp:242] Iteration 4017 (1.41187 iter/s, 27.6229s/39 iter), loss = 0.290725
I1112 17:44:31.073985  3366 solver.cpp:261]     Train net output #0: loss = 0.325419 (* 1 = 0.325419 loss)
I1112 17:44:31.074023  3366 sgd_solver.cpp:106] Iteration 4017, lr = 0.00286102
I1112 17:44:58.405170  3366 solver.cpp:242] Iteration 4056 (1.42696 iter/s, 27.3308s/39 iter), loss = 0.240493
I1112 17:44:58.405236  3366 solver.cpp:261]     Train net output #0: loss = 0.266022 (* 1 = 0.266022 loss)
I1112 17:44:58.405253  3366 sgd_solver.cpp:106] Iteration 4056, lr = 0.00284026
I1112 17:45:01.937257  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:45:06.903403  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_4069.caffemodel
I1112 17:45:06.924516  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4069.solverstate
I1112 17:45:06.939951  3366 solver.cpp:362] Iteration 4069, Testing net (#0)
I1112 17:45:06.939982  3366 net.cpp:723] Ignoring source layer train-data
I1112 17:45:18.045584  3366 solver.cpp:429]     Test net output #0: accuracy = 0.825356
I1112 17:45:18.045632  3366 solver.cpp:429]     Test net output #1: loss = 0.380852 (* 1 = 0.380852 loss)
I1112 17:45:37.579502  3366 solver.cpp:242] Iteration 4095 (0.995566 iter/s, 39.1737s/39 iter), loss = 0.282651
I1112 17:45:37.581351  3366 solver.cpp:261]     Train net output #0: loss = 0.31109 (* 1 = 0.31109 loss)
I1112 17:45:37.581378  3366 sgd_solver.cpp:106] Iteration 4095, lr = 0.00281949
I1112 17:46:04.680950  3366 solver.cpp:242] Iteration 4134 (1.43916 iter/s, 27.0992s/39 iter), loss = 0.419556
I1112 17:46:04.681011  3366 solver.cpp:261]     Train net output #0: loss = 0.382445 (* 1 = 0.382445 loss)
I1112 17:46:04.681030  3366 sgd_solver.cpp:106] Iteration 4134, lr = 0.00279872
I1112 17:46:32.139128  3366 solver.cpp:242] Iteration 4173 (1.42037 iter/s, 27.4577s/39 iter), loss = 0.301306
I1112 17:46:32.140406  3366 solver.cpp:261]     Train net output #0: loss = 0.3726 (* 1 = 0.3726 loss)
I1112 17:46:32.140429  3366 sgd_solver.cpp:106] Iteration 4173, lr = 0.00277796
I1112 17:46:59.507565  3366 solver.cpp:242] Iteration 4212 (1.42509 iter/s, 27.3668s/39 iter), loss = 0.245776
I1112 17:46:59.507633  3366 solver.cpp:261]     Train net output #0: loss = 0.275678 (* 1 = 0.275678 loss)
I1112 17:46:59.507653  3366 sgd_solver.cpp:106] Iteration 4212, lr = 0.00275719
I1112 17:47:26.721537  3366 solver.cpp:242] Iteration 4251 (1.43311 iter/s, 27.2135s/39 iter), loss = 0.281948
I1112 17:47:26.723793  3366 solver.cpp:261]     Train net output #0: loss = 0.2961 (* 1 = 0.2961 loss)
I1112 17:47:26.723816  3366 sgd_solver.cpp:106] Iteration 4251, lr = 0.00273642
I1112 17:47:54.290751  3366 solver.cpp:242] Iteration 4290 (1.41476 iter/s, 27.5666s/39 iter), loss = 0.262994
I1112 17:47:54.290834  3366 solver.cpp:261]     Train net output #0: loss = 0.309814 (* 1 = 0.309814 loss)
I1112 17:47:54.290858  3366 sgd_solver.cpp:106] Iteration 4290, lr = 0.00271565
I1112 17:47:58.155742  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:48:21.611435  3366 solver.cpp:242] Iteration 4329 (1.42751 iter/s, 27.3202s/39 iter), loss = 0.222162
I1112 17:48:21.611497  3366 solver.cpp:261]     Train net output #0: loss = 0.163289 (* 1 = 0.163289 loss)
I1112 17:48:21.611516  3366 sgd_solver.cpp:106] Iteration 4329, lr = 0.00269489
I1112 17:48:49.081313  3366 solver.cpp:242] Iteration 4368 (1.41976 iter/s, 27.4694s/39 iter), loss = 0.235693
I1112 17:48:49.081429  3366 solver.cpp:261]     Train net output #0: loss = 0.264877 (* 1 = 0.264877 loss)
I1112 17:48:49.081449  3366 sgd_solver.cpp:106] Iteration 4368, lr = 0.00267412
I1112 17:48:58.708796  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_4382.caffemodel
I1112 17:48:58.724030  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4382.solverstate
I1112 17:48:58.738335  3366 solver.cpp:362] Iteration 4382, Testing net (#0)
I1112 17:48:58.738371  3366 net.cpp:723] Ignoring source layer train-data
I1112 17:49:10.413898  3366 solver.cpp:429]     Test net output #0: accuracy = 0.851859
I1112 17:49:10.413956  3366 solver.cpp:429]     Test net output #1: loss = 0.338813 (* 1 = 0.338813 loss)
I1112 17:49:28.554658  3366 solver.cpp:242] Iteration 4407 (0.988025 iter/s, 39.4727s/39 iter), loss = 0.212935
I1112 17:49:28.556999  3366 solver.cpp:261]     Train net output #0: loss = 0.158597 (* 1 = 0.158597 loss)
I1112 17:49:28.557024  3366 sgd_solver.cpp:106] Iteration 4407, lr = 0.00265335
I1112 17:49:55.651214  3366 solver.cpp:242] Iteration 4446 (1.43944 iter/s, 27.0938s/39 iter), loss = 0.236759
I1112 17:49:55.651288  3366 solver.cpp:261]     Train net output #0: loss = 0.260342 (* 1 = 0.260342 loss)
I1112 17:49:55.651306  3366 sgd_solver.cpp:106] Iteration 4446, lr = 0.00263259
I1112 17:50:23.305645  3366 solver.cpp:242] Iteration 4485 (1.41029 iter/s, 27.654s/39 iter), loss = 0.234695
I1112 17:50:23.308869  3366 solver.cpp:261]     Train net output #0: loss = 0.219527 (* 1 = 0.219527 loss)
I1112 17:50:23.308894  3366 sgd_solver.cpp:106] Iteration 4485, lr = 0.00261182
I1112 17:50:50.419975  3366 solver.cpp:242] Iteration 4524 (1.43855 iter/s, 27.1107s/39 iter), loss = 0.202492
I1112 17:50:50.420037  3366 solver.cpp:261]     Train net output #0: loss = 0.185876 (* 1 = 0.185876 loss)
I1112 17:50:50.420055  3366 sgd_solver.cpp:106] Iteration 4524, lr = 0.00259105
I1112 17:50:54.003697  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:51:18.219422  3366 solver.cpp:242] Iteration 4563 (1.40293 iter/s, 27.799s/39 iter), loss = 0.237221
I1112 17:51:18.219483  3366 solver.cpp:261]     Train net output #0: loss = 0.258633 (* 1 = 0.258633 loss)
I1112 17:51:18.219502  3366 sgd_solver.cpp:106] Iteration 4563, lr = 0.00257029
I1112 17:51:45.560415  3366 solver.cpp:242] Iteration 4602 (1.42645 iter/s, 27.3405s/39 iter), loss = 0.236891
I1112 17:51:45.561400  3366 solver.cpp:261]     Train net output #0: loss = 0.204344 (* 1 = 0.204344 loss)
I1112 17:51:45.561420  3366 sgd_solver.cpp:106] Iteration 4602, lr = 0.00254952
I1112 17:52:12.528380  3366 solver.cpp:242] Iteration 4641 (1.44623 iter/s, 26.9666s/39 iter), loss = 0.198803
I1112 17:52:12.528439  3366 solver.cpp:261]     Train net output #0: loss = 0.164848 (* 1 = 0.164848 loss)
I1112 17:52:12.528456  3366 sgd_solver.cpp:106] Iteration 4641, lr = 0.00252875
I1112 17:52:40.201481  3366 solver.cpp:242] Iteration 4680 (1.40933 iter/s, 27.6727s/39 iter), loss = 0.210098
I1112 17:52:40.202363  3366 solver.cpp:261]     Train net output #0: loss = 0.229052 (* 1 = 0.229052 loss)
I1112 17:52:40.202383  3366 sgd_solver.cpp:106] Iteration 4680, lr = 0.00250799
I1112 17:52:50.148794  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_4695.caffemodel
I1112 17:52:50.163725  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4695.solverstate
I1112 17:52:50.170177  3366 solver.cpp:362] Iteration 4695, Testing net (#0)
I1112 17:52:50.170210  3366 net.cpp:723] Ignoring source layer train-data
I1112 17:53:01.301147  3366 solver.cpp:429]     Test net output #0: accuracy = 0.858188
I1112 17:53:01.301209  3366 solver.cpp:429]     Test net output #1: loss = 0.320235 (* 1 = 0.320235 loss)
I1112 17:53:18.708452  3366 solver.cpp:242] Iteration 4719 (1.01284 iter/s, 38.5056s/39 iter), loss = 0.220553
I1112 17:53:18.709153  3366 solver.cpp:261]     Train net output #0: loss = 0.206653 (* 1 = 0.206653 loss)
I1112 17:53:18.709175  3366 sgd_solver.cpp:106] Iteration 4719, lr = 0.00248722
I1112 17:53:46.416390  3366 solver.cpp:242] Iteration 4758 (1.40759 iter/s, 27.7068s/39 iter), loss = 0.19026
I1112 17:53:46.416448  3366 solver.cpp:261]     Train net output #0: loss = 0.281457 (* 1 = 0.281457 loss)
I1112 17:53:46.416466  3366 sgd_solver.cpp:106] Iteration 4758, lr = 0.00246645
I1112 17:53:50.170270  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:54:13.698041  3366 solver.cpp:242] Iteration 4797 (1.42956 iter/s, 27.2812s/39 iter), loss = 0.207505
I1112 17:54:13.698101  3366 solver.cpp:261]     Train net output #0: loss = 0.177914 (* 1 = 0.177914 loss)
I1112 17:54:13.698119  3366 sgd_solver.cpp:106] Iteration 4797, lr = 0.00244569
I1112 17:54:41.304963  3366 solver.cpp:242] Iteration 4836 (1.41271 iter/s, 27.6065s/39 iter), loss = 0.223335
I1112 17:54:41.305981  3366 solver.cpp:261]     Train net output #0: loss = 0.343788 (* 1 = 0.343788 loss)
I1112 17:54:41.306001  3366 sgd_solver.cpp:106] Iteration 4836, lr = 0.00242492
I1112 17:55:08.925411  3366 solver.cpp:242] Iteration 4875 (1.41207 iter/s, 27.619s/39 iter), loss = 0.228159
I1112 17:55:08.925473  3366 solver.cpp:261]     Train net output #0: loss = 0.224943 (* 1 = 0.224943 loss)
I1112 17:55:08.925492  3366 sgd_solver.cpp:106] Iteration 4875, lr = 0.00240415
I1112 17:55:36.214601  3366 solver.cpp:242] Iteration 4914 (1.42916 iter/s, 27.2887s/39 iter), loss = 0.178872
I1112 17:55:36.214720  3366 solver.cpp:261]     Train net output #0: loss = 0.170623 (* 1 = 0.170623 loss)
I1112 17:55:36.214738  3366 sgd_solver.cpp:106] Iteration 4914, lr = 0.00238339
I1112 17:56:03.791478  3366 solver.cpp:242] Iteration 4953 (1.41425 iter/s, 27.5764s/39 iter), loss = 0.286367
I1112 17:56:03.791545  3366 solver.cpp:261]     Train net output #0: loss = 0.209262 (* 1 = 0.209262 loss)
I1112 17:56:03.791564  3366 sgd_solver.cpp:106] Iteration 4953, lr = 0.00236262
I1112 17:56:31.104207  3366 solver.cpp:242] Iteration 4992 (1.42793 iter/s, 27.3123s/39 iter), loss = 0.154869
I1112 17:56:31.105468  3366 solver.cpp:261]     Train net output #0: loss = 0.127704 (* 1 = 0.127704 loss)
I1112 17:56:31.105487  3366 sgd_solver.cpp:106] Iteration 4992, lr = 0.00234185
I1112 17:56:41.731209  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_5008.caffemodel
I1112 17:56:41.746618  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5008.solverstate
I1112 17:56:41.753005  3366 solver.cpp:362] Iteration 5008, Testing net (#0)
I1112 17:56:41.753049  3366 net.cpp:723] Ignoring source layer train-data
I1112 17:56:45.826835  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:56:53.083781  3366 solver.cpp:429]     Test net output #0: accuracy = 0.87678
I1112 17:56:53.083827  3366 solver.cpp:429]     Test net output #1: loss = 0.278154 (* 1 = 0.278154 loss)
I1112 17:57:10.455471  3366 solver.cpp:242] Iteration 5031 (0.991119 iter/s, 39.3495s/39 iter), loss = 0.273936
I1112 17:57:10.456418  3366 solver.cpp:261]     Train net output #0: loss = 0.158505 (* 1 = 0.158505 loss)
I1112 17:57:10.456437  3366 sgd_solver.cpp:106] Iteration 5031, lr = 0.00232109
I1112 17:57:37.703624  3366 solver.cpp:242] Iteration 5070 (1.43136 iter/s, 27.2468s/39 iter), loss = 0.20048
I1112 17:57:37.703687  3366 solver.cpp:261]     Train net output #0: loss = 0.174723 (* 1 = 0.174723 loss)
I1112 17:57:37.703706  3366 sgd_solver.cpp:106] Iteration 5070, lr = 0.00230032
I1112 17:58:05.307390  3366 solver.cpp:242] Iteration 5109 (1.41287 iter/s, 27.6033s/39 iter), loss = 0.302927
I1112 17:58:05.309227  3366 solver.cpp:261]     Train net output #0: loss = 0.218788 (* 1 = 0.218788 loss)
I1112 17:58:05.309252  3366 sgd_solver.cpp:106] Iteration 5109, lr = 0.00227955
I1112 17:58:32.801978  3366 solver.cpp:242] Iteration 5148 (1.41858 iter/s, 27.4924s/39 iter), loss = 0.15475
I1112 17:58:32.802043  3366 solver.cpp:261]     Train net output #0: loss = 0.210781 (* 1 = 0.210781 loss)
I1112 17:58:32.802062  3366 sgd_solver.cpp:106] Iteration 5148, lr = 0.00225879
I1112 17:58:59.989732  3366 solver.cpp:242] Iteration 5187 (1.43449 iter/s, 27.1873s/39 iter), loss = 0.280067
I1112 17:58:59.989851  3366 solver.cpp:261]     Train net output #0: loss = 0.256278 (* 1 = 0.256278 loss)
I1112 17:58:59.989869  3366 sgd_solver.cpp:106] Iteration 5187, lr = 0.00223802
I1112 17:59:27.687453  3366 solver.cpp:242] Iteration 5226 (1.40808 iter/s, 27.6972s/39 iter), loss = 0.181868
I1112 17:59:27.687543  3366 solver.cpp:261]     Train net output #0: loss = 0.1644 (* 1 = 0.1644 loss)
I1112 17:59:27.687562  3366 sgd_solver.cpp:106] Iteration 5226, lr = 0.00221725
I1112 17:59:42.984459  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 17:59:54.927103  3366 solver.cpp:242] Iteration 5265 (1.43182 iter/s, 27.238s/39 iter), loss = 0.264136
I1112 17:59:54.927166  3366 solver.cpp:261]     Train net output #0: loss = 0.223937 (* 1 = 0.223937 loss)
I1112 17:59:54.927184  3366 sgd_solver.cpp:106] Iteration 5265, lr = 0.00219649
I1112 18:00:22.353997  3366 solver.cpp:242] Iteration 5304 (1.42199 iter/s, 27.4264s/39 iter), loss = 0.199642
I1112 18:00:22.358006  3366 solver.cpp:261]     Train net output #0: loss = 0.108705 (* 1 = 0.108705 loss)
I1112 18:00:22.358049  3366 sgd_solver.cpp:106] Iteration 5304, lr = 0.00217572
I1112 18:00:33.903403  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_5321.caffemodel
I1112 18:00:33.934002  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5321.solverstate
I1112 18:00:33.940153  3366 solver.cpp:362] Iteration 5321, Testing net (#0)
I1112 18:00:33.940186  3366 net.cpp:723] Ignoring source layer train-data
I1112 18:00:45.317343  3366 solver.cpp:429]     Test net output #0: accuracy = 0.894581
I1112 18:00:45.317389  3366 solver.cpp:429]     Test net output #1: loss = 0.25285 (* 1 = 0.25285 loss)
I1112 18:01:01.411684  3366 solver.cpp:242] Iteration 5343 (0.998639 iter/s, 39.0532s/39 iter), loss = 0.25957
I1112 18:01:01.417995  3366 solver.cpp:261]     Train net output #0: loss = 0.178725 (* 1 = 0.178725 loss)
I1112 18:01:01.418033  3366 sgd_solver.cpp:106] Iteration 5343, lr = 0.00215495
I1112 18:01:28.355545  3366 solver.cpp:242] Iteration 5382 (1.44781 iter/s, 26.9372s/39 iter), loss = 0.190894
I1112 18:01:28.355604  3366 solver.cpp:261]     Train net output #0: loss = 0.161959 (* 1 = 0.161959 loss)
I1112 18:01:28.355623  3366 sgd_solver.cpp:106] Iteration 5382, lr = 0.00213419
I1112 18:01:56.000193  3366 solver.cpp:242] Iteration 5421 (1.41078 iter/s, 27.6442s/39 iter), loss = 0.239367
I1112 18:01:56.000350  3366 solver.cpp:261]     Train net output #0: loss = 0.324066 (* 1 = 0.324066 loss)
I1112 18:01:56.000370  3366 sgd_solver.cpp:106] Iteration 5421, lr = 0.00211342
I1112 18:02:23.218369  3366 solver.cpp:242] Iteration 5460 (1.43289 iter/s, 27.2176s/39 iter), loss = 0.241422
I1112 18:02:23.218432  3366 solver.cpp:261]     Train net output #0: loss = 0.297513 (* 1 = 0.297513 loss)
I1112 18:02:23.218451  3366 sgd_solver.cpp:106] Iteration 5460, lr = 0.00209265
I1112 18:02:38.277869  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:02:51.170290  3366 solver.cpp:242] Iteration 5499 (1.39528 iter/s, 27.9515s/39 iter), loss = 0.239579
I1112 18:02:51.170353  3366 solver.cpp:261]     Train net output #0: loss = 0.367866 (* 1 = 0.367866 loss)
I1112 18:02:51.170372  3366 sgd_solver.cpp:106] Iteration 5499, lr = 0.00207188
I1112 18:03:18.584049  3366 solver.cpp:242] Iteration 5538 (1.42267 iter/s, 27.4133s/39 iter), loss = 0.196184
I1112 18:03:18.584161  3366 solver.cpp:261]     Train net output #0: loss = 0.211534 (* 1 = 0.211534 loss)
I1112 18:03:18.584178  3366 sgd_solver.cpp:106] Iteration 5538, lr = 0.00205112
I1112 18:03:45.771627  3366 solver.cpp:242] Iteration 5577 (1.4345 iter/s, 27.1871s/39 iter), loss = 0.159677
I1112 18:03:45.771689  3366 solver.cpp:261]     Train net output #0: loss = 0.179919 (* 1 = 0.179919 loss)
I1112 18:03:45.771708  3366 sgd_solver.cpp:106] Iteration 5577, lr = 0.00203035
I1112 18:04:13.396821  3366 solver.cpp:242] Iteration 5616 (1.41178 iter/s, 27.6247s/39 iter), loss = 0.222036
I1112 18:04:13.397362  3366 solver.cpp:261]     Train net output #0: loss = 0.138066 (* 1 = 0.138066 loss)
I1112 18:04:13.397382  3366 sgd_solver.cpp:106] Iteration 5616, lr = 0.00200958
I1112 18:04:25.508910  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_5634.caffemodel
I1112 18:04:25.542906  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5634.solverstate
I1112 18:04:25.554337  3366 solver.cpp:362] Iteration 5634, Testing net (#0)
I1112 18:04:25.554375  3366 net.cpp:723] Ignoring source layer train-data
I1112 18:04:36.665541  3366 solver.cpp:429]     Test net output #0: accuracy = 0.884296
I1112 18:04:36.665593  3366 solver.cpp:429]     Test net output #1: loss = 0.26033 (* 1 = 0.26033 loss)
I1112 18:04:51.878926  3366 solver.cpp:242] Iteration 5655 (1.01349 iter/s, 38.481s/39 iter), loss = 0.203893
I1112 18:04:51.879112  3366 solver.cpp:261]     Train net output #0: loss = 0.194432 (* 1 = 0.194432 loss)
I1112 18:04:51.879130  3366 sgd_solver.cpp:106] Iteration 5655, lr = 0.00198882
I1112 18:05:19.707634  3366 solver.cpp:242] Iteration 5694 (1.40146 iter/s, 27.8281s/39 iter), loss = 0.237981
I1112 18:05:19.707695  3366 solver.cpp:261]     Train net output #0: loss = 0.156734 (* 1 = 0.156734 loss)
I1112 18:05:19.707712  3366 sgd_solver.cpp:106] Iteration 5694, lr = 0.00196805
I1112 18:05:35.479439  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:05:46.990825  3366 solver.cpp:242] Iteration 5733 (1.42948 iter/s, 27.2827s/39 iter), loss = 0.18557
I1112 18:05:46.990895  3366 solver.cpp:261]     Train net output #0: loss = 0.121857 (* 1 = 0.121857 loss)
I1112 18:05:46.990916  3366 sgd_solver.cpp:106] Iteration 5733, lr = 0.00194728
I1112 18:06:14.577982  3366 solver.cpp:242] Iteration 5772 (1.41373 iter/s, 27.5867s/39 iter), loss = 0.188824
I1112 18:06:14.578330  3366 solver.cpp:261]     Train net output #0: loss = 0.253978 (* 1 = 0.253978 loss)
I1112 18:06:14.578351  3366 sgd_solver.cpp:106] Iteration 5772, lr = 0.00192652
I1112 18:06:42.073987  3366 solver.cpp:242] Iteration 5811 (1.41843 iter/s, 27.4953s/39 iter), loss = 0.179627
I1112 18:06:42.074048  3366 solver.cpp:261]     Train net output #0: loss = 0.189015 (* 1 = 0.189015 loss)
I1112 18:06:42.074065  3366 sgd_solver.cpp:106] Iteration 5811, lr = 0.00190575
I1112 18:07:09.165988  3366 solver.cpp:242] Iteration 5850 (1.43956 iter/s, 27.0916s/39 iter), loss = 0.181445
I1112 18:07:09.166100  3366 solver.cpp:261]     Train net output #0: loss = 0.236495 (* 1 = 0.236495 loss)
I1112 18:07:09.166117  3366 sgd_solver.cpp:106] Iteration 5850, lr = 0.00188498
I1112 18:07:36.929980  3366 solver.cpp:242] Iteration 5889 (1.40472 iter/s, 27.7635s/39 iter), loss = 0.173946
I1112 18:07:36.930044  3366 solver.cpp:261]     Train net output #0: loss = 0.254372 (* 1 = 0.254372 loss)
I1112 18:07:36.930063  3366 sgd_solver.cpp:106] Iteration 5889, lr = 0.00186422
I1112 18:08:04.074928  3366 solver.cpp:242] Iteration 5928 (1.43676 iter/s, 27.1445s/39 iter), loss = 0.160551
I1112 18:08:04.076267  3366 solver.cpp:261]     Train net output #0: loss = 0.178848 (* 1 = 0.178848 loss)
I1112 18:08:04.076287  3366 sgd_solver.cpp:106] Iteration 5928, lr = 0.00184345
I1112 18:08:16.704993  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_5947.caffemodel
I1112 18:08:16.726447  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5947.solverstate
I1112 18:08:16.732766  3366 solver.cpp:362] Iteration 5947, Testing net (#0)
I1112 18:08:16.732798  3366 net.cpp:723] Ignoring source layer train-data
I1112 18:08:27.841006  3366 solver.cpp:429]     Test net output #0: accuracy = 0.904866
I1112 18:08:27.841063  3366 solver.cpp:429]     Test net output #1: loss = 0.236864 (* 1 = 0.236864 loss)
I1112 18:08:31.454665  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:08:43.185989  3366 solver.cpp:242] Iteration 5967 (0.997209 iter/s, 39.1092s/39 iter), loss = 0.146501
I1112 18:08:43.186559  3366 solver.cpp:261]     Train net output #0: loss = 0.152065 (* 1 = 0.152065 loss)
I1112 18:08:43.186580  3366 sgd_solver.cpp:106] Iteration 5967, lr = 0.00182268
I1112 18:09:10.849879  3366 solver.cpp:242] Iteration 6006 (1.40983 iter/s, 27.6629s/39 iter), loss = 0.148002
I1112 18:09:10.858011  3366 solver.cpp:261]     Train net output #0: loss = 0.155558 (* 1 = 0.155558 loss)
I1112 18:09:10.858057  3366 sgd_solver.cpp:106] Iteration 6006, lr = 0.00180192
I1112 18:09:38.069525  3366 solver.cpp:242] Iteration 6045 (1.43324 iter/s, 27.2111s/39 iter), loss = 0.179383
I1112 18:09:38.076354  3366 solver.cpp:261]     Train net output #0: loss = 0.186313 (* 1 = 0.186313 loss)
I1112 18:09:38.076390  3366 sgd_solver.cpp:106] Iteration 6045, lr = 0.00178115
I1112 18:10:05.848017  3366 solver.cpp:242] Iteration 6084 (1.40433 iter/s, 27.7713s/39 iter), loss = 0.123427
I1112 18:10:05.848078  3366 solver.cpp:261]     Train net output #0: loss = 0.166246 (* 1 = 0.166246 loss)
I1112 18:10:05.848095  3366 sgd_solver.cpp:106] Iteration 6084, lr = 0.00176038
I1112 18:10:33.148188  3366 solver.cpp:242] Iteration 6123 (1.42859 iter/s, 27.2997s/39 iter), loss = 0.197029
I1112 18:10:33.150589  3366 solver.cpp:261]     Train net output #0: loss = 0.202032 (* 1 = 0.202032 loss)
I1112 18:10:33.150615  3366 sgd_solver.cpp:106] Iteration 6123, lr = 0.00173962
I1112 18:11:00.753980  3366 solver.cpp:242] Iteration 6162 (1.41289 iter/s, 27.603s/39 iter), loss = 0.167812
I1112 18:11:00.754046  3366 solver.cpp:261]     Train net output #0: loss = 0.214645 (* 1 = 0.214645 loss)
I1112 18:11:00.754065  3366 sgd_solver.cpp:106] Iteration 6162, lr = 0.00171885
I1112 18:11:28.025801  3366 solver.cpp:242] Iteration 6201 (1.43007 iter/s, 27.2714s/39 iter), loss = 0.171753
I1112 18:11:28.033984  3366 solver.cpp:261]     Train net output #0: loss = 0.0961953 (* 1 = 0.0961953 loss)
I1112 18:11:28.034024  3366 sgd_solver.cpp:106] Iteration 6201, lr = 0.00169808
I1112 18:11:29.644858  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:11:55.008186  3366 solver.cpp:242] Iteration 6240 (1.44585 iter/s, 26.9738s/39 iter), loss = 0.157509
I1112 18:11:55.008251  3366 solver.cpp:261]     Train net output #0: loss = 0.165081 (* 1 = 0.165081 loss)
I1112 18:11:55.008270  3366 sgd_solver.cpp:106] Iteration 6240, lr = 0.00167732
I1112 18:12:09.102763  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_6260.caffemodel
I1112 18:12:09.128146  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6260.solverstate
I1112 18:12:09.134667  3366 solver.cpp:362] Iteration 6260, Testing net (#0)
I1112 18:12:09.134694  3366 net.cpp:723] Ignoring source layer train-data
I1112 18:12:20.413233  3366 solver.cpp:429]     Test net output #0: accuracy = 0.908426
I1112 18:12:20.413285  3366 solver.cpp:429]     Test net output #1: loss = 0.217689 (* 1 = 0.217689 loss)
I1112 18:12:34.416929  3366 solver.cpp:242] Iteration 6279 (0.989644 iter/s, 39.4081s/39 iter), loss = 0.223649
I1112 18:12:34.416986  3366 solver.cpp:261]     Train net output #0: loss = 0.196737 (* 1 = 0.196737 loss)
I1112 18:12:34.417004  3366 sgd_solver.cpp:106] Iteration 6279, lr = 0.00165655
I1112 18:13:01.603297  3366 solver.cpp:242] Iteration 6318 (1.43457 iter/s, 27.1859s/39 iter), loss = 0.150741
I1112 18:13:01.609253  3366 solver.cpp:261]     Train net output #0: loss = 0.14694 (* 1 = 0.14694 loss)
I1112 18:13:01.609297  3366 sgd_solver.cpp:106] Iteration 6318, lr = 0.00163578
I1112 18:13:29.356194  3366 solver.cpp:242] Iteration 6357 (1.40558 iter/s, 27.7466s/39 iter), loss = 0.214944
I1112 18:13:29.356254  3366 solver.cpp:261]     Train net output #0: loss = 0.23382 (* 1 = 0.23382 loss)
I1112 18:13:29.356272  3366 sgd_solver.cpp:106] Iteration 6357, lr = 0.00161502
I1112 18:13:56.672895  3366 solver.cpp:242] Iteration 6396 (1.42772 iter/s, 27.3162s/39 iter), loss = 0.187642
I1112 18:13:56.673598  3366 solver.cpp:261]     Train net output #0: loss = 0.0955799 (* 1 = 0.0955799 loss)
I1112 18:13:56.673616  3366 sgd_solver.cpp:106] Iteration 6396, lr = 0.00159425
I1112 18:14:24.498370  3366 solver.cpp:242] Iteration 6435 (1.40165 iter/s, 27.8244s/39 iter), loss = 0.213587
I1112 18:14:24.498443  3366 solver.cpp:261]     Train net output #0: loss = 0.206269 (* 1 = 0.206269 loss)
I1112 18:14:24.498463  3366 sgd_solver.cpp:106] Iteration 6435, lr = 0.00157348
I1112 18:14:26.576644  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:14:51.914616  3366 solver.cpp:242] Iteration 6474 (1.42254 iter/s, 27.4158s/39 iter), loss = 0.214289
I1112 18:14:51.916817  3366 solver.cpp:261]     Train net output #0: loss = 0.191744 (* 1 = 0.191744 loss)
I1112 18:14:51.916846  3366 sgd_solver.cpp:106] Iteration 6474, lr = 0.00155272
I1112 18:15:19.118000  3366 solver.cpp:242] Iteration 6513 (1.43378 iter/s, 27.2008s/39 iter), loss = 0.202466
I1112 18:15:19.118084  3366 solver.cpp:261]     Train net output #0: loss = 0.116593 (* 1 = 0.116593 loss)
I1112 18:15:19.118105  3366 sgd_solver.cpp:106] Iteration 6513, lr = 0.00153195
I1112 18:15:46.747275  3366 solver.cpp:242] Iteration 6552 (1.41157 iter/s, 27.6288s/39 iter), loss = 0.213186
I1112 18:15:46.753975  3366 solver.cpp:261]     Train net output #0: loss = 0.143816 (* 1 = 0.143816 loss)
I1112 18:15:46.754010  3366 sgd_solver.cpp:106] Iteration 6552, lr = 0.00151118
I1112 18:16:00.892674  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_6573.caffemodel
I1112 18:16:00.906545  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6573.solverstate
I1112 18:16:00.912822  3366 solver.cpp:362] Iteration 6573, Testing net (#0)
I1112 18:16:00.912864  3366 net.cpp:723] Ignoring source layer train-data
I1112 18:16:12.054188  3366 solver.cpp:429]     Test net output #0: accuracy = 0.898932
I1112 18:16:12.054240  3366 solver.cpp:429]     Test net output #1: loss = 0.237265 (* 1 = 0.237265 loss)
I1112 18:16:25.185447  3366 solver.cpp:242] Iteration 6591 (1.01481 iter/s, 38.4309s/39 iter), loss = 0.235577
I1112 18:16:25.185945  3366 solver.cpp:261]     Train net output #0: loss = 0.0978638 (* 1 = 0.0978638 loss)
I1112 18:16:25.185964  3366 sgd_solver.cpp:106] Iteration 6591, lr = 0.00149042
I1112 18:16:52.891469  3366 solver.cpp:242] Iteration 6630 (1.40768 iter/s, 27.7051s/39 iter), loss = 0.1795
I1112 18:16:52.891542  3366 solver.cpp:261]     Train net output #0: loss = 0.0821243 (* 1 = 0.0821243 loss)
I1112 18:16:52.891562  3366 sgd_solver.cpp:106] Iteration 6630, lr = 0.00146965
I1112 18:17:20.093526  3366 solver.cpp:242] Iteration 6669 (1.43374 iter/s, 27.2016s/39 iter), loss = 0.214584
I1112 18:17:20.093634  3366 solver.cpp:261]     Train net output #0: loss = 0.147375 (* 1 = 0.147375 loss)
I1112 18:17:20.093652  3366 sgd_solver.cpp:106] Iteration 6669, lr = 0.00144888
I1112 18:17:22.951521  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:17:47.859753  3366 solver.cpp:242] Iteration 6708 (1.40461 iter/s, 27.7657s/39 iter), loss = 0.195578
I1112 18:17:47.859812  3366 solver.cpp:261]     Train net output #0: loss = 0.238463 (* 1 = 0.238463 loss)
I1112 18:17:47.859832  3366 sgd_solver.cpp:106] Iteration 6708, lr = 0.00142812
I1112 18:18:15.503468  3366 solver.cpp:242] Iteration 6747 (1.41083 iter/s, 27.6433s/39 iter), loss = 0.239288
I1112 18:18:15.506366  3366 solver.cpp:261]     Train net output #0: loss = 0.269819 (* 1 = 0.269819 loss)
I1112 18:18:15.506392  3366 sgd_solver.cpp:106] Iteration 6747, lr = 0.00140735
I1112 18:18:42.573900  3366 solver.cpp:242] Iteration 6786 (1.44086 iter/s, 27.0672s/39 iter), loss = 0.182905
I1112 18:18:42.573968  3366 solver.cpp:261]     Train net output #0: loss = 0.178447 (* 1 = 0.178447 loss)
I1112 18:18:42.573988  3366 sgd_solver.cpp:106] Iteration 6786, lr = 0.00138658
I1112 18:19:10.442327  3366 solver.cpp:242] Iteration 6825 (1.39946 iter/s, 27.868s/39 iter), loss = 0.203179
I1112 18:19:10.442450  3366 solver.cpp:261]     Train net output #0: loss = 0.250287 (* 1 = 0.250287 loss)
I1112 18:19:10.442468  3366 sgd_solver.cpp:106] Iteration 6825, lr = 0.00136581
I1112 18:19:37.891049  3366 solver.cpp:242] Iteration 6864 (1.42086 iter/s, 27.4482s/39 iter), loss = 0.166367
I1112 18:19:37.891110  3366 solver.cpp:261]     Train net output #0: loss = 0.235028 (* 1 = 0.235028 loss)
I1112 18:19:37.891129  3366 sgd_solver.cpp:106] Iteration 6864, lr = 0.00134505
I1112 18:19:52.566429  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_6886.caffemodel
I1112 18:19:52.586724  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6886.solverstate
I1112 18:19:52.592998  3366 solver.cpp:362] Iteration 6886, Testing net (#0)
I1112 18:19:52.593030  3366 net.cpp:723] Ignoring source layer train-data
I1112 18:20:03.785128  3366 solver.cpp:429]     Test net output #0: accuracy = 0.902097
I1112 18:20:03.785176  3366 solver.cpp:429]     Test net output #1: loss = 0.246784 (* 1 = 0.246784 loss)
I1112 18:20:16.952625  3366 solver.cpp:242] Iteration 6903 (0.998439 iter/s, 39.061s/39 iter), loss = 0.206357
I1112 18:20:16.952687  3366 solver.cpp:261]     Train net output #0: loss = 0.181158 (* 1 = 0.181158 loss)
I1112 18:20:16.952704  3366 sgd_solver.cpp:106] Iteration 6903, lr = 0.00132428
I1112 18:20:20.318035  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:20:44.127264  3366 solver.cpp:242] Iteration 6942 (1.43519 iter/s, 27.1742s/39 iter), loss = 0.168037
I1112 18:20:44.127456  3366 solver.cpp:261]     Train net output #0: loss = 0.218312 (* 1 = 0.218312 loss)
I1112 18:20:44.127501  3366 sgd_solver.cpp:106] Iteration 6942, lr = 0.00130351
I1112 18:21:11.414960  3366 solver.cpp:242] Iteration 6981 (1.42925 iter/s, 27.2871s/39 iter), loss = 0.18961
I1112 18:21:11.415024  3366 solver.cpp:261]     Train net output #0: loss = 0.224273 (* 1 = 0.224273 loss)
I1112 18:21:11.415041  3366 sgd_solver.cpp:106] Iteration 6981, lr = 0.00128275
I1112 18:21:39.125928  3366 solver.cpp:242] Iteration 7020 (1.40741 iter/s, 27.7105s/39 iter), loss = 0.179122
I1112 18:21:39.126256  3366 solver.cpp:261]     Train net output #0: loss = 0.171283 (* 1 = 0.171283 loss)
I1112 18:21:39.126274  3366 sgd_solver.cpp:106] Iteration 7020, lr = 0.00126198
I1112 18:22:06.420008  3366 solver.cpp:242] Iteration 7059 (1.42892 iter/s, 27.2934s/39 iter), loss = 0.203528
I1112 18:22:06.420073  3366 solver.cpp:261]     Train net output #0: loss = 0.229758 (* 1 = 0.229758 loss)
I1112 18:22:06.420090  3366 sgd_solver.cpp:106] Iteration 7059, lr = 0.00124121
I1112 18:22:34.401535  3366 solver.cpp:242] Iteration 7098 (1.3938 iter/s, 27.9811s/39 iter), loss = 0.153071
I1112 18:22:34.402983  3366 solver.cpp:261]     Train net output #0: loss = 0.141034 (* 1 = 0.141034 loss)
I1112 18:22:34.403005  3366 sgd_solver.cpp:106] Iteration 7098, lr = 0.00122045
I1112 18:23:01.785977  3366 solver.cpp:242] Iteration 7137 (1.42426 iter/s, 27.3826s/39 iter), loss = 0.17421
I1112 18:23:01.786046  3366 solver.cpp:261]     Train net output #0: loss = 0.207179 (* 1 = 0.207179 loss)
I1112 18:23:01.786067  3366 sgd_solver.cpp:106] Iteration 7137, lr = 0.00119968
I1112 18:23:17.200707  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:23:28.899168  3366 solver.cpp:242] Iteration 7176 (1.43844 iter/s, 27.1127s/39 iter), loss = 0.1688
I1112 18:23:28.899232  3366 solver.cpp:261]     Train net output #0: loss = 0.184552 (* 1 = 0.184552 loss)
I1112 18:23:28.899251  3366 sgd_solver.cpp:106] Iteration 7176, lr = 0.00117891
I1112 18:23:45.019490  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_7199.caffemodel
I1112 18:23:45.040385  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7199.solverstate
I1112 18:23:45.046702  3366 solver.cpp:362] Iteration 7199, Testing net (#0)
I1112 18:23:45.046730  3366 net.cpp:723] Ignoring source layer train-data
I1112 18:23:56.307317  3366 solver.cpp:429]     Test net output #0: accuracy = 0.915546
I1112 18:23:56.309828  3366 solver.cpp:429]     Test net output #1: loss = 0.21557 (* 1 = 0.21557 loss)
I1112 18:24:08.133980  3366 solver.cpp:242] Iteration 7215 (0.994031 iter/s, 39.2342s/39 iter), loss = 0.183378
I1112 18:24:08.134047  3366 solver.cpp:261]     Train net output #0: loss = 0.213443 (* 1 = 0.213443 loss)
I1112 18:24:08.134065  3366 sgd_solver.cpp:106] Iteration 7215, lr = 0.00115815
I1112 18:24:35.215507  3366 solver.cpp:242] Iteration 7254 (1.44012 iter/s, 27.0811s/39 iter), loss = 0.142486
I1112 18:24:35.215894  3366 solver.cpp:261]     Train net output #0: loss = 0.110478 (* 1 = 0.110478 loss)
I1112 18:24:35.215915  3366 sgd_solver.cpp:106] Iteration 7254, lr = 0.00113738
I1112 18:25:03.081799  3366 solver.cpp:242] Iteration 7293 (1.39958 iter/s, 27.8655s/39 iter), loss = 0.1645
I1112 18:25:03.081858  3366 solver.cpp:261]     Train net output #0: loss = 0.171129 (* 1 = 0.171129 loss)
I1112 18:25:03.081877  3366 sgd_solver.cpp:106] Iteration 7293, lr = 0.00111661
I1112 18:25:30.486312  3366 solver.cpp:242] Iteration 7332 (1.42315 iter/s, 27.4041s/39 iter), loss = 0.169188
I1112 18:25:30.486521  3366 solver.cpp:261]     Train net output #0: loss = 0.0968419 (* 1 = 0.0968419 loss)
I1112 18:25:30.486541  3366 sgd_solver.cpp:106] Iteration 7332, lr = 0.00109585
I1112 18:25:57.993196  3366 solver.cpp:242] Iteration 7371 (1.41786 iter/s, 27.5063s/39 iter), loss = 0.16239
I1112 18:25:57.993268  3366 solver.cpp:261]     Train net output #0: loss = 0.183862 (* 1 = 0.183862 loss)
I1112 18:25:57.993286  3366 sgd_solver.cpp:106] Iteration 7371, lr = 0.00107508
I1112 18:26:15.257297  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:26:25.514438  3366 solver.cpp:242] Iteration 7410 (1.41711 iter/s, 27.5208s/39 iter), loss = 0.1635
I1112 18:26:25.514503  3366 solver.cpp:261]     Train net output #0: loss = 0.168074 (* 1 = 0.168074 loss)
I1112 18:26:25.514520  3366 sgd_solver.cpp:106] Iteration 7410, lr = 0.00105431
I1112 18:26:52.758023  3366 solver.cpp:242] Iteration 7449 (1.43155 iter/s, 27.2431s/39 iter), loss = 0.189123
I1112 18:26:52.758144  3366 solver.cpp:261]     Train net output #0: loss = 0.117454 (* 1 = 0.117454 loss)
I1112 18:26:52.758163  3366 sgd_solver.cpp:106] Iteration 7449, lr = 0.00103355
I1112 18:27:20.624279  3366 solver.cpp:242] Iteration 7488 (1.39957 iter/s, 27.8657s/39 iter), loss = 0.162526
I1112 18:27:20.624346  3366 solver.cpp:261]     Train net output #0: loss = 0.195819 (* 1 = 0.195819 loss)
I1112 18:27:20.624363  3366 sgd_solver.cpp:106] Iteration 7488, lr = 0.00101278
I1112 18:27:36.936228  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_7512.caffemodel
I1112 18:27:36.956373  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7512.solverstate
I1112 18:27:36.972671  3366 solver.cpp:362] Iteration 7512, Testing net (#0)
I1112 18:27:36.972705  3366 net.cpp:723] Ignoring source layer train-data
I1112 18:27:48.053053  3366 solver.cpp:429]     Test net output #0: accuracy = 0.91693
I1112 18:27:48.053109  3366 solver.cpp:429]     Test net output #1: loss = 0.200854 (* 1 = 0.200854 loss)
I1112 18:27:59.287402  3366 solver.cpp:242] Iteration 7527 (1.00873 iter/s, 38.6625s/39 iter), loss = 0.158676
I1112 18:27:59.287472  3366 solver.cpp:261]     Train net output #0: loss = 0.154874 (* 1 = 0.154874 loss)
I1112 18:27:59.294652  3366 sgd_solver.cpp:106] Iteration 7527, lr = 0.000992013
I1112 18:28:27.056061  3366 solver.cpp:242] Iteration 7566 (1.40485 iter/s, 27.761s/39 iter), loss = 0.163114
I1112 18:28:27.056998  3366 solver.cpp:261]     Train net output #0: loss = 0.136428 (* 1 = 0.136428 loss)
I1112 18:28:27.057021  3366 sgd_solver.cpp:106] Iteration 7566, lr = 0.000971246
I1112 18:28:55.511667  3366 solver.cpp:242] Iteration 7605 (1.37062 iter/s, 28.4543s/39 iter), loss = 0.205123
I1112 18:28:55.511744  3366 solver.cpp:261]     Train net output #0: loss = 0.208382 (* 1 = 0.208382 loss)
I1112 18:28:55.511765  3366 sgd_solver.cpp:106] Iteration 7605, lr = 0.000950479
I1112 18:29:13.612121  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:29:23.613795  3366 solver.cpp:242] Iteration 7644 (1.38782 iter/s, 28.1016s/39 iter), loss = 0.166949
I1112 18:29:23.613883  3366 solver.cpp:261]     Train net output #0: loss = 0.116328 (* 1 = 0.116328 loss)
I1112 18:29:23.617466  3366 sgd_solver.cpp:106] Iteration 7644, lr = 0.000929712
I1112 18:29:50.767431  3366 solver.cpp:242] Iteration 7683 (1.4363 iter/s, 27.1532s/39 iter), loss = 0.181969
I1112 18:29:50.770640  3366 solver.cpp:261]     Train net output #0: loss = 0.156361 (* 1 = 0.156361 loss)
I1112 18:29:50.770663  3366 sgd_solver.cpp:106] Iteration 7683, lr = 0.000908946
I1112 18:30:18.200768  3366 solver.cpp:242] Iteration 7722 (1.42181 iter/s, 27.4297s/39 iter), loss = 0.151686
I1112 18:30:18.200839  3366 solver.cpp:261]     Train net output #0: loss = 0.155277 (* 1 = 0.155277 loss)
I1112 18:30:18.200857  3366 sgd_solver.cpp:106] Iteration 7722, lr = 0.000888179
I1112 18:30:46.090960  3366 solver.cpp:242] Iteration 7761 (1.39836 iter/s, 27.8897s/39 iter), loss = 0.165527
I1112 18:30:46.091780  3366 solver.cpp:261]     Train net output #0: loss = 0.158528 (* 1 = 0.158528 loss)
I1112 18:30:46.091802  3366 sgd_solver.cpp:106] Iteration 7761, lr = 0.000867412
I1112 18:31:13.331287  3366 solver.cpp:242] Iteration 7800 (1.43176 iter/s, 27.2391s/39 iter), loss = 0.152085
I1112 18:31:13.331346  3366 solver.cpp:261]     Train net output #0: loss = 0.15307 (* 1 = 0.15307 loss)
I1112 18:31:13.331364  3366 sgd_solver.cpp:106] Iteration 7800, lr = 0.000846645
I1112 18:31:30.560492  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_7825.caffemodel
I1112 18:31:30.593472  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7825.solverstate
I1112 18:31:30.607381  3366 solver.cpp:362] Iteration 7825, Testing net (#0)
I1112 18:31:30.607415  3366 net.cpp:723] Ignoring source layer train-data
I1112 18:31:41.931321  3366 solver.cpp:429]     Test net output #0: accuracy = 0.919502
I1112 18:31:41.931372  3366 solver.cpp:429]     Test net output #1: loss = 0.200209 (* 1 = 0.200209 loss)
I1112 18:31:52.313590  3366 solver.cpp:242] Iteration 7839 (1.00047 iter/s, 38.9817s/39 iter), loss = 0.183545
I1112 18:31:52.313649  3366 solver.cpp:261]     Train net output #0: loss = 0.175711 (* 1 = 0.175711 loss)
I1112 18:31:52.313668  3366 sgd_solver.cpp:106] Iteration 7839, lr = 0.000825879
I1112 18:32:10.067929  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:32:19.322001  3366 solver.cpp:242] Iteration 7878 (1.44402 iter/s, 27.008s/39 iter), loss = 0.185186
I1112 18:32:19.322060  3366 solver.cpp:261]     Train net output #0: loss = 0.184108 (* 1 = 0.184108 loss)
I1112 18:32:19.322079  3366 sgd_solver.cpp:106] Iteration 7878, lr = 0.000805112
I1112 18:32:47.185485  3366 solver.cpp:242] Iteration 7917 (1.3997 iter/s, 27.863s/39 iter), loss = 0.199144
I1112 18:32:47.186342  3366 solver.cpp:261]     Train net output #0: loss = 0.23606 (* 1 = 0.23606 loss)
I1112 18:32:47.186364  3366 sgd_solver.cpp:106] Iteration 7917, lr = 0.000784345
I1112 18:33:14.280282  3366 solver.cpp:242] Iteration 7956 (1.43946 iter/s, 27.0936s/39 iter), loss = 0.187859
I1112 18:33:14.280342  3366 solver.cpp:261]     Train net output #0: loss = 0.219556 (* 1 = 0.219556 loss)
I1112 18:33:14.280360  3366 sgd_solver.cpp:106] Iteration 7956, lr = 0.000763578
I1112 18:33:41.572913  3366 solver.cpp:242] Iteration 7995 (1.42898 iter/s, 27.2922s/39 iter), loss = 0.1821
I1112 18:33:41.576148  3366 solver.cpp:261]     Train net output #0: loss = 0.132584 (* 1 = 0.132584 loss)
I1112 18:33:41.576175  3366 sgd_solver.cpp:106] Iteration 7995, lr = 0.000742812
I1112 18:34:10.062940  3366 solver.cpp:242] Iteration 8034 (1.36907 iter/s, 28.4864s/39 iter), loss = 0.142235
I1112 18:34:10.063009  3366 solver.cpp:261]     Train net output #0: loss = 0.148114 (* 1 = 0.148114 loss)
I1112 18:34:10.063029  3366 sgd_solver.cpp:106] Iteration 8034, lr = 0.000722045
I1112 18:34:37.389981  3366 solver.cpp:242] Iteration 8073 (1.42718 iter/s, 27.3266s/39 iter), loss = 0.183224
I1112 18:34:37.390094  3366 solver.cpp:261]     Train net output #0: loss = 0.169582 (* 1 = 0.169582 loss)
I1112 18:34:37.390115  3366 sgd_solver.cpp:106] Iteration 8073, lr = 0.000701278
I1112 18:35:04.360129  3366 solver.cpp:242] Iteration 8112 (1.44607 iter/s, 26.9696s/39 iter), loss = 0.10846
I1112 18:35:04.360204  3366 solver.cpp:261]     Train net output #0: loss = 0.0898128 (* 1 = 0.0898128 loss)
I1112 18:35:04.360224  3366 sgd_solver.cpp:106] Iteration 8112, lr = 0.000680511
I1112 18:35:08.332891  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:35:21.745076  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_8138.caffemodel
I1112 18:35:21.773864  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_8138.solverstate
I1112 18:35:21.780297  3366 solver.cpp:362] Iteration 8138, Testing net (#0)
I1112 18:35:21.780323  3366 net.cpp:723] Ignoring source layer train-data
I1112 18:35:33.049588  3366 solver.cpp:429]     Test net output #0: accuracy = 0.920293
I1112 18:35:33.049639  3366 solver.cpp:429]     Test net output #1: loss = 0.200062 (* 1 = 0.200062 loss)
I1112 18:35:42.835424  3366 solver.cpp:242] Iteration 8151 (1.01365 iter/s, 38.4747s/39 iter), loss = 0.139687
I1112 18:35:42.836814  3366 solver.cpp:261]     Train net output #0: loss = 0.17944 (* 1 = 0.17944 loss)
I1112 18:35:42.836836  3366 sgd_solver.cpp:106] Iteration 8151, lr = 0.000659744
I1112 18:36:10.592212  3366 solver.cpp:242] Iteration 8190 (1.40515 iter/s, 27.755s/39 iter), loss = 0.165422
I1112 18:36:10.592270  3366 solver.cpp:261]     Train net output #0: loss = 0.10883 (* 1 = 0.10883 loss)
I1112 18:36:10.592288  3366 sgd_solver.cpp:106] Iteration 8190, lr = 0.000638978
I1112 18:36:37.724006  3366 solver.cpp:242] Iteration 8229 (1.43745 iter/s, 27.1313s/39 iter), loss = 0.194253
I1112 18:36:37.725098  3366 solver.cpp:261]     Train net output #0: loss = 0.189472 (* 1 = 0.189472 loss)
I1112 18:36:37.725121  3366 sgd_solver.cpp:106] Iteration 8229, lr = 0.000618211
I1112 18:37:05.871433  3366 solver.cpp:242] Iteration 8268 (1.38564 iter/s, 28.1459s/39 iter), loss = 0.199648
I1112 18:37:05.871496  3366 solver.cpp:261]     Train net output #0: loss = 0.15716 (* 1 = 0.15716 loss)
I1112 18:37:05.871515  3366 sgd_solver.cpp:106] Iteration 8268, lr = 0.000597444
I1112 18:37:33.042057  3366 solver.cpp:242] Iteration 8307 (1.4354 iter/s, 27.1702s/39 iter), loss = 0.129336
I1112 18:37:33.043612  3366 solver.cpp:261]     Train net output #0: loss = 0.143748 (* 1 = 0.143748 loss)
I1112 18:37:33.043632  3366 sgd_solver.cpp:106] Iteration 8307, lr = 0.000576677
I1112 18:38:00.076207  3366 solver.cpp:242] Iteration 8346 (1.44272 iter/s, 27.0322s/39 iter), loss = 0.205188
I1112 18:38:00.076267  3366 solver.cpp:261]     Train net output #0: loss = 0.154345 (* 1 = 0.154345 loss)
I1112 18:38:00.076284  3366 sgd_solver.cpp:106] Iteration 8346, lr = 0.00055591
I1112 18:38:03.465659  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:38:28.207190  3366 solver.cpp:242] Iteration 8385 (1.38639 iter/s, 28.1305s/39 iter), loss = 0.145205
I1112 18:38:28.207252  3366 solver.cpp:261]     Train net output #0: loss = 0.196318 (* 1 = 0.196318 loss)
I1112 18:38:28.207269  3366 sgd_solver.cpp:106] Iteration 8385, lr = 0.000535144
I1112 18:38:55.387495  3366 solver.cpp:242] Iteration 8424 (1.43489 iter/s, 27.1799s/39 iter), loss = 0.212169
I1112 18:38:55.387615  3366 solver.cpp:261]     Train net output #0: loss = 0.275334 (* 1 = 0.275334 loss)
I1112 18:38:55.387637  3366 sgd_solver.cpp:106] Iteration 8424, lr = 0.000514377
I1112 18:39:13.772850  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_8451.caffemodel
I1112 18:39:13.799669  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_8451.solverstate
I1112 18:39:13.838047  3366 solver.cpp:362] Iteration 8451, Testing net (#0)
I1112 18:39:13.838094  3366 net.cpp:723] Ignoring source layer train-data
I1112 18:39:25.828675  3366 solver.cpp:429]     Test net output #0: accuracy = 0.921479
I1112 18:39:25.833966  3366 solver.cpp:429]     Test net output #1: loss = 0.197928 (* 1 = 0.197928 loss)
I1112 18:39:34.971665  3366 solver.cpp:242] Iteration 8463 (0.985259 iter/s, 39.5835s/39 iter), loss = 0.140555
I1112 18:39:34.971727  3366 solver.cpp:261]     Train net output #0: loss = 0.104516 (* 1 = 0.104516 loss)
I1112 18:39:34.971745  3366 sgd_solver.cpp:106] Iteration 8463, lr = 0.00049361
I1112 18:40:02.232067  3366 solver.cpp:242] Iteration 8502 (1.43067 iter/s, 27.2599s/39 iter), loss = 0.158981
I1112 18:40:02.234940  3366 solver.cpp:261]     Train net output #0: loss = 0.185886 (* 1 = 0.185886 loss)
I1112 18:40:02.234961  3366 sgd_solver.cpp:106] Iteration 8502, lr = 0.000472843
I1112 18:40:29.996598  3366 solver.cpp:242] Iteration 8541 (1.40484 iter/s, 27.7613s/39 iter), loss = 0.137637
I1112 18:40:29.996670  3366 solver.cpp:261]     Train net output #0: loss = 0.165306 (* 1 = 0.165306 loss)
I1112 18:40:29.996688  3366 sgd_solver.cpp:106] Iteration 8541, lr = 0.000452077
I1112 18:40:57.513294  3366 solver.cpp:242] Iteration 8580 (1.41735 iter/s, 27.5162s/39 iter), loss = 0.16084
I1112 18:40:57.513749  3366 solver.cpp:261]     Train net output #0: loss = 0.139678 (* 1 = 0.139678 loss)
I1112 18:40:57.513769  3366 sgd_solver.cpp:106] Iteration 8580, lr = 0.00043131
I1112 18:41:00.041223  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:41:24.792199  3366 solver.cpp:242] Iteration 8619 (1.42972 iter/s, 27.2781s/39 iter), loss = 0.147326
I1112 18:41:24.792259  3366 solver.cpp:261]     Train net output #0: loss = 0.188245 (* 1 = 0.188245 loss)
I1112 18:41:24.792279  3366 sgd_solver.cpp:106] Iteration 8619, lr = 0.000410543
I1112 18:41:52.749979  3366 solver.cpp:242] Iteration 8658 (1.39498 iter/s, 27.9573s/39 iter), loss = 0.14826
I1112 18:41:52.750095  3366 solver.cpp:261]     Train net output #0: loss = 0.251621 (* 1 = 0.251621 loss)
I1112 18:41:52.750114  3366 sgd_solver.cpp:106] Iteration 8658, lr = 0.000389776
I1112 18:42:19.822758  3366 solver.cpp:242] Iteration 8697 (1.44059 iter/s, 27.0723s/39 iter), loss = 0.155847
I1112 18:42:19.822820  3366 solver.cpp:261]     Train net output #0: loss = 0.103721 (* 1 = 0.103721 loss)
I1112 18:42:19.822839  3366 sgd_solver.cpp:106] Iteration 8697, lr = 0.00036901
I1112 18:42:47.765785  3366 solver.cpp:242] Iteration 8736 (1.39572 iter/s, 27.9426s/39 iter), loss = 0.146958
I1112 18:42:47.766561  3366 solver.cpp:261]     Train net output #0: loss = 0.23845 (* 1 = 0.23845 loss)
I1112 18:42:47.766583  3366 sgd_solver.cpp:106] Iteration 8736, lr = 0.000348243
I1112 18:43:07.135462  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_8764.caffemodel
I1112 18:43:07.149430  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_8764.solverstate
I1112 18:43:07.155905  3366 solver.cpp:362] Iteration 8764, Testing net (#0)
I1112 18:43:07.155939  3366 net.cpp:723] Ignoring source layer train-data
I1112 18:43:18.301976  3366 solver.cpp:429]     Test net output #0: accuracy = 0.921282
I1112 18:43:18.308254  3366 solver.cpp:429]     Test net output #1: loss = 0.198326 (* 1 = 0.198326 loss)
I1112 18:43:26.801986  3366 solver.cpp:242] Iteration 8775 (0.999107 iter/s, 39.0349s/39 iter), loss = 0.134612
I1112 18:43:26.802050  3366 solver.cpp:261]     Train net output #0: loss = 0.105309 (* 1 = 0.105309 loss)
I1112 18:43:26.802069  3366 sgd_solver.cpp:106] Iteration 8775, lr = 0.000327476
I1112 18:43:54.106078  3366 solver.cpp:242] Iteration 8814 (1.42838 iter/s, 27.3036s/39 iter), loss = 0.112868
I1112 18:43:54.107388  3366 solver.cpp:261]     Train net output #0: loss = 0.166738 (* 1 = 0.166738 loss)
I1112 18:43:54.107414  3366 sgd_solver.cpp:106] Iteration 8814, lr = 0.000306709
I1112 18:43:56.853442  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:44:22.322670  3366 solver.cpp:242] Iteration 8853 (1.38225 iter/s, 28.2149s/39 iter), loss = 0.15043
I1112 18:44:22.322784  3366 solver.cpp:261]     Train net output #0: loss = 0.0950913 (* 1 = 0.0950913 loss)
I1112 18:44:22.322803  3366 sgd_solver.cpp:106] Iteration 8853, lr = 0.000285943
I1112 18:44:49.429671  3366 solver.cpp:242] Iteration 8892 (1.43877 iter/s, 27.1065s/39 iter), loss = 0.1405
I1112 18:44:49.433116  3366 solver.cpp:261]     Train net output #0: loss = 0.204589 (* 1 = 0.204589 loss)
I1112 18:44:49.433140  3366 sgd_solver.cpp:106] Iteration 8892, lr = 0.000265176
I1112 18:45:17.526298  3366 solver.cpp:242] Iteration 8931 (1.38826 iter/s, 28.0928s/39 iter), loss = 0.142729
I1112 18:45:17.526377  3366 solver.cpp:261]     Train net output #0: loss = 0.129957 (* 1 = 0.129957 loss)
I1112 18:45:17.526397  3366 sgd_solver.cpp:106] Iteration 8931, lr = 0.000244409
I1112 18:45:44.776710  3366 solver.cpp:242] Iteration 8970 (1.4312 iter/s, 27.2499s/39 iter), loss = 0.1316
I1112 18:45:44.778787  3366 solver.cpp:261]     Train net output #0: loss = 0.125918 (* 1 = 0.125918 loss)
I1112 18:45:44.778810  3366 sgd_solver.cpp:106] Iteration 8970, lr = 0.000223642
I1112 18:46:11.682581  3366 solver.cpp:242] Iteration 9009 (1.44963 iter/s, 26.9034s/39 iter), loss = 0.156504
I1112 18:46:11.682636  3366 solver.cpp:261]     Train net output #0: loss = 0.245461 (* 1 = 0.245461 loss)
I1112 18:46:11.682654  3366 sgd_solver.cpp:106] Iteration 9009, lr = 0.000202875
I1112 18:46:39.710229  3366 solver.cpp:242] Iteration 9048 (1.39151 iter/s, 28.0272s/39 iter), loss = 0.105808
I1112 18:46:39.710422  3366 solver.cpp:261]     Train net output #0: loss = 0.0894267 (* 1 = 0.0894267 loss)
I1112 18:46:39.710441  3366 sgd_solver.cpp:106] Iteration 9048, lr = 0.000182109
I1112 18:46:54.327373  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:46:59.237951  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_9077.caffemodel
I1112 18:46:59.267138  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_9077.solverstate
I1112 18:46:59.299466  3366 solver.cpp:362] Iteration 9077, Testing net (#0)
I1112 18:46:59.299495  3366 net.cpp:723] Ignoring source layer train-data
I1112 18:47:10.512096  3366 solver.cpp:429]     Test net output #0: accuracy = 0.924644
I1112 18:47:10.513947  3366 solver.cpp:429]     Test net output #1: loss = 0.188123 (* 1 = 0.188123 loss)
I1112 18:47:18.215462  3366 solver.cpp:242] Iteration 9087 (1.01287 iter/s, 38.5045s/39 iter), loss = 0.154107
I1112 18:47:18.215524  3366 solver.cpp:261]     Train net output #0: loss = 0.181049 (* 1 = 0.181049 loss)
I1112 18:47:18.215543  3366 sgd_solver.cpp:106] Iteration 9087, lr = 0.000161342
I1112 18:47:45.301321  3366 solver.cpp:242] Iteration 9126 (1.43989 iter/s, 27.0854s/39 iter), loss = 0.124527
I1112 18:47:45.302623  3366 solver.cpp:261]     Train net output #0: loss = 0.0630031 (* 1 = 0.0630031 loss)
I1112 18:47:45.302644  3366 sgd_solver.cpp:106] Iteration 9126, lr = 0.000140575
I1112 18:48:11.699594  3366 solver.cpp:242] Iteration 9165 (1.47746 iter/s, 26.3966s/39 iter), loss = 0.121162
I1112 18:48:11.699663  3366 solver.cpp:261]     Train net output #0: loss = 0.220826 (* 1 = 0.220826 loss)
I1112 18:48:11.699682  3366 sgd_solver.cpp:106] Iteration 9165, lr = 0.000119808
I1112 18:48:38.214751  3366 solver.cpp:242] Iteration 9204 (1.47088 iter/s, 26.5147s/39 iter), loss = 0.160142
I1112 18:48:38.215356  3366 solver.cpp:261]     Train net output #0: loss = 0.129582 (* 1 = 0.129582 loss)
I1112 18:48:38.215381  3366 sgd_solver.cpp:106] Iteration 9204, lr = 9.90415e-05
I1112 18:49:04.473979  3366 solver.cpp:242] Iteration 9243 (1.48525 iter/s, 26.2583s/39 iter), loss = 0.137683
I1112 18:49:04.474046  3366 solver.cpp:261]     Train net output #0: loss = 0.176252 (* 1 = 0.176252 loss)
I1112 18:49:04.474066  3366 sgd_solver.cpp:106] Iteration 9243, lr = 7.82749e-05
I1112 18:49:30.801017  3366 solver.cpp:242] Iteration 9282 (1.48139 iter/s, 26.3266s/39 iter), loss = 0.162533
I1112 18:49:30.801218  3366 solver.cpp:261]     Train net output #0: loss = 0.165576 (* 1 = 0.165576 loss)
I1112 18:49:30.801235  3366 sgd_solver.cpp:106] Iteration 9282, lr = 5.7508e-05
I1112 18:49:44.687408  3366 blocking_queue.cpp:50] Data layer prefetch queue empty
I1112 18:49:57.159548  3366 solver.cpp:242] Iteration 9321 (1.47963 iter/s, 26.358s/39 iter), loss = 0.132546
I1112 18:49:57.159633  3366 solver.cpp:261]     Train net output #0: loss = 0.133568 (* 1 = 0.133568 loss)
I1112 18:49:57.159656  3366 sgd_solver.cpp:106] Iteration 9321, lr = 3.67412e-05
I1112 18:50:23.554498  3366 solver.cpp:242] Iteration 9360 (1.47758 iter/s, 26.3945s/39 iter), loss = 0.128542
I1112 18:50:23.554611  3366 solver.cpp:261]     Train net output #0: loss = 0.131796 (* 1 = 0.131796 loss)
I1112 18:50:23.554630  3366 sgd_solver.cpp:106] Iteration 9360, lr = 1.59743e-05
I1112 18:50:43.248813  3366 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_9390.caffemodel
I1112 18:50:43.285764  3366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_9390.solverstate
I1112 18:50:43.299839  3366 solver.cpp:362] Iteration 9390, Testing net (#0)
I1112 18:50:43.299875  3366 net.cpp:723] Ignoring source layer train-data
I1112 18:50:54.183210  3366 solver.cpp:429]     Test net output #0: accuracy = 0.920886
I1112 18:50:54.185179  3366 solver.cpp:429]     Test net output #1: loss = 0.189998 (* 1 = 0.189998 loss)
I1112 18:50:54.185192  3366 solver.cpp:347] Optimization Done.
I1112 18:50:54.185199  3366 caffe.cpp:234] Optimization Done.
