I1018 23:03:55.339124  3328 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': /media/myuser/120Gb/DIGITS/digits/jobs/20161018-230353-fe12/solver.prototxt
I1018 23:03:55.339334  3328 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W1018 23:03:55.339342  3328 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I1018 23:03:55.519618  3328 caffe.cpp:197] Using GPUs 0
I1018 23:03:55.519950  3328 caffe.cpp:202] GPU 0: GeForce GTX 1070
I1018 23:03:56.089666  3328 solver.cpp:48] Initializing solver from parameters:
test_iter: 40
test_interval: 157
base_lr: 0.005
display: 19
max_iter: 4710
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 5e-05
snapshot: 157
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
iter_size: 4
type: "SGD"
I1018 23:03:56.089819  3328 solver.cpp:91] Creating training net from net file: train_val.prototxt
I1018 23:03:56.090862  3328 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer val-data
I1018 23:03:56.090893  3328 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1018 23:03:56.091157  3328 net.cpp:52] Initializing net from parameters:
state {
phase: TRAIN
}
layer {
name: "train-data"
type: "Data"
top: "data"
top: "label"
include {
phase: TRAIN
}
transform_param {
mirror: true
crop_size: 224
mean_file: "/media/myuser/120Gb/DIGITS/digits/jobs/20160917-133511-8c62/mean.binaryproto"
}
data_param {
source: "/media/myuser/120Gb/DIGITS/digits/jobs/20160917-133511-8c62/train_db"
batch_size: 128
backend: LMDB
}
}
layer {
name: "conv1"
type: "Convolution"
bottom: "data"
top: "conv1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 11
stride: 4
weight_filler {
type: "gaussian"
mean: 0
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu0"
type: "ReLU"
bottom: "conv1"
top: "conv1"
}
layer {
name: "cccp1"
type: "Convolution"
bottom: "conv1"
top: "cccp1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 1
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu1"
type: "ReLU"
bottom: "cccp1"
top: "cccp1"
}
layer {
name: "cccp2"
type: "Convolution"
bottom: "cccp1"
top: "cccp2"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 1
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu2"
type: "ReLU"
bottom: "cccp2"
top: "cccp2"
}
layer {
name: "pool0"
type: "Pooling"
bottom: "cccp2"
top: "pool0"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv2"
type: "Convolution"
bottom: "pool0"
top: "conv2"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 2
kernel_size: 5
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv2"
top: "conv2"
}
layer {
name: "cccp3"
type: "Convolution"
bottom: "conv2"
top: "cccp3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
kernel_size: 1
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "cccp3"
top: "cccp3"
}
layer {
name: "cccp4"
type: "Convolution"
bottom: "cccp3"
top: "cccp4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
kernel_size: 1
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "cccp4"
top: "cccp4"
}
layer {
name: "pool2"
type: "Pooling"
bottom: "cccp4"
top: "pool2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool2"
top: "conv3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "cccp5"
type: "Convolution"
bottom: "conv3"
top: "cccp5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
kernel_size: 1
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu8"
type: "ReLU"
bottom: "cccp5"
top: "cccp5"
}
layer {
name: "cccp6"
type: "Convolution"
bottom: "cccp5"
top: "cccp6"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
kernel_size: 1
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu9"
type: "ReLU"
bottom: "cccp6"
top: "cccp6"
}
layer {
name: "pool3"
type: "Pooling"
bottom: "cccp6"
top: "pool3"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "drop"
type: "Dropout"
bottom: "pool3"
top: "pool3"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "conv4-1024"
type: "Convolution"
bottom: "pool3"
top: "conv4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 1024
pad: 1
kernel_size: 3
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu10"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "cccp7-1024"
type: "Convolution"
bottom: "conv4"
top: "cccp7"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 1024
kernel_size: 1
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu11"
type: "ReLU"
bottom: "cccp7"
top: "cccp7"
}
layer {
name: "cccp8-1024"
type: "Convolution"
bottom: "cccp7"
top: "cccp8"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 2
kernel_size: 1
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu12"
type: "ReLU"
bottom: "cccp8"
top: "cccp8"
}
layer {
name: "pool4"
type: "Pooling"
bottom: "cccp8"
top: "pool4"
pooling_param {
pool: AVE
kernel_size: 6
stride: 1
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "pool4"
bottom: "label"
top: "loss"
}
I1018 23:03:56.091311  3328 layer_factory.hpp:77] Creating layer train-data
I1018 23:03:56.091825  3328 net.cpp:94] Creating Layer train-data
I1018 23:03:56.091850  3328 net.cpp:409] train-data -> data
I1018 23:03:56.091881  3328 net.cpp:409] train-data -> label
I1018 23:03:56.091902  3328 data_transformer.cpp:25] Loading mean file from: /media/myuser/120Gb/DIGITS/digits/jobs/20160917-133511-8c62/mean.binaryproto
I1018 23:03:56.095347  3334 db_lmdb.cpp:35] Opened lmdb /media/myuser/120Gb/DIGITS/digits/jobs/20160917-133511-8c62/train_db
I1018 23:03:56.105412  3328 data_layer.cpp:76] output data size: 128,3,224,224
I1018 23:03:56.359378  3328 net.cpp:144] Setting up train-data
I1018 23:03:56.359419  3328 net.cpp:151] Top shape: 128 3 224 224 (19267584)
I1018 23:03:56.359431  3328 net.cpp:151] Top shape: 128 (128)
I1018 23:03:56.359438  3328 net.cpp:159] Memory required for data: 77070848
I1018 23:03:56.359454  3328 layer_factory.hpp:77] Creating layer conv1
I1018 23:03:56.359483  3328 net.cpp:94] Creating Layer conv1
I1018 23:03:56.363512  3328 net.cpp:435] conv1 <- data
I1018 23:03:56.363536  3328 net.cpp:409] conv1 -> conv1
I1018 23:04:00.863708  3328 net.cpp:144] Setting up conv1
I1018 23:04:00.863754  3328 net.cpp:151] Top shape: 128 96 54 54 (35831808)
I1018 23:04:00.863764  3328 net.cpp:159] Memory required for data: 220398080
I1018 23:04:00.863791  3328 layer_factory.hpp:77] Creating layer relu0
I1018 23:04:00.863811  3328 net.cpp:94] Creating Layer relu0
I1018 23:04:00.863821  3328 net.cpp:435] relu0 <- conv1
I1018 23:04:00.863831  3328 net.cpp:396] relu0 -> conv1 (in-place)
I1018 23:04:00.863867  3328 net.cpp:144] Setting up relu0
I1018 23:04:00.863878  3328 net.cpp:151] Top shape: 128 96 54 54 (35831808)
I1018 23:04:00.863885  3328 net.cpp:159] Memory required for data: 363725312
I1018 23:04:00.863893  3328 layer_factory.hpp:77] Creating layer cccp1
I1018 23:04:00.863911  3328 net.cpp:94] Creating Layer cccp1
I1018 23:04:00.863919  3328 net.cpp:435] cccp1 <- conv1
I1018 23:04:00.863930  3328 net.cpp:409] cccp1 -> cccp1
I1018 23:04:00.936507  3328 net.cpp:144] Setting up cccp1
I1018 23:04:00.936544  3328 net.cpp:151] Top shape: 128 96 54 54 (35831808)
I1018 23:04:00.936553  3328 net.cpp:159] Memory required for data: 507052544
I1018 23:04:00.936573  3328 layer_factory.hpp:77] Creating layer relu1
I1018 23:04:00.936589  3328 net.cpp:94] Creating Layer relu1
I1018 23:04:00.936599  3328 net.cpp:435] relu1 <- cccp1
I1018 23:04:00.936609  3328 net.cpp:396] relu1 -> cccp1 (in-place)
I1018 23:04:00.936625  3328 net.cpp:144] Setting up relu1
I1018 23:04:00.936633  3328 net.cpp:151] Top shape: 128 96 54 54 (35831808)
I1018 23:04:00.936640  3328 net.cpp:159] Memory required for data: 650379776
I1018 23:04:00.936647  3328 layer_factory.hpp:77] Creating layer cccp2
I1018 23:04:00.936664  3328 net.cpp:94] Creating Layer cccp2
I1018 23:04:00.936672  3328 net.cpp:435] cccp2 <- cccp1
I1018 23:04:00.936682  3328 net.cpp:409] cccp2 -> cccp2
I1018 23:04:00.987152  3328 net.cpp:144] Setting up cccp2
I1018 23:04:00.987192  3328 net.cpp:151] Top shape: 128 96 54 54 (35831808)
I1018 23:04:00.987200  3328 net.cpp:159] Memory required for data: 793707008
I1018 23:04:00.987221  3328 layer_factory.hpp:77] Creating layer relu2
I1018 23:04:00.987236  3328 net.cpp:94] Creating Layer relu2
I1018 23:04:00.987246  3328 net.cpp:435] relu2 <- cccp2
I1018 23:04:00.987256  3328 net.cpp:396] relu2 -> cccp2 (in-place)
I1018 23:04:00.987272  3328 net.cpp:144] Setting up relu2
I1018 23:04:00.987282  3328 net.cpp:151] Top shape: 128 96 54 54 (35831808)
I1018 23:04:00.987288  3328 net.cpp:159] Memory required for data: 937034240
I1018 23:04:00.987295  3328 layer_factory.hpp:77] Creating layer pool0
I1018 23:04:00.987311  3328 net.cpp:94] Creating Layer pool0
I1018 23:04:00.987319  3328 net.cpp:435] pool0 <- cccp2
I1018 23:04:00.987329  3328 net.cpp:409] pool0 -> pool0
I1018 23:04:00.987438  3328 net.cpp:144] Setting up pool0
I1018 23:04:00.987448  3328 net.cpp:151] Top shape: 128 96 27 27 (8957952)
I1018 23:04:00.987457  3328 net.cpp:159] Memory required for data: 972866048
I1018 23:04:00.987463  3328 layer_factory.hpp:77] Creating layer conv2
I1018 23:04:00.987526  3328 net.cpp:94] Creating Layer conv2
I1018 23:04:00.987534  3328 net.cpp:435] conv2 <- pool0
I1018 23:04:00.987545  3328 net.cpp:409] conv2 -> conv2
I1018 23:04:01.321887  3328 net.cpp:144] Setting up conv2
I1018 23:04:01.321928  3328 net.cpp:151] Top shape: 128 256 27 27 (23887872)
I1018 23:04:01.321935  3328 net.cpp:159] Memory required for data: 1068417536
I1018 23:04:01.321951  3328 layer_factory.hpp:77] Creating layer relu3
I1018 23:04:01.321965  3328 net.cpp:94] Creating Layer relu3
I1018 23:04:01.321974  3328 net.cpp:435] relu3 <- conv2
I1018 23:04:01.321985  3328 net.cpp:396] relu3 -> conv2 (in-place)
I1018 23:04:01.322001  3328 net.cpp:144] Setting up relu3
I1018 23:04:01.322010  3328 net.cpp:151] Top shape: 128 256 27 27 (23887872)
I1018 23:04:01.322017  3328 net.cpp:159] Memory required for data: 1163969024
I1018 23:04:01.322024  3328 layer_factory.hpp:77] Creating layer cccp3
I1018 23:04:01.322041  3328 net.cpp:94] Creating Layer cccp3
I1018 23:04:01.322049  3328 net.cpp:435] cccp3 <- conv2
I1018 23:04:01.322060  3328 net.cpp:409] cccp3 -> cccp3
I1018 23:04:01.366147  3328 net.cpp:144] Setting up cccp3
I1018 23:04:01.366181  3328 net.cpp:151] Top shape: 128 256 27 27 (23887872)
I1018 23:04:01.366189  3328 net.cpp:159] Memory required for data: 1259520512
I1018 23:04:01.366211  3328 layer_factory.hpp:77] Creating layer relu5
I1018 23:04:01.366225  3328 net.cpp:94] Creating Layer relu5
I1018 23:04:01.366235  3328 net.cpp:435] relu5 <- cccp3
I1018 23:04:01.366245  3328 net.cpp:396] relu5 -> cccp3 (in-place)
I1018 23:04:01.366261  3328 net.cpp:144] Setting up relu5
I1018 23:04:01.366271  3328 net.cpp:151] Top shape: 128 256 27 27 (23887872)
I1018 23:04:01.366277  3328 net.cpp:159] Memory required for data: 1355072000
I1018 23:04:01.366284  3328 layer_factory.hpp:77] Creating layer cccp4
I1018 23:04:01.366300  3328 net.cpp:94] Creating Layer cccp4
I1018 23:04:01.366308  3328 net.cpp:435] cccp4 <- cccp3
I1018 23:04:01.366318  3328 net.cpp:409] cccp4 -> cccp4
I1018 23:04:01.410581  3328 net.cpp:144] Setting up cccp4
I1018 23:04:01.410621  3328 net.cpp:151] Top shape: 128 256 27 27 (23887872)
I1018 23:04:01.410629  3328 net.cpp:159] Memory required for data: 1450623488
I1018 23:04:01.410645  3328 layer_factory.hpp:77] Creating layer relu6
I1018 23:04:01.410660  3328 net.cpp:94] Creating Layer relu6
I1018 23:04:01.410668  3328 net.cpp:435] relu6 <- cccp4
I1018 23:04:01.410679  3328 net.cpp:396] relu6 -> cccp4 (in-place)
I1018 23:04:01.410696  3328 net.cpp:144] Setting up relu6
I1018 23:04:01.410704  3328 net.cpp:151] Top shape: 128 256 27 27 (23887872)
I1018 23:04:01.410712  3328 net.cpp:159] Memory required for data: 1546174976
I1018 23:04:01.410718  3328 layer_factory.hpp:77] Creating layer pool2
I1018 23:04:01.410732  3328 net.cpp:94] Creating Layer pool2
I1018 23:04:01.410738  3328 net.cpp:435] pool2 <- cccp4
I1018 23:04:01.410748  3328 net.cpp:409] pool2 -> pool2
I1018 23:04:01.410840  3328 net.cpp:144] Setting up pool2
I1018 23:04:01.410851  3328 net.cpp:151] Top shape: 128 256 13 13 (5537792)
I1018 23:04:01.410858  3328 net.cpp:159] Memory required for data: 1568326144
I1018 23:04:01.410866  3328 layer_factory.hpp:77] Creating layer conv3
I1018 23:04:01.410882  3328 net.cpp:94] Creating Layer conv3
I1018 23:04:01.410890  3328 net.cpp:435] conv3 <- pool2
I1018 23:04:01.410900  3328 net.cpp:409] conv3 -> conv3
I1018 23:04:01.617657  3328 net.cpp:144] Setting up conv3
I1018 23:04:01.617686  3328 net.cpp:151] Top shape: 128 384 13 13 (8306688)
I1018 23:04:01.617694  3328 net.cpp:159] Memory required for data: 1601552896
I1018 23:04:01.617712  3328 layer_factory.hpp:77] Creating layer relu7
I1018 23:04:01.617730  3328 net.cpp:94] Creating Layer relu7
I1018 23:04:01.617739  3328 net.cpp:435] relu7 <- conv3
I1018 23:04:01.617750  3328 net.cpp:396] relu7 -> conv3 (in-place)
I1018 23:04:01.617766  3328 net.cpp:144] Setting up relu7
I1018 23:04:01.617776  3328 net.cpp:151] Top shape: 128 384 13 13 (8306688)
I1018 23:04:01.617782  3328 net.cpp:159] Memory required for data: 1634779648
I1018 23:04:01.617790  3328 layer_factory.hpp:77] Creating layer cccp5
I1018 23:04:01.617832  3328 net.cpp:94] Creating Layer cccp5
I1018 23:04:01.617841  3328 net.cpp:435] cccp5 <- conv3
I1018 23:04:01.617852  3328 net.cpp:409] cccp5 -> cccp5
I1018 23:04:01.646081  3328 net.cpp:144] Setting up cccp5
I1018 23:04:01.646103  3328 net.cpp:151] Top shape: 128 384 13 13 (8306688)
I1018 23:04:01.646116  3328 net.cpp:159] Memory required for data: 1668006400
I1018 23:04:01.646132  3328 layer_factory.hpp:77] Creating layer relu8
I1018 23:04:01.646147  3328 net.cpp:94] Creating Layer relu8
I1018 23:04:01.646159  3328 net.cpp:435] relu8 <- cccp5
I1018 23:04:01.646173  3328 net.cpp:396] relu8 -> cccp5 (in-place)
I1018 23:04:01.646193  3328 net.cpp:144] Setting up relu8
I1018 23:04:01.646203  3328 net.cpp:151] Top shape: 128 384 13 13 (8306688)
I1018 23:04:01.646209  3328 net.cpp:159] Memory required for data: 1701233152
I1018 23:04:01.646216  3328 layer_factory.hpp:77] Creating layer cccp6
I1018 23:04:01.646230  3328 net.cpp:94] Creating Layer cccp6
I1018 23:04:01.646237  3328 net.cpp:435] cccp6 <- cccp5
I1018 23:04:01.646248  3328 net.cpp:409] cccp6 -> cccp6
I1018 23:04:01.675459  3328 net.cpp:144] Setting up cccp6
I1018 23:04:01.675482  3328 net.cpp:151] Top shape: 128 384 13 13 (8306688)
I1018 23:04:01.675505  3328 net.cpp:159] Memory required for data: 1734459904
I1018 23:04:01.675532  3328 layer_factory.hpp:77] Creating layer relu9
I1018 23:04:01.675549  3328 net.cpp:94] Creating Layer relu9
I1018 23:04:01.675565  3328 net.cpp:435] relu9 <- cccp6
I1018 23:04:01.675573  3328 net.cpp:396] relu9 -> cccp6 (in-place)
I1018 23:04:01.675586  3328 net.cpp:144] Setting up relu9
I1018 23:04:01.675595  3328 net.cpp:151] Top shape: 128 384 13 13 (8306688)
I1018 23:04:01.675602  3328 net.cpp:159] Memory required for data: 1767686656
I1018 23:04:01.675609  3328 layer_factory.hpp:77] Creating layer pool3
I1018 23:04:01.675621  3328 net.cpp:94] Creating Layer pool3
I1018 23:04:01.675628  3328 net.cpp:435] pool3 <- cccp6
I1018 23:04:01.675638  3328 net.cpp:409] pool3 -> pool3
I1018 23:04:01.675690  3328 net.cpp:144] Setting up pool3
I1018 23:04:01.675700  3328 net.cpp:151] Top shape: 128 384 6 6 (1769472)
I1018 23:04:01.675707  3328 net.cpp:159] Memory required for data: 1774764544
I1018 23:04:01.675715  3328 layer_factory.hpp:77] Creating layer drop
I1018 23:04:01.675732  3328 net.cpp:94] Creating Layer drop
I1018 23:04:01.675740  3328 net.cpp:435] drop <- pool3
I1018 23:04:01.675750  3328 net.cpp:396] drop -> pool3 (in-place)
I1018 23:04:01.675781  3328 net.cpp:144] Setting up drop
I1018 23:04:01.675791  3328 net.cpp:151] Top shape: 128 384 6 6 (1769472)
I1018 23:04:01.675798  3328 net.cpp:159] Memory required for data: 1781842432
I1018 23:04:01.675806  3328 layer_factory.hpp:77] Creating layer conv4-1024
I1018 23:04:01.675819  3328 net.cpp:94] Creating Layer conv4-1024
I1018 23:04:01.675827  3328 net.cpp:435] conv4-1024 <- pool3
I1018 23:04:01.675837  3328 net.cpp:409] conv4-1024 -> conv4
I1018 23:04:01.981207  3328 net.cpp:144] Setting up conv4-1024
I1018 23:04:01.981238  3328 net.cpp:151] Top shape: 128 1024 6 6 (4718592)
I1018 23:04:01.981246  3328 net.cpp:159] Memory required for data: 1800716800
I1018 23:04:01.981262  3328 layer_factory.hpp:77] Creating layer relu10
I1018 23:04:01.981276  3328 net.cpp:94] Creating Layer relu10
I1018 23:04:01.981286  3328 net.cpp:435] relu10 <- conv4
I1018 23:04:01.981297  3328 net.cpp:396] relu10 -> conv4 (in-place)
I1018 23:04:01.981312  3328 net.cpp:144] Setting up relu10
I1018 23:04:01.981322  3328 net.cpp:151] Top shape: 128 1024 6 6 (4718592)
I1018 23:04:01.981328  3328 net.cpp:159] Memory required for data: 1819591168
I1018 23:04:01.981334  3328 layer_factory.hpp:77] Creating layer cccp7-1024
I1018 23:04:01.981350  3328 net.cpp:94] Creating Layer cccp7-1024
I1018 23:04:01.981359  3328 net.cpp:435] cccp7-1024 <- conv4
I1018 23:04:01.981369  3328 net.cpp:409] cccp7-1024 -> cccp7
I1018 23:04:02.075837  3328 net.cpp:144] Setting up cccp7-1024
I1018 23:04:02.075873  3328 net.cpp:151] Top shape: 128 1024 6 6 (4718592)
I1018 23:04:02.075914  3328 net.cpp:159] Memory required for data: 1838465536
I1018 23:04:02.075935  3328 layer_factory.hpp:77] Creating layer relu11
I1018 23:04:02.075954  3328 net.cpp:94] Creating Layer relu11
I1018 23:04:02.075968  3328 net.cpp:435] relu11 <- cccp7
I1018 23:04:02.075983  3328 net.cpp:396] relu11 -> cccp7 (in-place)
I1018 23:04:02.076002  3328 net.cpp:144] Setting up relu11
I1018 23:04:02.076016  3328 net.cpp:151] Top shape: 128 1024 6 6 (4718592)
I1018 23:04:02.076027  3328 net.cpp:159] Memory required for data: 1857339904
I1018 23:04:02.076038  3328 layer_factory.hpp:77] Creating layer cccp8-1024
I1018 23:04:02.076061  3328 net.cpp:94] Creating Layer cccp8-1024
I1018 23:04:02.076071  3328 net.cpp:435] cccp8-1024 <- cccp7
I1018 23:04:02.076087  3328 net.cpp:409] cccp8-1024 -> cccp8
I1018 23:04:02.081485  3328 net.cpp:144] Setting up cccp8-1024
I1018 23:04:02.081506  3328 net.cpp:151] Top shape: 128 2 6 6 (9216)
I1018 23:04:02.081517  3328 net.cpp:159] Memory required for data: 1857376768
I1018 23:04:02.081534  3328 layer_factory.hpp:77] Creating layer relu12
I1018 23:04:02.081548  3328 net.cpp:94] Creating Layer relu12
I1018 23:04:02.081559  3328 net.cpp:435] relu12 <- cccp8
I1018 23:04:02.081573  3328 net.cpp:396] relu12 -> cccp8 (in-place)
I1018 23:04:02.081590  3328 net.cpp:144] Setting up relu12
I1018 23:04:02.081604  3328 net.cpp:151] Top shape: 128 2 6 6 (9216)
I1018 23:04:02.081614  3328 net.cpp:159] Memory required for data: 1857413632
I1018 23:04:02.081625  3328 layer_factory.hpp:77] Creating layer pool4
I1018 23:04:02.081640  3328 net.cpp:94] Creating Layer pool4
I1018 23:04:02.081651  3328 net.cpp:435] pool4 <- cccp8
I1018 23:04:02.081666  3328 net.cpp:409] pool4 -> pool4
I1018 23:04:02.081729  3328 net.cpp:144] Setting up pool4
I1018 23:04:02.081744  3328 net.cpp:151] Top shape: 128 2 1 1 (256)
I1018 23:04:02.081754  3328 net.cpp:159] Memory required for data: 1857414656
I1018 23:04:02.081765  3328 layer_factory.hpp:77] Creating layer loss
I1018 23:04:02.081787  3328 net.cpp:94] Creating Layer loss
I1018 23:04:02.081799  3328 net.cpp:435] loss <- pool4
I1018 23:04:02.081810  3328 net.cpp:435] loss <- label
I1018 23:04:02.081826  3328 net.cpp:409] loss -> loss
I1018 23:04:02.081851  3328 layer_factory.hpp:77] Creating layer loss
I1018 23:04:02.082022  3328 net.cpp:144] Setting up loss
I1018 23:04:02.082037  3328 net.cpp:151] Top shape: (1)
I1018 23:04:02.082048  3328 net.cpp:154]     with loss weight 1
I1018 23:04:02.082077  3328 net.cpp:159] Memory required for data: 1857414660
I1018 23:04:02.082088  3328 net.cpp:220] loss needs backward computation.
I1018 23:04:02.082099  3328 net.cpp:220] pool4 needs backward computation.
I1018 23:04:02.082110  3328 net.cpp:220] relu12 needs backward computation.
I1018 23:04:02.082120  3328 net.cpp:220] cccp8-1024 needs backward computation.
I1018 23:04:02.082130  3328 net.cpp:220] relu11 needs backward computation.
I1018 23:04:02.082141  3328 net.cpp:220] cccp7-1024 needs backward computation.
I1018 23:04:02.082151  3328 net.cpp:220] relu10 needs backward computation.
I1018 23:04:02.082161  3328 net.cpp:220] conv4-1024 needs backward computation.
I1018 23:04:02.082172  3328 net.cpp:220] drop needs backward computation.
I1018 23:04:02.082182  3328 net.cpp:220] pool3 needs backward computation.
I1018 23:04:02.082192  3328 net.cpp:220] relu9 needs backward computation.
I1018 23:04:02.082203  3328 net.cpp:220] cccp6 needs backward computation.
I1018 23:04:02.082213  3328 net.cpp:220] relu8 needs backward computation.
I1018 23:04:02.082223  3328 net.cpp:220] cccp5 needs backward computation.
I1018 23:04:02.082234  3328 net.cpp:220] relu7 needs backward computation.
I1018 23:04:02.082244  3328 net.cpp:220] conv3 needs backward computation.
I1018 23:04:02.082255  3328 net.cpp:220] pool2 needs backward computation.
I1018 23:04:02.082265  3328 net.cpp:220] relu6 needs backward computation.
I1018 23:04:02.082275  3328 net.cpp:220] cccp4 needs backward computation.
I1018 23:04:02.082288  3328 net.cpp:220] relu5 needs backward computation.
I1018 23:04:02.082298  3328 net.cpp:220] cccp3 needs backward computation.
I1018 23:04:02.082324  3328 net.cpp:220] relu3 needs backward computation.
I1018 23:04:02.082336  3328 net.cpp:220] conv2 needs backward computation.
I1018 23:04:02.082346  3328 net.cpp:220] pool0 needs backward computation.
I1018 23:04:02.082357  3328 net.cpp:220] relu2 needs backward computation.
I1018 23:04:02.082367  3328 net.cpp:220] cccp2 needs backward computation.
I1018 23:04:02.082378  3328 net.cpp:220] relu1 needs backward computation.
I1018 23:04:02.082388  3328 net.cpp:220] cccp1 needs backward computation.
I1018 23:04:02.082398  3328 net.cpp:220] relu0 needs backward computation.
I1018 23:04:02.082409  3328 net.cpp:220] conv1 needs backward computation.
I1018 23:04:02.082420  3328 net.cpp:222] train-data does not need backward computation.
I1018 23:04:02.082430  3328 net.cpp:264] This network produces output loss
I1018 23:04:02.082468  3328 net.cpp:284] Network initialization done.
I1018 23:04:02.084107  3328 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I1018 23:04:02.084195  3328 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer train-data
I1018 23:04:02.084641  3328 net.cpp:52] Initializing net from parameters:
state {
phase: TEST
}
layer {
name: "val-data"
type: "Data"
top: "data"
top: "label"
include {
phase: TEST
}
transform_param {
crop_size: 224
mean_file: "/media/myuser/120Gb/DIGITS/digits/jobs/20160917-133511-8c62/mean.binaryproto"
}
data_param {
source: "/media/myuser/120Gb/DIGITS/digits/jobs/20160917-133511-8c62/val_db"
batch_size: 128
backend: LMDB
}
}
layer {
name: "conv1"
type: "Convolution"
bottom: "data"
top: "conv1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 11
stride: 4
weight_filler {
type: "gaussian"
mean: 0
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu0"
type: "ReLU"
bottom: "conv1"
top: "conv1"
}
layer {
name: "cccp1"
type: "Convolution"
bottom: "conv1"
top: "cccp1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 1
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu1"
type: "ReLU"
bottom: "cccp1"
top: "cccp1"
}
layer {
name: "cccp2"
type: "Convolution"
bottom: "cccp1"
top: "cccp2"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 1
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu2"
type: "ReLU"
bottom: "cccp2"
top: "cccp2"
}
layer {
name: "pool0"
type: "Pooling"
bottom: "cccp2"
top: "pool0"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv2"
type: "Convolution"
bottom: "pool0"
top: "conv2"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 2
kernel_size: 5
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv2"
top: "conv2"
}
layer {
name: "cccp3"
type: "Convolution"
bottom: "conv2"
top: "cccp3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
kernel_size: 1
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "cccp3"
top: "cccp3"
}
layer {
name: "cccp4"
type: "Convolution"
bottom: "cccp3"
top: "cccp4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
kernel_size: 1
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "cccp4"
top: "cccp4"
}
layer {
name: "pool2"
type: "Pooling"
bottom: "cccp4"
top: "pool2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool2"
top: "conv3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "cccp5"
type: "Convolution"
bottom: "conv3"
top: "cccp5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
kernel_size: 1
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu8"
type: "ReLU"
bottom: "cccp5"
top: "cccp5"
}
layer {
name: "cccp6"
type: "Convolution"
bottom: "cccp5"
top: "cccp6"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
kernel_size: 1
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu9"
type: "ReLU"
bottom: "cccp6"
top: "cccp6"
}
layer {
name: "pool3"
type: "Pooling"
bottom: "cccp6"
top: "pool3"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "drop"
type: "Dropout"
bottom: "pool3"
top: "pool3"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "conv4-1024"
type: "Convolution"
bottom: "pool3"
top: "conv4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 1024
pad: 1
kernel_size: 3
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu10"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "cccp7-1024"
type: "Convolution"
bottom: "conv4"
top: "cccp7"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 1024
kernel_size: 1
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.05
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu11"
type: "ReLU"
bottom: "cccp7"
top: "cccp7"
}
layer {
name: "cccp8-1024"
type: "Convolution"
bottom: "cccp7"
top: "cccp8"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 2
kernel_size: 1
stride: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu12"
type: "ReLU"
bottom: "cccp8"
top: "cccp8"
}
layer {
name: "pool4"
type: "Pooling"
bottom: "cccp8"
top: "pool4"
pooling_param {
pool: AVE
kernel_size: 6
stride: 1
}
}
layer {
name: "accuracy"
type: "Accuracy"
bottom: "pool4"
bottom: "label"
top: "accuracy"
include {
phase: TEST
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "pool4"
bottom: "label"
top: "loss"
}
I1018 23:04:02.084880  3328 layer_factory.hpp:77] Creating layer val-data
I1018 23:04:02.085486  3328 net.cpp:94] Creating Layer val-data
I1018 23:04:02.085508  3328 net.cpp:409] val-data -> data
I1018 23:04:02.085528  3328 net.cpp:409] val-data -> label
I1018 23:04:02.085548  3328 data_transformer.cpp:25] Loading mean file from: /media/myuser/120Gb/DIGITS/digits/jobs/20160917-133511-8c62/mean.binaryproto
I1018 23:04:02.086392  3338 db_lmdb.cpp:35] Opened lmdb /media/myuser/120Gb/DIGITS/digits/jobs/20160917-133511-8c62/val_db
I1018 23:04:02.096029  3328 data_layer.cpp:76] output data size: 128,3,224,224
I1018 23:04:02.366956  3328 net.cpp:144] Setting up val-data
I1018 23:04:02.366991  3328 net.cpp:151] Top shape: 128 3 224 224 (19267584)
I1018 23:04:02.367002  3328 net.cpp:151] Top shape: 128 (128)
I1018 23:04:02.367009  3328 net.cpp:159] Memory required for data: 77070848
I1018 23:04:02.367020  3328 layer_factory.hpp:77] Creating layer label_val-data_1_split
I1018 23:04:02.367038  3328 net.cpp:94] Creating Layer label_val-data_1_split
I1018 23:04:02.367046  3328 net.cpp:435] label_val-data_1_split <- label
I1018 23:04:02.367058  3328 net.cpp:409] label_val-data_1_split -> label_val-data_1_split_0
I1018 23:04:02.367074  3328 net.cpp:409] label_val-data_1_split -> label_val-data_1_split_1
I1018 23:04:02.367137  3328 net.cpp:144] Setting up label_val-data_1_split
I1018 23:04:02.367147  3328 net.cpp:151] Top shape: 128 (128)
I1018 23:04:02.367156  3328 net.cpp:151] Top shape: 128 (128)
I1018 23:04:02.367164  3328 net.cpp:159] Memory required for data: 77071872
I1018 23:04:02.367172  3328 layer_factory.hpp:77] Creating layer conv1
I1018 23:04:02.367190  3328 net.cpp:94] Creating Layer conv1
I1018 23:04:02.367198  3328 net.cpp:435] conv1 <- data
I1018 23:04:02.367209  3328 net.cpp:409] conv1 -> conv1
I1018 23:04:02.416482  3328 net.cpp:144] Setting up conv1
I1018 23:04:02.416523  3328 net.cpp:151] Top shape: 128 96 54 54 (35831808)
I1018 23:04:02.416532  3328 net.cpp:159] Memory required for data: 220399104
I1018 23:04:02.416550  3328 layer_factory.hpp:77] Creating layer relu0
I1018 23:04:02.416565  3328 net.cpp:94] Creating Layer relu0
I1018 23:04:02.416574  3328 net.cpp:435] relu0 <- conv1
I1018 23:04:02.416584  3328 net.cpp:396] relu0 -> conv1 (in-place)
I1018 23:04:02.416601  3328 net.cpp:144] Setting up relu0
I1018 23:04:02.416610  3328 net.cpp:151] Top shape: 128 96 54 54 (35831808)
I1018 23:04:02.416617  3328 net.cpp:159] Memory required for data: 363726336
I1018 23:04:02.416625  3328 layer_factory.hpp:77] Creating layer cccp1
I1018 23:04:02.416643  3328 net.cpp:94] Creating Layer cccp1
I1018 23:04:02.416651  3328 net.cpp:435] cccp1 <- conv1
I1018 23:04:02.416662  3328 net.cpp:409] cccp1 -> cccp1
I1018 23:04:02.431618  3328 net.cpp:144] Setting up cccp1
I1018 23:04:02.431653  3328 net.cpp:151] Top shape: 128 96 54 54 (35831808)
I1018 23:04:02.431663  3328 net.cpp:159] Memory required for data: 507053568
I1018 23:04:02.431682  3328 layer_factory.hpp:77] Creating layer relu1
I1018 23:04:02.431697  3328 net.cpp:94] Creating Layer relu1
I1018 23:04:02.431706  3328 net.cpp:435] relu1 <- cccp1
I1018 23:04:02.431717  3328 net.cpp:396] relu1 -> cccp1 (in-place)
I1018 23:04:02.431735  3328 net.cpp:144] Setting up relu1
I1018 23:04:02.431743  3328 net.cpp:151] Top shape: 128 96 54 54 (35831808)
I1018 23:04:02.431751  3328 net.cpp:159] Memory required for data: 650380800
I1018 23:04:02.431758  3328 layer_factory.hpp:77] Creating layer cccp2
I1018 23:04:02.431776  3328 net.cpp:94] Creating Layer cccp2
I1018 23:04:02.431783  3328 net.cpp:435] cccp2 <- cccp1
I1018 23:04:02.431794  3328 net.cpp:409] cccp2 -> cccp2
I1018 23:04:02.443701  3328 net.cpp:144] Setting up cccp2
I1018 23:04:02.443738  3328 net.cpp:151] Top shape: 128 96 54 54 (35831808)
I1018 23:04:02.443745  3328 net.cpp:159] Memory required for data: 793708032
I1018 23:04:02.443765  3328 layer_factory.hpp:77] Creating layer relu2
I1018 23:04:02.443779  3328 net.cpp:94] Creating Layer relu2
I1018 23:04:02.443817  3328 net.cpp:435] relu2 <- cccp2
I1018 23:04:02.443828  3328 net.cpp:396] relu2 -> cccp2 (in-place)
I1018 23:04:02.443843  3328 net.cpp:144] Setting up relu2
I1018 23:04:02.443852  3328 net.cpp:151] Top shape: 128 96 54 54 (35831808)
I1018 23:04:02.443859  3328 net.cpp:159] Memory required for data: 937035264
I1018 23:04:02.443866  3328 layer_factory.hpp:77] Creating layer pool0
I1018 23:04:02.443881  3328 net.cpp:94] Creating Layer pool0
I1018 23:04:02.443889  3328 net.cpp:435] pool0 <- cccp2
I1018 23:04:02.443899  3328 net.cpp:409] pool0 -> pool0
I1018 23:04:02.443999  3328 net.cpp:144] Setting up pool0
I1018 23:04:02.444008  3328 net.cpp:151] Top shape: 128 96 27 27 (8957952)
I1018 23:04:02.444015  3328 net.cpp:159] Memory required for data: 972867072
I1018 23:04:02.444022  3328 layer_factory.hpp:77] Creating layer conv2
I1018 23:04:02.444038  3328 net.cpp:94] Creating Layer conv2
I1018 23:04:02.444046  3328 net.cpp:435] conv2 <- pool0
I1018 23:04:02.444056  3328 net.cpp:409] conv2 -> conv2
I1018 23:04:02.579324  3328 net.cpp:144] Setting up conv2
I1018 23:04:02.579367  3328 net.cpp:151] Top shape: 128 256 27 27 (23887872)
I1018 23:04:02.579375  3328 net.cpp:159] Memory required for data: 1068418560
I1018 23:04:02.579391  3328 layer_factory.hpp:77] Creating layer relu3
I1018 23:04:02.579406  3328 net.cpp:94] Creating Layer relu3
I1018 23:04:02.579416  3328 net.cpp:435] relu3 <- conv2
I1018 23:04:02.579427  3328 net.cpp:396] relu3 -> conv2 (in-place)
I1018 23:04:02.579442  3328 net.cpp:144] Setting up relu3
I1018 23:04:02.579452  3328 net.cpp:151] Top shape: 128 256 27 27 (23887872)
I1018 23:04:02.579459  3328 net.cpp:159] Memory required for data: 1163970048
I1018 23:04:02.579466  3328 layer_factory.hpp:77] Creating layer cccp3
I1018 23:04:02.579483  3328 net.cpp:94] Creating Layer cccp3
I1018 23:04:02.579499  3328 net.cpp:435] cccp3 <- conv2
I1018 23:04:02.579510  3328 net.cpp:409] cccp3 -> cccp3
I1018 23:04:02.596318  3328 net.cpp:144] Setting up cccp3
I1018 23:04:02.596364  3328 net.cpp:151] Top shape: 128 256 27 27 (23887872)
I1018 23:04:02.596371  3328 net.cpp:159] Memory required for data: 1259521536
I1018 23:04:02.596397  3328 layer_factory.hpp:77] Creating layer relu5
I1018 23:04:02.596415  3328 net.cpp:94] Creating Layer relu5
I1018 23:04:02.596426  3328 net.cpp:435] relu5 <- cccp3
I1018 23:04:02.596436  3328 net.cpp:396] relu5 -> cccp3 (in-place)
I1018 23:04:02.596457  3328 net.cpp:144] Setting up relu5
I1018 23:04:02.596465  3328 net.cpp:151] Top shape: 128 256 27 27 (23887872)
I1018 23:04:02.596472  3328 net.cpp:159] Memory required for data: 1355073024
I1018 23:04:02.596479  3328 layer_factory.hpp:77] Creating layer cccp4
I1018 23:04:02.596499  3328 net.cpp:94] Creating Layer cccp4
I1018 23:04:02.596508  3328 net.cpp:435] cccp4 <- cccp3
I1018 23:04:02.596518  3328 net.cpp:409] cccp4 -> cccp4
I1018 23:04:02.613251  3328 net.cpp:144] Setting up cccp4
I1018 23:04:02.613297  3328 net.cpp:151] Top shape: 128 256 27 27 (23887872)
I1018 23:04:02.613306  3328 net.cpp:159] Memory required for data: 1450624512
I1018 23:04:02.613325  3328 layer_factory.hpp:77] Creating layer relu6
I1018 23:04:02.613342  3328 net.cpp:94] Creating Layer relu6
I1018 23:04:02.613351  3328 net.cpp:435] relu6 <- cccp4
I1018 23:04:02.613363  3328 net.cpp:396] relu6 -> cccp4 (in-place)
I1018 23:04:02.613381  3328 net.cpp:144] Setting up relu6
I1018 23:04:02.613390  3328 net.cpp:151] Top shape: 128 256 27 27 (23887872)
I1018 23:04:02.613397  3328 net.cpp:159] Memory required for data: 1546176000
I1018 23:04:02.613404  3328 layer_factory.hpp:77] Creating layer pool2
I1018 23:04:02.613416  3328 net.cpp:94] Creating Layer pool2
I1018 23:04:02.613423  3328 net.cpp:435] pool2 <- cccp4
I1018 23:04:02.613433  3328 net.cpp:409] pool2 -> pool2
I1018 23:04:02.613554  3328 net.cpp:144] Setting up pool2
I1018 23:04:02.613564  3328 net.cpp:151] Top shape: 128 256 13 13 (5537792)
I1018 23:04:02.613571  3328 net.cpp:159] Memory required for data: 1568327168
I1018 23:04:02.613579  3328 layer_factory.hpp:77] Creating layer conv3
I1018 23:04:02.613639  3328 net.cpp:94] Creating Layer conv3
I1018 23:04:02.613648  3328 net.cpp:435] conv3 <- pool2
I1018 23:04:02.613659  3328 net.cpp:409] conv3 -> conv3
I1018 23:04:02.777976  3328 net.cpp:144] Setting up conv3
I1018 23:04:02.778026  3328 net.cpp:151] Top shape: 128 384 13 13 (8306688)
I1018 23:04:02.778035  3328 net.cpp:159] Memory required for data: 1601553920
I1018 23:04:02.778055  3328 layer_factory.hpp:77] Creating layer relu7
I1018 23:04:02.778074  3328 net.cpp:94] Creating Layer relu7
I1018 23:04:02.778084  3328 net.cpp:435] relu7 <- conv3
I1018 23:04:02.778095  3328 net.cpp:396] relu7 -> conv3 (in-place)
I1018 23:04:02.778115  3328 net.cpp:144] Setting up relu7
I1018 23:04:02.778126  3328 net.cpp:151] Top shape: 128 384 13 13 (8306688)
I1018 23:04:02.778132  3328 net.cpp:159] Memory required for data: 1634780672
I1018 23:04:02.778139  3328 layer_factory.hpp:77] Creating layer cccp5
I1018 23:04:02.778159  3328 net.cpp:94] Creating Layer cccp5
I1018 23:04:02.778167  3328 net.cpp:435] cccp5 <- conv3
I1018 23:04:02.778178  3328 net.cpp:409] cccp5 -> cccp5
I1018 23:04:02.797601  3328 net.cpp:144] Setting up cccp5
I1018 23:04:02.797641  3328 net.cpp:151] Top shape: 128 384 13 13 (8306688)
I1018 23:04:02.797649  3328 net.cpp:159] Memory required for data: 1668007424
I1018 23:04:02.797665  3328 layer_factory.hpp:77] Creating layer relu8
I1018 23:04:02.797680  3328 net.cpp:94] Creating Layer relu8
I1018 23:04:02.797689  3328 net.cpp:435] relu8 <- cccp5
I1018 23:04:02.797700  3328 net.cpp:396] relu8 -> cccp5 (in-place)
I1018 23:04:02.797718  3328 net.cpp:144] Setting up relu8
I1018 23:04:02.797726  3328 net.cpp:151] Top shape: 128 384 13 13 (8306688)
I1018 23:04:02.797734  3328 net.cpp:159] Memory required for data: 1701234176
I1018 23:04:02.797740  3328 layer_factory.hpp:77] Creating layer cccp6
I1018 23:04:02.797757  3328 net.cpp:94] Creating Layer cccp6
I1018 23:04:02.797765  3328 net.cpp:435] cccp6 <- cccp5
I1018 23:04:02.797776  3328 net.cpp:409] cccp6 -> cccp6
I1018 23:04:02.826128  3328 net.cpp:144] Setting up cccp6
I1018 23:04:02.826164  3328 net.cpp:151] Top shape: 128 384 13 13 (8306688)
I1018 23:04:02.826172  3328 net.cpp:159] Memory required for data: 1734460928
I1018 23:04:02.826195  3328 layer_factory.hpp:77] Creating layer relu9
I1018 23:04:02.826210  3328 net.cpp:94] Creating Layer relu9
I1018 23:04:02.826217  3328 net.cpp:435] relu9 <- cccp6
I1018 23:04:02.826228  3328 net.cpp:396] relu9 -> cccp6 (in-place)
I1018 23:04:02.826244  3328 net.cpp:144] Setting up relu9
I1018 23:04:02.826253  3328 net.cpp:151] Top shape: 128 384 13 13 (8306688)
I1018 23:04:02.826261  3328 net.cpp:159] Memory required for data: 1767687680
I1018 23:04:02.826267  3328 layer_factory.hpp:77] Creating layer pool3
I1018 23:04:02.826279  3328 net.cpp:94] Creating Layer pool3
I1018 23:04:02.826287  3328 net.cpp:435] pool3 <- cccp6
I1018 23:04:02.826297  3328 net.cpp:409] pool3 -> pool3
I1018 23:04:02.826391  3328 net.cpp:144] Setting up pool3
I1018 23:04:02.826401  3328 net.cpp:151] Top shape: 128 384 6 6 (1769472)
I1018 23:04:02.826408  3328 net.cpp:159] Memory required for data: 1774765568
I1018 23:04:02.826416  3328 layer_factory.hpp:77] Creating layer drop
I1018 23:04:02.826426  3328 net.cpp:94] Creating Layer drop
I1018 23:04:02.826434  3328 net.cpp:435] drop <- pool3
I1018 23:04:02.826443  3328 net.cpp:396] drop -> pool3 (in-place)
I1018 23:04:02.826472  3328 net.cpp:144] Setting up drop
I1018 23:04:02.826481  3328 net.cpp:151] Top shape: 128 384 6 6 (1769472)
I1018 23:04:02.826488  3328 net.cpp:159] Memory required for data: 1781843456
I1018 23:04:02.826495  3328 layer_factory.hpp:77] Creating layer conv4-1024
I1018 23:04:02.826511  3328 net.cpp:94] Creating Layer conv4-1024
I1018 23:04:02.826519  3328 net.cpp:435] conv4-1024 <- pool3
I1018 23:04:02.826530  3328 net.cpp:409] conv4-1024 -> conv4
I1018 23:04:03.074159  3328 net.cpp:144] Setting up conv4-1024
I1018 23:04:03.074200  3328 net.cpp:151] Top shape: 128 1024 6 6 (4718592)
I1018 23:04:03.074208  3328 net.cpp:159] Memory required for data: 1800717824
I1018 23:04:03.074257  3328 layer_factory.hpp:77] Creating layer relu10
I1018 23:04:03.074272  3328 net.cpp:94] Creating Layer relu10
I1018 23:04:03.074282  3328 net.cpp:435] relu10 <- conv4
I1018 23:04:03.074293  3328 net.cpp:396] relu10 -> conv4 (in-place)
I1018 23:04:03.074311  3328 net.cpp:144] Setting up relu10
I1018 23:04:03.074319  3328 net.cpp:151] Top shape: 128 1024 6 6 (4718592)
I1018 23:04:03.074326  3328 net.cpp:159] Memory required for data: 1819592192
I1018 23:04:03.074333  3328 layer_factory.hpp:77] Creating layer cccp7-1024
I1018 23:04:03.074350  3328 net.cpp:94] Creating Layer cccp7-1024
I1018 23:04:03.074358  3328 net.cpp:435] cccp7-1024 <- conv4
I1018 23:04:03.074368  3328 net.cpp:409] cccp7-1024 -> cccp7
I1018 23:04:03.176852  3328 net.cpp:144] Setting up cccp7-1024
I1018 23:04:03.176901  3328 net.cpp:151] Top shape: 128 1024 6 6 (4718592)
I1018 23:04:03.176910  3328 net.cpp:159] Memory required for data: 1838466560
I1018 23:04:03.176925  3328 layer_factory.hpp:77] Creating layer relu11
I1018 23:04:03.176939  3328 net.cpp:94] Creating Layer relu11
I1018 23:04:03.176949  3328 net.cpp:435] relu11 <- cccp7
I1018 23:04:03.176959  3328 net.cpp:396] relu11 -> cccp7 (in-place)
I1018 23:04:03.176975  3328 net.cpp:144] Setting up relu11
I1018 23:04:03.176985  3328 net.cpp:151] Top shape: 128 1024 6 6 (4718592)
I1018 23:04:03.176991  3328 net.cpp:159] Memory required for data: 1857340928
I1018 23:04:03.176998  3328 layer_factory.hpp:77] Creating layer cccp8-1024
I1018 23:04:03.177014  3328 net.cpp:94] Creating Layer cccp8-1024
I1018 23:04:03.177022  3328 net.cpp:435] cccp8-1024 <- cccp7
I1018 23:04:03.177032  3328 net.cpp:409] cccp8-1024 -> cccp8
I1018 23:04:03.178349  3328 net.cpp:144] Setting up cccp8-1024
I1018 23:04:03.178360  3328 net.cpp:151] Top shape: 128 2 6 6 (9216)
I1018 23:04:03.178367  3328 net.cpp:159] Memory required for data: 1857377792
I1018 23:04:03.178378  3328 layer_factory.hpp:77] Creating layer relu12
I1018 23:04:03.178387  3328 net.cpp:94] Creating Layer relu12
I1018 23:04:03.178395  3328 net.cpp:435] relu12 <- cccp8
I1018 23:04:03.178405  3328 net.cpp:396] relu12 -> cccp8 (in-place)
I1018 23:04:03.178416  3328 net.cpp:144] Setting up relu12
I1018 23:04:03.178424  3328 net.cpp:151] Top shape: 128 2 6 6 (9216)
I1018 23:04:03.178431  3328 net.cpp:159] Memory required for data: 1857414656
I1018 23:04:03.178438  3328 layer_factory.hpp:77] Creating layer pool4
I1018 23:04:03.178449  3328 net.cpp:94] Creating Layer pool4
I1018 23:04:03.178457  3328 net.cpp:435] pool4 <- cccp8
I1018 23:04:03.178467  3328 net.cpp:409] pool4 -> pool4
I1018 23:04:03.178501  3328 net.cpp:144] Setting up pool4
I1018 23:04:03.178510  3328 net.cpp:151] Top shape: 128 2 1 1 (256)
I1018 23:04:03.178517  3328 net.cpp:159] Memory required for data: 1857415680
I1018 23:04:03.178524  3328 layer_factory.hpp:77] Creating layer pool4_pool4_0_split
I1018 23:04:03.178534  3328 net.cpp:94] Creating Layer pool4_pool4_0_split
I1018 23:04:03.178541  3328 net.cpp:435] pool4_pool4_0_split <- pool4
I1018 23:04:03.178550  3328 net.cpp:409] pool4_pool4_0_split -> pool4_pool4_0_split_0
I1018 23:04:03.178561  3328 net.cpp:409] pool4_pool4_0_split -> pool4_pool4_0_split_1
I1018 23:04:03.178607  3328 net.cpp:144] Setting up pool4_pool4_0_split
I1018 23:04:03.178617  3328 net.cpp:151] Top shape: 128 2 1 1 (256)
I1018 23:04:03.178625  3328 net.cpp:151] Top shape: 128 2 1 1 (256)
I1018 23:04:03.178632  3328 net.cpp:159] Memory required for data: 1857417728
I1018 23:04:03.178638  3328 layer_factory.hpp:77] Creating layer accuracy
I1018 23:04:03.178658  3328 net.cpp:94] Creating Layer accuracy
I1018 23:04:03.178664  3328 net.cpp:435] accuracy <- pool4_pool4_0_split_0
I1018 23:04:03.178673  3328 net.cpp:435] accuracy <- label_val-data_1_split_0
I1018 23:04:03.178683  3328 net.cpp:409] accuracy -> accuracy
I1018 23:04:03.178695  3328 net.cpp:144] Setting up accuracy
I1018 23:04:03.178704  3328 net.cpp:151] Top shape: (1)
I1018 23:04:03.178711  3328 net.cpp:159] Memory required for data: 1857417732
I1018 23:04:03.178719  3328 layer_factory.hpp:77] Creating layer loss
I1018 23:04:03.178755  3328 net.cpp:94] Creating Layer loss
I1018 23:04:03.178763  3328 net.cpp:435] loss <- pool4_pool4_0_split_1
I1018 23:04:03.178771  3328 net.cpp:435] loss <- label_val-data_1_split_1
I1018 23:04:03.178781  3328 net.cpp:409] loss -> loss
I1018 23:04:03.178792  3328 layer_factory.hpp:77] Creating layer loss
I1018 23:04:03.178905  3328 net.cpp:144] Setting up loss
I1018 23:04:03.178915  3328 net.cpp:151] Top shape: (1)
I1018 23:04:03.178921  3328 net.cpp:154]     with loss weight 1
I1018 23:04:03.178938  3328 net.cpp:159] Memory required for data: 1857417736
I1018 23:04:03.178946  3328 net.cpp:220] loss needs backward computation.
I1018 23:04:03.178952  3328 net.cpp:222] accuracy does not need backward computation.
I1018 23:04:03.178961  3328 net.cpp:220] pool4_pool4_0_split needs backward computation.
I1018 23:04:03.178968  3328 net.cpp:220] pool4 needs backward computation.
I1018 23:04:03.178974  3328 net.cpp:220] relu12 needs backward computation.
I1018 23:04:03.178982  3328 net.cpp:220] cccp8-1024 needs backward computation.
I1018 23:04:03.178988  3328 net.cpp:220] relu11 needs backward computation.
I1018 23:04:03.178994  3328 net.cpp:220] cccp7-1024 needs backward computation.
I1018 23:04:03.179003  3328 net.cpp:220] relu10 needs backward computation.
I1018 23:04:03.179008  3328 net.cpp:220] conv4-1024 needs backward computation.
I1018 23:04:03.179015  3328 net.cpp:220] drop needs backward computation.
I1018 23:04:03.179023  3328 net.cpp:220] pool3 needs backward computation.
I1018 23:04:03.179029  3328 net.cpp:220] relu9 needs backward computation.
I1018 23:04:03.179036  3328 net.cpp:220] cccp6 needs backward computation.
I1018 23:04:03.179044  3328 net.cpp:220] relu8 needs backward computation.
I1018 23:04:03.179050  3328 net.cpp:220] cccp5 needs backward computation.
I1018 23:04:03.179057  3328 net.cpp:220] relu7 needs backward computation.
I1018 23:04:03.179064  3328 net.cpp:220] conv3 needs backward computation.
I1018 23:04:03.179071  3328 net.cpp:220] pool2 needs backward computation.
I1018 23:04:03.179078  3328 net.cpp:220] relu6 needs backward computation.
I1018 23:04:03.179085  3328 net.cpp:220] cccp4 needs backward computation.
I1018 23:04:03.179091  3328 net.cpp:220] relu5 needs backward computation.
I1018 23:04:03.179098  3328 net.cpp:220] cccp3 needs backward computation.
I1018 23:04:03.179105  3328 net.cpp:220] relu3 needs backward computation.
I1018 23:04:03.179112  3328 net.cpp:220] conv2 needs backward computation.
I1018 23:04:03.179119  3328 net.cpp:220] pool0 needs backward computation.
I1018 23:04:03.179126  3328 net.cpp:220] relu2 needs backward computation.
I1018 23:04:03.179133  3328 net.cpp:220] cccp2 needs backward computation.
I1018 23:04:03.179141  3328 net.cpp:220] relu1 needs backward computation.
I1018 23:04:03.179147  3328 net.cpp:220] cccp1 needs backward computation.
I1018 23:04:03.179153  3328 net.cpp:220] relu0 needs backward computation.
I1018 23:04:03.179160  3328 net.cpp:220] conv1 needs backward computation.
I1018 23:04:03.179168  3328 net.cpp:222] label_val-data_1_split does not need backward computation.
I1018 23:04:03.179175  3328 net.cpp:222] val-data does not need backward computation.
I1018 23:04:03.179183  3328 net.cpp:264] This network produces output accuracy
I1018 23:04:03.179189  3328 net.cpp:264] This network produces output loss
I1018 23:04:03.179214  3328 net.cpp:284] Network initialization done.
I1018 23:04:03.179369  3328 solver.cpp:60] Solver scaffolding done.
I1018 23:04:03.180563  3328 caffe.cpp:231] Starting Optimization
I1018 23:04:03.180575  3328 solver.cpp:304] Solving
I1018 23:04:03.180582  3328 solver.cpp:305] Learning Rate Policy: poly
I1018 23:04:03.183578  3328 solver.cpp:362] Iteration 0, Testing net (#0)
I1018 23:04:03.183595  3328 net.cpp:723] Ignoring source layer train-data
I1018 23:04:04.723604  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1018 23:04:14.956070  3328 solver.cpp:429]     Test net output #0: accuracy = 0.498633
I1018 23:04:14.956117  3328 solver.cpp:429]     Test net output #1: loss = 0.69318 (* 1 = 0.69318 loss)
I1018 23:04:27.503939  3328 solver.cpp:242] Iteration 0 (0 iter/s, 24.323s/19 iter), loss = 0.692871
I1018 23:04:27.504617  3328 solver.cpp:261]     Train net output #0: loss = 0.692967 (* 1 = 0.692967 loss)
I1018 23:04:27.504652  3328 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I1018 23:04:53.067602  3328 solver.cpp:242] Iteration 19 (0.743273 iter/s, 25.5626s/19 iter), loss = 0.689882
I1018 23:04:53.067685  3328 solver.cpp:261]     Train net output #0: loss = 0.688308 (* 1 = 0.688308 loss)
I1018 23:04:53.067704  3328 sgd_solver.cpp:106] Iteration 19, lr = 0.00497983
I1018 23:05:18.451566  3328 solver.cpp:242] Iteration 38 (0.748517 iter/s, 25.3835s/19 iter), loss = 0.683297
I1018 23:05:18.451668  3328 solver.cpp:261]     Train net output #0: loss = 0.684105 (* 1 = 0.684105 loss)
I1018 23:05:18.451688  3328 sgd_solver.cpp:106] Iteration 38, lr = 0.00495966
I1018 23:05:43.544070  3328 solver.cpp:242] Iteration 57 (0.757212 iter/s, 25.092s/19 iter), loss = 0.680384
I1018 23:05:43.544144  3328 solver.cpp:261]     Train net output #0: loss = 0.66729 (* 1 = 0.66729 loss)
I1018 23:05:43.544163  3328 sgd_solver.cpp:106] Iteration 57, lr = 0.00493949
I1018 23:06:08.716528  3328 solver.cpp:242] Iteration 76 (0.754806 iter/s, 25.172s/19 iter), loss = 0.64918
I1018 23:06:08.718205  3328 solver.cpp:261]     Train net output #0: loss = 0.656986 (* 1 = 0.656986 loss)
I1018 23:06:08.718233  3328 sgd_solver.cpp:106] Iteration 76, lr = 0.00491932
I1018 23:06:33.986156  3328 solver.cpp:242] Iteration 95 (0.751951 iter/s, 25.2676s/19 iter), loss = 0.671488
I1018 23:06:33.986217  3328 solver.cpp:261]     Train net output #0: loss = 0.679371 (* 1 = 0.679371 loss)
I1018 23:06:33.986235  3328 sgd_solver.cpp:106] Iteration 95, lr = 0.00489915
I1018 23:06:58.800307  3328 solver.cpp:242] Iteration 114 (0.765705 iter/s, 24.8137s/19 iter), loss = 0.698714
I1018 23:06:58.800554  3328 solver.cpp:261]     Train net output #0: loss = 0.786642 (* 1 = 0.786642 loss)
I1018 23:06:58.800572  3328 sgd_solver.cpp:106] Iteration 114, lr = 0.00487898
I1018 23:07:23.516574  3328 solver.cpp:242] Iteration 133 (0.768743 iter/s, 24.7157s/19 iter), loss = 0.623906
I1018 23:07:23.516633  3328 solver.cpp:261]     Train net output #0: loss = 0.654093 (* 1 = 0.654093 loss)
I1018 23:07:23.516651  3328 sgd_solver.cpp:106] Iteration 133, lr = 0.00485881
I1018 23:07:48.819582  3328 solver.cpp:242] Iteration 152 (0.750912 iter/s, 25.3026s/19 iter), loss = 0.598813
I1018 23:07:48.819696  3328 solver.cpp:261]     Train net output #0: loss = 0.629242 (* 1 = 0.629242 loss)
I1018 23:07:48.819716  3328 sgd_solver.cpp:106] Iteration 152, lr = 0.00483864
I1018 23:07:54.176172  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_157.caffemodel
I1018 23:07:54.360966  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_157.solverstate
I1018 23:07:54.452020  3328 solver.cpp:362] Iteration 157, Testing net (#0)
I1018 23:07:54.452054  3328 net.cpp:723] Ignoring source layer train-data
I1018 23:08:05.359014  3328 solver.cpp:429]     Test net output #0: accuracy = 0.653125
I1018 23:08:05.359071  3328 solver.cpp:429]     Test net output #1: loss = 0.619255 (* 1 = 0.619255 loss)
I1018 23:08:24.903579  3328 solver.cpp:242] Iteration 171 (0.526559 iter/s, 36.0834s/19 iter), loss = 0.613966
I1018 23:08:24.904142  3328 solver.cpp:261]     Train net output #0: loss = 0.613042 (* 1 = 0.613042 loss)
I1018 23:08:24.904165  3328 sgd_solver.cpp:106] Iteration 171, lr = 0.00481847
I1018 23:08:50.155571  3328 solver.cpp:242] Iteration 190 (0.752444 iter/s, 25.2511s/19 iter), loss = 0.599502
I1018 23:08:50.155637  3328 solver.cpp:261]     Train net output #0: loss = 0.619402 (* 1 = 0.619402 loss)
I1018 23:08:50.155655  3328 sgd_solver.cpp:106] Iteration 190, lr = 0.0047983
I1018 23:09:15.159240  3328 solver.cpp:242] Iteration 209 (0.759902 iter/s, 25.0032s/19 iter), loss = 0.603136
I1018 23:09:15.159436  3328 solver.cpp:261]     Train net output #0: loss = 0.629702 (* 1 = 0.629702 loss)
I1018 23:09:15.159456  3328 sgd_solver.cpp:106] Iteration 209, lr = 0.00477813
I1018 23:09:40.125573  3328 solver.cpp:242] Iteration 228 (0.761042 iter/s, 24.9658s/19 iter), loss = 0.585989
I1018 23:09:40.125636  3328 solver.cpp:261]     Train net output #0: loss = 0.578139 (* 1 = 0.578139 loss)
I1018 23:09:40.125654  3328 sgd_solver.cpp:106] Iteration 228, lr = 0.00475796
I1018 23:09:47.544234  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1018 23:10:05.655226  3328 solver.cpp:242] Iteration 247 (0.744245 iter/s, 25.5292s/19 iter), loss = 0.583373
I1018 23:10:05.655288  3328 solver.cpp:261]     Train net output #0: loss = 0.532052 (* 1 = 0.532052 loss)
I1018 23:10:05.655306  3328 sgd_solver.cpp:106] Iteration 247, lr = 0.00473779
I1018 23:10:30.658527  3328 solver.cpp:242] Iteration 266 (0.759913 iter/s, 25.0029s/19 iter), loss = 0.566218
I1018 23:10:30.667579  3328 solver.cpp:261]     Train net output #0: loss = 0.56947 (* 1 = 0.56947 loss)
I1018 23:10:30.667619  3328 sgd_solver.cpp:106] Iteration 266, lr = 0.00471762
I1018 23:10:55.645778  3328 solver.cpp:242] Iteration 285 (0.760674 iter/s, 24.9779s/19 iter), loss = 0.605019
I1018 23:10:55.645844  3328 solver.cpp:261]     Train net output #0: loss = 0.593155 (* 1 = 0.593155 loss)
I1018 23:10:55.645864  3328 sgd_solver.cpp:106] Iteration 285, lr = 0.00469745
I1018 23:11:20.756582  3328 solver.cpp:242] Iteration 304 (0.756659 iter/s, 25.1104s/19 iter), loss = 0.566859
I1018 23:11:20.759554  3328 solver.cpp:261]     Train net output #0: loss = 0.503592 (* 1 = 0.503592 loss)
I1018 23:11:20.759583  3328 sgd_solver.cpp:106] Iteration 304, lr = 0.00467728
I1018 23:11:32.688405  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_314.caffemodel
I1018 23:11:32.853163  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_314.solverstate
I1018 23:11:32.906384  3328 solver.cpp:362] Iteration 314, Testing net (#0)
I1018 23:11:32.906419  3328 net.cpp:723] Ignoring source layer train-data
I1018 23:11:44.006615  3328 solver.cpp:429]     Test net output #0: accuracy = 0.713281
I1018 23:11:44.006664  3328 solver.cpp:429]     Test net output #1: loss = 0.564463 (* 1 = 0.564463 loss)
I1018 23:11:57.062769  3328 solver.cpp:242] Iteration 323 (0.523377 iter/s, 36.3027s/19 iter), loss = 0.552909
I1018 23:11:57.062914  3328 solver.cpp:261]     Train net output #0: loss = 0.562653 (* 1 = 0.562653 loss)
I1018 23:11:57.062932  3328 sgd_solver.cpp:106] Iteration 323, lr = 0.00465711
I1018 23:12:22.376616  3328 solver.cpp:242] Iteration 342 (0.750593 iter/s, 25.3133s/19 iter), loss = 0.538116
I1018 23:12:22.376682  3328 solver.cpp:261]     Train net output #0: loss = 0.61069 (* 1 = 0.61069 loss)
I1018 23:12:22.376700  3328 sgd_solver.cpp:106] Iteration 342, lr = 0.00463694
I1018 23:12:47.730264  3328 solver.cpp:242] Iteration 361 (0.749412 iter/s, 25.3532s/19 iter), loss = 0.589946
I1018 23:12:47.735551  3328 solver.cpp:261]     Train net output #0: loss = 0.589428 (* 1 = 0.589428 loss)
I1018 23:12:47.735582  3328 sgd_solver.cpp:106] Iteration 361, lr = 0.00461677
I1018 23:13:12.708309  3328 solver.cpp:242] Iteration 380 (0.760841 iter/s, 24.9724s/19 iter), loss = 0.551616
I1018 23:13:12.708372  3328 solver.cpp:261]     Train net output #0: loss = 0.557624 (* 1 = 0.557624 loss)
I1018 23:13:12.708390  3328 sgd_solver.cpp:106] Iteration 380, lr = 0.0045966
I1018 23:13:37.985348  3328 solver.cpp:242] Iteration 399 (0.751683 iter/s, 25.2766s/19 iter), loss = 0.611744
I1018 23:13:37.991447  3328 solver.cpp:261]     Train net output #0: loss = 0.636937 (* 1 = 0.636937 loss)
I1018 23:13:37.991503  3328 sgd_solver.cpp:106] Iteration 399, lr = 0.00457643
I1018 23:14:02.740996  3328 solver.cpp:242] Iteration 418 (0.767701 iter/s, 24.7492s/19 iter), loss = 0.5375
I1018 23:14:02.741057  3328 solver.cpp:261]     Train net output #0: loss = 0.487212 (* 1 = 0.487212 loss)
I1018 23:14:02.741075  3328 sgd_solver.cpp:106] Iteration 418, lr = 0.00455626
I1018 23:14:28.079254  3328 solver.cpp:242] Iteration 437 (0.749869 iter/s, 25.3378s/19 iter), loss = 0.636006
I1018 23:14:28.079519  3328 solver.cpp:261]     Train net output #0: loss = 0.668643 (* 1 = 0.668643 loss)
I1018 23:14:28.079540  3328 sgd_solver.cpp:106] Iteration 437, lr = 0.00453609
I1018 23:14:53.227059  3328 solver.cpp:242] Iteration 456 (0.755553 iter/s, 25.1472s/19 iter), loss = 0.576454
I1018 23:14:53.227119  3328 solver.cpp:261]     Train net output #0: loss = 0.567797 (* 1 = 0.567797 loss)
I1018 23:14:53.227138  3328 sgd_solver.cpp:106] Iteration 456, lr = 0.00451592
I1018 23:15:11.958247  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_471.caffemodel
I1018 23:15:12.138659  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_471.solverstate
I1018 23:15:12.249037  3328 solver.cpp:362] Iteration 471, Testing net (#0)
I1018 23:15:12.249071  3328 net.cpp:723] Ignoring source layer train-data
I1018 23:15:18.587138  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1018 23:15:23.014989  3328 solver.cpp:429]     Test net output #0: accuracy = 0.720898
I1018 23:15:23.015038  3328 solver.cpp:429]     Test net output #1: loss = 0.551986 (* 1 = 0.551986 loss)
I1018 23:15:29.557214  3328 solver.cpp:242] Iteration 475 (0.522992 iter/s, 36.3295s/19 iter), loss = 0.54223
I1018 23:15:29.557286  3328 solver.cpp:261]     Train net output #0: loss = 0.537731 (* 1 = 0.537731 loss)
I1018 23:15:29.557307  3328 sgd_solver.cpp:106] Iteration 475, lr = 0.00449575
I1018 23:15:55.108773  3328 solver.cpp:242] Iteration 494 (0.74361 iter/s, 25.551s/19 iter), loss = 0.522524
I1018 23:15:55.109994  3328 solver.cpp:261]     Train net output #0: loss = 0.498369 (* 1 = 0.498369 loss)
I1018 23:15:55.110016  3328 sgd_solver.cpp:106] Iteration 494, lr = 0.00447558
I1018 23:16:19.903203  3328 solver.cpp:242] Iteration 513 (0.766352 iter/s, 24.7928s/19 iter), loss = 0.627834
I1018 23:16:19.903264  3328 solver.cpp:261]     Train net output #0: loss = 0.590503 (* 1 = 0.590503 loss)
I1018 23:16:19.903282  3328 sgd_solver.cpp:106] Iteration 513, lr = 0.00445541
I1018 23:16:44.782912  3328 solver.cpp:242] Iteration 532 (0.76369 iter/s, 24.8792s/19 iter), loss = 0.501063
I1018 23:16:44.783033  3328 solver.cpp:261]     Train net output #0: loss = 0.479452 (* 1 = 0.479452 loss)
I1018 23:16:44.783061  3328 sgd_solver.cpp:106] Iteration 532, lr = 0.00443524
I1018 23:17:10.084972  3328 solver.cpp:242] Iteration 551 (0.750943 iter/s, 25.3015s/19 iter), loss = 0.509054
I1018 23:17:10.085045  3328 solver.cpp:261]     Train net output #0: loss = 0.446234 (* 1 = 0.446234 loss)
I1018 23:17:10.085065  3328 sgd_solver.cpp:106] Iteration 551, lr = 0.00441507
I1018 23:17:35.131851  3328 solver.cpp:242] Iteration 570 (0.758593 iter/s, 25.0464s/19 iter), loss = 0.454296
I1018 23:17:35.131963  3328 solver.cpp:261]     Train net output #0: loss = 0.449969 (* 1 = 0.449969 loss)
I1018 23:17:35.131981  3328 sgd_solver.cpp:106] Iteration 570, lr = 0.0043949
I1018 23:18:00.114833  3328 solver.cpp:242] Iteration 589 (0.760534 iter/s, 24.9824s/19 iter), loss = 0.49215
I1018 23:18:00.114902  3328 solver.cpp:261]     Train net output #0: loss = 0.437418 (* 1 = 0.437418 loss)
I1018 23:18:00.114920  3328 sgd_solver.cpp:106] Iteration 589, lr = 0.00437473
I1018 23:18:25.205602  3328 solver.cpp:242] Iteration 608 (0.757265 iter/s, 25.0903s/19 iter), loss = 0.476165
I1018 23:18:25.219575  3328 solver.cpp:261]     Train net output #0: loss = 0.523109 (* 1 = 0.523109 loss)
I1018 23:18:25.219619  3328 sgd_solver.cpp:106] Iteration 608, lr = 0.00435456
I1018 23:18:50.246793  3328 solver.cpp:242] Iteration 627 (0.759185 iter/s, 25.0268s/19 iter), loss = 0.492972
I1018 23:18:50.246851  3328 solver.cpp:261]     Train net output #0: loss = 0.408368 (* 1 = 0.408368 loss)
I1018 23:18:50.246870  3328 sgd_solver.cpp:106] Iteration 627, lr = 0.00433439
I1018 23:18:50.247499  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_628.caffemodel
I1018 23:18:50.594511  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_628.solverstate
I1018 23:18:50.704125  3328 solver.cpp:362] Iteration 628, Testing net (#0)
I1018 23:18:50.704159  3328 net.cpp:723] Ignoring source layer train-data
I1018 23:19:01.634208  3328 solver.cpp:429]     Test net output #0: accuracy = 0.750586
I1018 23:19:01.634503  3328 solver.cpp:429]     Test net output #1: loss = 0.502364 (* 1 = 0.502364 loss)
I1018 23:19:26.974661  3328 solver.cpp:242] Iteration 646 (0.517328 iter/s, 36.7272s/19 iter), loss = 0.514334
I1018 23:19:26.974735  3328 solver.cpp:261]     Train net output #0: loss = 0.477689 (* 1 = 0.477689 loss)
I1018 23:19:26.974755  3328 sgd_solver.cpp:106] Iteration 646, lr = 0.00431422
I1018 23:19:51.871567  3328 solver.cpp:242] Iteration 665 (0.763162 iter/s, 24.8964s/19 iter), loss = 0.595167
I1018 23:19:51.871686  3328 solver.cpp:261]     Train net output #0: loss = 0.610654 (* 1 = 0.610654 loss)
I1018 23:19:51.871706  3328 sgd_solver.cpp:106] Iteration 665, lr = 0.00429406
I1018 23:20:17.052592  3328 solver.cpp:242] Iteration 684 (0.754552 iter/s, 25.1805s/19 iter), loss = 0.570944
I1018 23:20:17.052650  3328 solver.cpp:261]     Train net output #0: loss = 0.579433 (* 1 = 0.579433 loss)
I1018 23:20:17.052669  3328 sgd_solver.cpp:106] Iteration 684, lr = 0.00427389
I1018 23:20:42.170861  3328 solver.cpp:242] Iteration 703 (0.756436 iter/s, 25.1178s/19 iter), loss = 0.481388
I1018 23:20:42.170970  3328 solver.cpp:261]     Train net output #0: loss = 0.503784 (* 1 = 0.503784 loss)
I1018 23:20:42.170989  3328 sgd_solver.cpp:106] Iteration 703, lr = 0.00425372
I1018 23:20:49.491961  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1018 23:21:07.037456  3328 solver.cpp:242] Iteration 722 (0.764093 iter/s, 24.8661s/19 iter), loss = 0.447083
I1018 23:21:07.037519  3328 solver.cpp:261]     Train net output #0: loss = 0.417002 (* 1 = 0.417002 loss)
I1018 23:21:07.037539  3328 sgd_solver.cpp:106] Iteration 722, lr = 0.00423355
I1018 23:21:32.165707  3328 solver.cpp:242] Iteration 741 (0.756135 iter/s, 25.1278s/19 iter), loss = 0.454533
I1018 23:21:32.167181  3328 solver.cpp:261]     Train net output #0: loss = 0.449193 (* 1 = 0.449193 loss)
I1018 23:21:32.167207  3328 sgd_solver.cpp:106] Iteration 741, lr = 0.00421338
I1018 23:21:57.195215  3328 solver.cpp:242] Iteration 760 (0.759161 iter/s, 25.0276s/19 iter), loss = 0.448256
I1018 23:21:57.195272  3328 solver.cpp:261]     Train net output #0: loss = 0.485227 (* 1 = 0.485227 loss)
I1018 23:21:57.195291  3328 sgd_solver.cpp:106] Iteration 760, lr = 0.00419321
I1018 23:22:22.023109  3328 solver.cpp:242] Iteration 779 (0.765282 iter/s, 24.8274s/19 iter), loss = 0.442534
I1018 23:22:22.034349  3328 solver.cpp:261]     Train net output #0: loss = 0.464227 (* 1 = 0.464227 loss)
I1018 23:22:22.034391  3328 sgd_solver.cpp:106] Iteration 779, lr = 0.00417304
I1018 23:22:28.964164  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_785.caffemodel
I1018 23:22:29.255239  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_785.solverstate
I1018 23:22:29.321022  3328 solver.cpp:362] Iteration 785, Testing net (#0)
I1018 23:22:29.321060  3328 net.cpp:723] Ignoring source layer train-data
I1018 23:22:40.236958  3328 solver.cpp:429]     Test net output #0: accuracy = 0.787695
I1018 23:22:40.237005  3328 solver.cpp:429]     Test net output #1: loss = 0.451667 (* 1 = 0.451667 loss)
I1018 23:22:58.393573  3328 solver.cpp:242] Iteration 798 (0.522572 iter/s, 36.3587s/19 iter), loss = 0.464941
I1018 23:22:58.393712  3328 solver.cpp:261]     Train net output #0: loss = 0.469734 (* 1 = 0.469734 loss)
I1018 23:22:58.393733  3328 sgd_solver.cpp:106] Iteration 798, lr = 0.00415287
I1018 23:23:23.337538  3328 solver.cpp:242] Iteration 817 (0.761725 iter/s, 24.9434s/19 iter), loss = 0.39574
I1018 23:23:23.337602  3328 solver.cpp:261]     Train net output #0: loss = 0.378163 (* 1 = 0.378163 loss)
I1018 23:23:23.337621  3328 sgd_solver.cpp:106] Iteration 817, lr = 0.0041327
I1018 23:23:48.771570  3328 solver.cpp:242] Iteration 836 (0.747045 iter/s, 25.4335s/19 iter), loss = 0.413219
I1018 23:23:48.771801  3328 solver.cpp:261]     Train net output #0: loss = 0.480888 (* 1 = 0.480888 loss)
I1018 23:23:48.771823  3328 sgd_solver.cpp:106] Iteration 836, lr = 0.00411253
I1018 23:24:14.031282  3328 solver.cpp:242] Iteration 855 (0.752206 iter/s, 25.2591s/19 iter), loss = 0.409271
I1018 23:24:14.031342  3328 solver.cpp:261]     Train net output #0: loss = 0.404072 (* 1 = 0.404072 loss)
I1018 23:24:14.031360  3328 sgd_solver.cpp:106] Iteration 855, lr = 0.00409236
I1018 23:24:38.981246  3328 solver.cpp:242] Iteration 874 (0.761539 iter/s, 24.9495s/19 iter), loss = 0.387214
I1018 23:24:38.981370  3328 solver.cpp:261]     Train net output #0: loss = 0.364418 (* 1 = 0.364418 loss)
I1018 23:24:38.981396  3328 sgd_solver.cpp:106] Iteration 874, lr = 0.00407219
I1018 23:25:04.439571  3328 solver.cpp:242] Iteration 893 (0.746334 iter/s, 25.4578s/19 iter), loss = 0.448985
I1018 23:25:04.439633  3328 solver.cpp:261]     Train net output #0: loss = 0.394038 (* 1 = 0.394038 loss)
I1018 23:25:04.439652  3328 sgd_solver.cpp:106] Iteration 893, lr = 0.00405202
I1018 23:25:29.439476  3328 solver.cpp:242] Iteration 912 (0.760018 iter/s, 24.9994s/19 iter), loss = 0.395665
I1018 23:25:29.439602  3328 solver.cpp:261]     Train net output #0: loss = 0.4507 (* 1 = 0.4507 loss)
I1018 23:25:29.439621  3328 sgd_solver.cpp:106] Iteration 912, lr = 0.00403185
I1018 23:25:54.611567  3328 solver.cpp:242] Iteration 931 (0.75482 iter/s, 25.1716s/19 iter), loss = 0.382877
I1018 23:25:54.611635  3328 solver.cpp:261]     Train net output #0: loss = 0.451788 (* 1 = 0.451788 loss)
I1018 23:25:54.611654  3328 sgd_solver.cpp:106] Iteration 931, lr = 0.00401168
I1018 23:26:08.017947  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_942.caffemodel
I1018 23:26:08.194489  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_942.solverstate
I1018 23:26:08.263877  3328 solver.cpp:362] Iteration 942, Testing net (#0)
I1018 23:26:08.263911  3328 net.cpp:723] Ignoring source layer train-data
I1018 23:26:19.070415  3328 solver.cpp:429]     Test net output #0: accuracy = 0.835352
I1018 23:26:19.070477  3328 solver.cpp:429]     Test net output #1: loss = 0.389635 (* 1 = 0.389635 loss)
I1018 23:26:20.028170  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1018 23:26:30.835541  3328 solver.cpp:242] Iteration 950 (0.524524 iter/s, 36.2233s/19 iter), loss = 0.413025
I1018 23:26:30.835602  3328 solver.cpp:261]     Train net output #0: loss = 0.451012 (* 1 = 0.451012 loss)
I1018 23:26:30.835620  3328 sgd_solver.cpp:106] Iteration 950, lr = 0.00399151
I1018 23:26:55.778055  3328 solver.cpp:242] Iteration 969 (0.761766 iter/s, 24.942s/19 iter), loss = 0.395798
I1018 23:26:55.780490  3328 solver.cpp:261]     Train net output #0: loss = 0.441682 (* 1 = 0.441682 loss)
I1018 23:26:55.780510  3328 sgd_solver.cpp:106] Iteration 969, lr = 0.00397134
I1018 23:27:21.287256  3328 solver.cpp:242] Iteration 988 (0.744913 iter/s, 25.5063s/19 iter), loss = 0.39548
I1018 23:27:21.287317  3328 solver.cpp:261]     Train net output #0: loss = 0.347149 (* 1 = 0.347149 loss)
I1018 23:27:21.287334  3328 sgd_solver.cpp:106] Iteration 988, lr = 0.00395117
I1018 23:27:46.292805  3328 solver.cpp:242] Iteration 1007 (0.759846 iter/s, 25.0051s/19 iter), loss = 0.445946
I1018 23:27:46.292913  3328 solver.cpp:261]     Train net output #0: loss = 0.442675 (* 1 = 0.442675 loss)
I1018 23:27:46.292932  3328 sgd_solver.cpp:106] Iteration 1007, lr = 0.003931
I1018 23:28:11.699578  3328 solver.cpp:242] Iteration 1026 (0.747848 iter/s, 25.4062s/19 iter), loss = 0.352078
I1018 23:28:11.699651  3328 solver.cpp:261]     Train net output #0: loss = 0.348933 (* 1 = 0.348933 loss)
I1018 23:28:11.699671  3328 sgd_solver.cpp:106] Iteration 1026, lr = 0.00391083
I1018 23:28:36.794666  3328 solver.cpp:242] Iteration 1045 (0.757135 iter/s, 25.0946s/19 iter), loss = 0.336828
I1018 23:28:36.794870  3328 solver.cpp:261]     Train net output #0: loss = 0.335908 (* 1 = 0.335908 loss)
I1018 23:28:36.794917  3328 sgd_solver.cpp:106] Iteration 1045, lr = 0.00389066
I1018 23:29:01.592635  3328 solver.cpp:242] Iteration 1064 (0.76621 iter/s, 24.7974s/19 iter), loss = 0.38238
I1018 23:29:01.592696  3328 solver.cpp:261]     Train net output #0: loss = 0.336965 (* 1 = 0.336965 loss)
I1018 23:29:01.592715  3328 sgd_solver.cpp:106] Iteration 1064, lr = 0.00387049
I1018 23:29:27.036917  3328 solver.cpp:242] Iteration 1083 (0.746743 iter/s, 25.4438s/19 iter), loss = 0.333295
I1018 23:29:27.037485  3328 solver.cpp:261]     Train net output #0: loss = 0.299484 (* 1 = 0.299484 loss)
I1018 23:29:27.037503  3328 sgd_solver.cpp:106] Iteration 1083, lr = 0.00385032
I1018 23:29:46.684584  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_1099.caffemodel
I1018 23:29:46.896770  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1099.solverstate
I1018 23:29:47.014845  3328 solver.cpp:362] Iteration 1099, Testing net (#0)
I1018 23:29:47.014888  3328 net.cpp:723] Ignoring source layer train-data
I1018 23:29:57.879441  3328 solver.cpp:429]     Test net output #0: accuracy = 0.856445
I1018 23:29:57.879541  3328 solver.cpp:429]     Test net output #1: loss = 0.338296 (* 1 = 0.338296 loss)
I1018 23:30:03.091562  3328 solver.cpp:242] Iteration 1102 (0.526994 iter/s, 36.0535s/19 iter), loss = 0.317557
I1018 23:30:03.091629  3328 solver.cpp:261]     Train net output #0: loss = 0.352438 (* 1 = 0.352438 loss)
I1018 23:30:03.091646  3328 sgd_solver.cpp:106] Iteration 1102, lr = 0.00383015
I1018 23:30:28.234099  3328 solver.cpp:242] Iteration 1121 (0.755706 iter/s, 25.1421s/19 iter), loss = 0.324808
I1018 23:30:28.234203  3328 solver.cpp:261]     Train net output #0: loss = 0.35903 (* 1 = 0.35903 loss)
I1018 23:30:28.234222  3328 sgd_solver.cpp:106] Iteration 1121, lr = 0.00380998
I1018 23:30:53.324936  3328 solver.cpp:242] Iteration 1140 (0.757264 iter/s, 25.0903s/19 iter), loss = 0.330135
I1018 23:30:53.325000  3328 solver.cpp:261]     Train net output #0: loss = 0.341907 (* 1 = 0.341907 loss)
I1018 23:30:53.325017  3328 sgd_solver.cpp:106] Iteration 1140, lr = 0.00378981
I1018 23:31:18.215684  3328 solver.cpp:242] Iteration 1159 (0.76335 iter/s, 24.8903s/19 iter), loss = 0.315557
I1018 23:31:18.217742  3328 solver.cpp:261]     Train net output #0: loss = 0.333303 (* 1 = 0.333303 loss)
I1018 23:31:18.217780  3328 sgd_solver.cpp:106] Iteration 1159, lr = 0.00376964
I1018 23:31:43.806517  3328 solver.cpp:242] Iteration 1178 (0.742526 iter/s, 25.5883s/19 iter), loss = 0.335921
I1018 23:31:43.806581  3328 solver.cpp:261]     Train net output #0: loss = 0.321933 (* 1 = 0.321933 loss)
I1018 23:31:43.806601  3328 sgd_solver.cpp:106] Iteration 1178, lr = 0.00374947
I1018 23:31:51.295534  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1018 23:32:08.862198  3328 solver.cpp:242] Iteration 1197 (0.758325 iter/s, 25.0552s/19 iter), loss = 0.313699
I1018 23:32:08.862262  3328 solver.cpp:261]     Train net output #0: loss = 0.286661 (* 1 = 0.286661 loss)
I1018 23:32:08.862278  3328 sgd_solver.cpp:106] Iteration 1197, lr = 0.0037293
I1018 23:32:33.967217  3328 solver.cpp:242] Iteration 1216 (0.756834 iter/s, 25.1046s/19 iter), loss = 0.360207
I1018 23:32:33.967332  3328 solver.cpp:261]     Train net output #0: loss = 0.377148 (* 1 = 0.377148 loss)
I1018 23:32:33.967350  3328 sgd_solver.cpp:106] Iteration 1216, lr = 0.00370913
I1018 23:32:59.457130  3328 solver.cpp:242] Iteration 1235 (0.745408 iter/s, 25.4894s/19 iter), loss = 0.286686
I1018 23:32:59.457200  3328 solver.cpp:261]     Train net output #0: loss = 0.274925 (* 1 = 0.274925 loss)
I1018 23:32:59.457218  3328 sgd_solver.cpp:106] Iteration 1235, lr = 0.00368896
I1018 23:33:24.463562  3328 solver.cpp:242] Iteration 1254 (0.759818 iter/s, 25.006s/19 iter), loss = 0.278883
I1018 23:33:24.463665  3328 solver.cpp:261]     Train net output #0: loss = 0.247496 (* 1 = 0.247496 loss)
I1018 23:33:24.463683  3328 sgd_solver.cpp:106] Iteration 1254, lr = 0.00366879
I1018 23:33:26.001211  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_1256.caffemodel
I1018 23:33:26.162969  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1256.solverstate
I1018 23:33:26.223065  3328 solver.cpp:362] Iteration 1256, Testing net (#0)
I1018 23:33:26.223101  3328 net.cpp:723] Ignoring source layer train-data
I1018 23:33:37.201617  3328 solver.cpp:429]     Test net output #0: accuracy = 0.86875
I1018 23:33:37.201665  3328 solver.cpp:429]     Test net output #1: loss = 0.309421 (* 1 = 0.309421 loss)
I1018 23:34:01.287591  3328 solver.cpp:242] Iteration 1273 (0.515977 iter/s, 36.8234s/19 iter), loss = 0.276466
I1018 23:34:01.287776  3328 solver.cpp:261]     Train net output #0: loss = 0.28421 (* 1 = 0.28421 loss)
I1018 23:34:01.287796  3328 sgd_solver.cpp:106] Iteration 1273, lr = 0.00364862
I1018 23:34:26.273917  3328 solver.cpp:242] Iteration 1292 (0.760433 iter/s, 24.9858s/19 iter), loss = 0.28408
I1018 23:34:26.273978  3328 solver.cpp:261]     Train net output #0: loss = 0.326577 (* 1 = 0.326577 loss)
I1018 23:34:26.273995  3328 sgd_solver.cpp:106] Iteration 1292, lr = 0.00362845
I1018 23:34:51.048468  3328 solver.cpp:242] Iteration 1311 (0.76693 iter/s, 24.7741s/19 iter), loss = 0.272475
I1018 23:34:51.048581  3328 solver.cpp:261]     Train net output #0: loss = 0.240688 (* 1 = 0.240688 loss)
I1018 23:34:51.048599  3328 sgd_solver.cpp:106] Iteration 1311, lr = 0.00360828
I1018 23:35:16.332819  3328 solver.cpp:242] Iteration 1330 (0.751468 iter/s, 25.2838s/19 iter), loss = 0.274769
I1018 23:35:16.332880  3328 solver.cpp:261]     Train net output #0: loss = 0.257179 (* 1 = 0.257179 loss)
I1018 23:35:16.332896  3328 sgd_solver.cpp:106] Iteration 1330, lr = 0.00358811
I1018 23:35:41.083647  3328 solver.cpp:242] Iteration 1349 (0.767665 iter/s, 24.7504s/19 iter), loss = 0.549517
I1018 23:35:41.086105  3328 solver.cpp:261]     Train net output #0: loss = 0.520687 (* 1 = 0.520687 loss)
I1018 23:35:41.086128  3328 sgd_solver.cpp:106] Iteration 1349, lr = 0.00356794
I1018 23:36:06.339560  3328 solver.cpp:242] Iteration 1368 (0.752384 iter/s, 25.2531s/19 iter), loss = 0.364651
I1018 23:36:06.339624  3328 solver.cpp:261]     Train net output #0: loss = 0.452031 (* 1 = 0.452031 loss)
I1018 23:36:06.339643  3328 sgd_solver.cpp:106] Iteration 1368, lr = 0.00354777
I1018 23:36:31.322335  3328 solver.cpp:242] Iteration 1387 (0.760538 iter/s, 24.9823s/19 iter), loss = 0.270294
I1018 23:36:31.323384  3328 solver.cpp:261]     Train net output #0: loss = 0.284878 (* 1 = 0.284878 loss)
I1018 23:36:31.323406  3328 sgd_solver.cpp:106] Iteration 1387, lr = 0.0035276
I1018 23:36:56.274951  3328 solver.cpp:242] Iteration 1406 (0.761487 iter/s, 24.9512s/19 iter), loss = 0.309416
I1018 23:36:56.275024  3328 solver.cpp:261]     Train net output #0: loss = 0.354204 (* 1 = 0.354204 loss)
I1018 23:36:56.275043  3328 sgd_solver.cpp:106] Iteration 1406, lr = 0.00350743
I1018 23:37:04.288310  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_1413.caffemodel
I1018 23:37:04.505712  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1413.solverstate
I1018 23:37:04.580427  3328 solver.cpp:362] Iteration 1413, Testing net (#0)
I1018 23:37:04.580457  3328 net.cpp:723] Ignoring source layer train-data
I1018 23:37:15.839480  3328 solver.cpp:429]     Test net output #0: accuracy = 0.882422
I1018 23:37:15.840900  3328 solver.cpp:429]     Test net output #1: loss = 0.279488 (* 1 = 0.279488 loss)
I1018 23:37:22.275264  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1018 23:37:32.931727  3328 solver.cpp:242] Iteration 1425 (0.51833 iter/s, 36.6562s/19 iter), loss = 0.292674
I1018 23:37:32.931800  3328 solver.cpp:261]     Train net output #0: loss = 0.233993 (* 1 = 0.233993 loss)
I1018 23:37:32.931821  3328 sgd_solver.cpp:106] Iteration 1425, lr = 0.00348726
I1018 23:37:58.081259  3328 solver.cpp:242] Iteration 1444 (0.755495 iter/s, 25.1491s/19 iter), loss = 0.304413
I1018 23:37:58.081442  3328 solver.cpp:261]     Train net output #0: loss = 0.286952 (* 1 = 0.286952 loss)
I1018 23:37:58.081461  3328 sgd_solver.cpp:106] Iteration 1444, lr = 0.00346709
I1018 23:38:23.268962  3328 solver.cpp:242] Iteration 1463 (0.754353 iter/s, 25.1871s/19 iter), loss = 0.296831
I1018 23:38:23.269022  3328 solver.cpp:261]     Train net output #0: loss = 0.301041 (* 1 = 0.301041 loss)
I1018 23:38:23.269039  3328 sgd_solver.cpp:106] Iteration 1463, lr = 0.00344692
I1018 23:38:48.320838  3328 solver.cpp:242] Iteration 1482 (0.75844 iter/s, 25.0514s/19 iter), loss = 0.243841
I1018 23:38:48.324952  3328 solver.cpp:261]     Train net output #0: loss = 0.203485 (* 1 = 0.203485 loss)
I1018 23:38:48.324983  3328 sgd_solver.cpp:106] Iteration 1482, lr = 0.00342675
I1018 23:39:14.153414  3328 solver.cpp:242] Iteration 1501 (0.735633 iter/s, 25.8281s/19 iter), loss = 0.256571
I1018 23:39:14.153468  3328 solver.cpp:261]     Train net output #0: loss = 0.236518 (* 1 = 0.236518 loss)
I1018 23:39:14.153486  3328 sgd_solver.cpp:106] Iteration 1501, lr = 0.00340658
I1018 23:39:39.771580  3328 solver.cpp:242] Iteration 1520 (0.741674 iter/s, 25.6177s/19 iter), loss = 0.263906
I1018 23:39:39.771893  3328 solver.cpp:261]     Train net output #0: loss = 0.245632 (* 1 = 0.245632 loss)
I1018 23:39:39.771914  3328 sgd_solver.cpp:106] Iteration 1520, lr = 0.00338641
I1018 23:40:04.634856  3328 solver.cpp:242] Iteration 1539 (0.7642 iter/s, 24.8626s/19 iter), loss = 0.26202
I1018 23:40:04.634919  3328 solver.cpp:261]     Train net output #0: loss = 0.288493 (* 1 = 0.288493 loss)
I1018 23:40:04.634938  3328 sgd_solver.cpp:106] Iteration 1539, lr = 0.00336624
I1018 23:40:29.687947  3328 solver.cpp:242] Iteration 1558 (0.758403 iter/s, 25.0526s/19 iter), loss = 0.217122
I1018 23:40:29.688060  3328 solver.cpp:261]     Train net output #0: loss = 0.184491 (* 1 = 0.184491 loss)
I1018 23:40:29.688078  3328 sgd_solver.cpp:106] Iteration 1558, lr = 0.00334607
I1018 23:40:44.632048  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_1570.caffemodel
I1018 23:40:44.866008  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1570.solverstate
I1018 23:40:44.973062  3328 solver.cpp:362] Iteration 1570, Testing net (#0)
I1018 23:40:44.973099  3328 net.cpp:723] Ignoring source layer train-data
I1018 23:40:55.923832  3328 solver.cpp:429]     Test net output #0: accuracy = 0.87832
I1018 23:40:55.923883  3328 solver.cpp:429]     Test net output #1: loss = 0.284829 (* 1 = 0.284829 loss)
I1018 23:41:06.363561  3328 solver.cpp:242] Iteration 1577 (0.518066 iter/s, 36.6749s/19 iter), loss = 0.291126
I1018 23:41:06.364704  3328 solver.cpp:261]     Train net output #0: loss = 0.298448 (* 1 = 0.298448 loss)
I1018 23:41:06.364733  3328 sgd_solver.cpp:106] Iteration 1577, lr = 0.0033259
I1018 23:41:31.197892  3328 solver.cpp:242] Iteration 1596 (0.765119 iter/s, 24.8328s/19 iter), loss = 0.21897
I1018 23:41:31.197952  3328 solver.cpp:261]     Train net output #0: loss = 0.212333 (* 1 = 0.212333 loss)
I1018 23:41:31.197969  3328 sgd_solver.cpp:106] Iteration 1596, lr = 0.00330573
I1018 23:41:56.699439  3328 solver.cpp:242] Iteration 1615 (0.745068 iter/s, 25.501s/19 iter), loss = 0.23525
I1018 23:41:56.700852  3328 solver.cpp:261]     Train net output #0: loss = 0.277067 (* 1 = 0.277067 loss)
I1018 23:41:56.700881  3328 sgd_solver.cpp:106] Iteration 1615, lr = 0.00328556
I1018 23:42:21.614819  3328 solver.cpp:242] Iteration 1634 (0.762638 iter/s, 24.9135s/19 iter), loss = 0.232843
I1018 23:42:21.614899  3328 solver.cpp:261]     Train net output #0: loss = 0.157023 (* 1 = 0.157023 loss)
I1018 23:42:21.614920  3328 sgd_solver.cpp:106] Iteration 1634, lr = 0.00326539
I1018 23:42:46.539571  3328 solver.cpp:242] Iteration 1653 (0.76231 iter/s, 24.9242s/19 iter), loss = 0.21935
I1018 23:42:46.542183  3328 solver.cpp:261]     Train net output #0: loss = 0.198629 (* 1 = 0.198629 loss)
I1018 23:42:46.542215  3328 sgd_solver.cpp:106] Iteration 1653, lr = 0.00324522
I1018 23:42:53.824987  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1018 23:43:12.359566  3328 solver.cpp:242] Iteration 1672 (0.735951 iter/s, 25.8169s/19 iter), loss = 0.298493
I1018 23:43:12.359629  3328 solver.cpp:261]     Train net output #0: loss = 0.301062 (* 1 = 0.301062 loss)
I1018 23:43:12.359647  3328 sgd_solver.cpp:106] Iteration 1672, lr = 0.00322505
I1018 23:43:42.115550  3328 solver.cpp:242] Iteration 1691 (0.638539 iter/s, 29.7554s/19 iter), loss = 0.245058
I1018 23:43:42.115690  3328 solver.cpp:261]     Train net output #0: loss = 0.246305 (* 1 = 0.246305 loss)
I1018 23:43:42.115710  3328 sgd_solver.cpp:106] Iteration 1691, lr = 0.00320488
I1018 23:44:15.141626  3328 solver.cpp:242] Iteration 1710 (0.575315 iter/s, 33.0254s/19 iter), loss = 0.230824
I1018 23:44:15.147552  3328 solver.cpp:261]     Train net output #0: loss = 0.292491 (* 1 = 0.292491 loss)
I1018 23:44:15.147581  3328 sgd_solver.cpp:106] Iteration 1710, lr = 0.00318471
I1018 23:44:39.669854  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_1727.caffemodel
I1018 23:44:39.877050  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1727.solverstate
I1018 23:44:39.994421  3328 solver.cpp:362] Iteration 1727, Testing net (#0)
I1018 23:44:39.994457  3328 net.cpp:723] Ignoring source layer train-data
I1018 23:44:52.667392  3328 solver.cpp:429]     Test net output #0: accuracy = 0.900781
I1018 23:44:52.675535  3328 solver.cpp:429]     Test net output #1: loss = 0.237258 (* 1 = 0.237258 loss)
I1018 23:44:56.867561  3328 solver.cpp:242] Iteration 1729 (0.455425 iter/s, 41.7193s/19 iter), loss = 0.232722
I1018 23:44:56.867627  3328 solver.cpp:261]     Train net output #0: loss = 0.242668 (* 1 = 0.242668 loss)
I1018 23:44:56.867645  3328 sgd_solver.cpp:106] Iteration 1729, lr = 0.00316454
I1018 23:45:22.538270  3328 solver.cpp:242] Iteration 1748 (0.74016 iter/s, 25.6701s/19 iter), loss = 0.213193
I1018 23:45:22.538329  3328 solver.cpp:261]     Train net output #0: loss = 0.245995 (* 1 = 0.245995 loss)
I1018 23:45:22.538347  3328 sgd_solver.cpp:106] Iteration 1748, lr = 0.00314437
I1018 23:45:47.679564  3328 solver.cpp:242] Iteration 1767 (0.755745 iter/s, 25.1407s/19 iter), loss = 0.223381
I1018 23:45:47.681747  3328 solver.cpp:261]     Train net output #0: loss = 0.22278 (* 1 = 0.22278 loss)
I1018 23:45:47.681769  3328 sgd_solver.cpp:106] Iteration 1767, lr = 0.0031242
I1018 23:46:12.783583  3328 solver.cpp:242] Iteration 1786 (0.756931 iter/s, 25.1014s/19 iter), loss = 0.228683
I1018 23:46:12.783658  3328 solver.cpp:261]     Train net output #0: loss = 0.265121 (* 1 = 0.265121 loss)
I1018 23:46:12.783677  3328 sgd_solver.cpp:106] Iteration 1786, lr = 0.00310403
I1018 23:46:38.111563  3328 solver.cpp:242] Iteration 1805 (0.750175 iter/s, 25.3274s/19 iter), loss = 0.20082
I1018 23:46:38.111675  3328 solver.cpp:261]     Train net output #0: loss = 0.263033 (* 1 = 0.263033 loss)
I1018 23:46:38.111693  3328 sgd_solver.cpp:106] Iteration 1805, lr = 0.00308386
I1018 23:47:02.877908  3328 solver.cpp:242] Iteration 1824 (0.767188 iter/s, 24.7658s/19 iter), loss = 0.186647
I1018 23:47:02.877966  3328 solver.cpp:261]     Train net output #0: loss = 0.211436 (* 1 = 0.211436 loss)
I1018 23:47:02.877985  3328 sgd_solver.cpp:106] Iteration 1824, lr = 0.00306369
I1018 23:47:28.253675  3328 solver.cpp:242] Iteration 1843 (0.748762 iter/s, 25.3752s/19 iter), loss = 0.201868
I1018 23:47:28.254070  3328 solver.cpp:261]     Train net output #0: loss = 0.223774 (* 1 = 0.223774 loss)
I1018 23:47:28.254087  3328 sgd_solver.cpp:106] Iteration 1843, lr = 0.00304352
I1018 23:47:53.208612  3328 solver.cpp:242] Iteration 1862 (0.761398 iter/s, 24.9541s/19 iter), loss = 0.190811
I1018 23:47:53.208676  3328 solver.cpp:261]     Train net output #0: loss = 0.255658 (* 1 = 0.255658 loss)
I1018 23:47:53.208694  3328 sgd_solver.cpp:106] Iteration 1862, lr = 0.00302335
I1018 23:48:18.235551  3328 solver.cpp:242] Iteration 1881 (0.759198 iter/s, 25.0264s/19 iter), loss = 0.207492
I1018 23:48:18.235939  3328 solver.cpp:261]     Train net output #0: loss = 0.206395 (* 1 = 0.206395 loss)
I1018 23:48:18.235960  3328 sgd_solver.cpp:106] Iteration 1881, lr = 0.00300318
I1018 23:48:20.966714  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_1884.caffemodel
I1018 23:48:21.173660  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1884.solverstate
I1018 23:48:21.268528  3328 solver.cpp:362] Iteration 1884, Testing net (#0)
I1018 23:48:21.268558  3328 net.cpp:723] Ignoring source layer train-data
I1018 23:48:32.382519  3328 solver.cpp:429]     Test net output #0: accuracy = 0.908008
I1018 23:48:32.382575  3328 solver.cpp:429]     Test net output #1: loss = 0.218292 (* 1 = 0.218292 loss)
I1018 23:48:43.922125  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1018 23:48:54.613615  3328 solver.cpp:242] Iteration 1900 (0.522308 iter/s, 36.377s/19 iter), loss = 0.166028
I1018 23:48:54.614307  3328 solver.cpp:261]     Train net output #0: loss = 0.177047 (* 1 = 0.177047 loss)
I1018 23:48:54.614327  3328 sgd_solver.cpp:106] Iteration 1900, lr = 0.00298301
I1018 23:49:19.587564  3328 solver.cpp:242] Iteration 1919 (0.760828 iter/s, 24.9728s/19 iter), loss = 0.218889
I1018 23:49:19.587623  3328 solver.cpp:261]     Train net output #0: loss = 0.3109 (* 1 = 0.3109 loss)
I1018 23:49:19.587641  3328 sgd_solver.cpp:106] Iteration 1919, lr = 0.00296284
I1018 23:49:44.794277  3328 solver.cpp:242] Iteration 1938 (0.753783 iter/s, 25.2062s/19 iter), loss = 0.201966
I1018 23:49:44.795253  3328 solver.cpp:261]     Train net output #0: loss = 0.188083 (* 1 = 0.188083 loss)
I1018 23:49:44.795274  3328 sgd_solver.cpp:106] Iteration 1938, lr = 0.00294268
I1018 23:50:10.350489  3328 solver.cpp:242] Iteration 1957 (0.743501 iter/s, 25.5548s/19 iter), loss = 0.189495
I1018 23:50:10.350555  3328 solver.cpp:261]     Train net output #0: loss = 0.250312 (* 1 = 0.250312 loss)
I1018 23:50:10.350574  3328 sgd_solver.cpp:106] Iteration 1957, lr = 0.00292251
I1018 23:50:35.035192  3328 solver.cpp:242] Iteration 1976 (0.769723 iter/s, 24.6842s/19 iter), loss = 0.172364
I1018 23:50:35.035660  3328 solver.cpp:261]     Train net output #0: loss = 0.19728 (* 1 = 0.19728 loss)
I1018 23:50:35.035886  3328 sgd_solver.cpp:106] Iteration 1976, lr = 0.00290234
I1018 23:50:59.991566  3328 solver.cpp:242] Iteration 1995 (0.761356 iter/s, 24.9555s/19 iter), loss = 0.157493
I1018 23:50:59.991631  3328 solver.cpp:261]     Train net output #0: loss = 0.0852157 (* 1 = 0.0852157 loss)
I1018 23:50:59.991649  3328 sgd_solver.cpp:106] Iteration 1995, lr = 0.00288217
I1018 23:51:24.978998  3328 solver.cpp:242] Iteration 2014 (0.760398 iter/s, 24.9869s/19 iter), loss = 0.215826
I1018 23:51:24.988142  3328 solver.cpp:261]     Train net output #0: loss = 0.236845 (* 1 = 0.236845 loss)
I1018 23:51:24.988183  3328 sgd_solver.cpp:106] Iteration 2014, lr = 0.002862
I1018 23:51:50.135558  3328 solver.cpp:242] Iteration 2033 (0.755557 iter/s, 25.147s/19 iter), loss = 0.173196
I1018 23:51:50.135627  3328 solver.cpp:261]     Train net output #0: loss = 0.195384 (* 1 = 0.195384 loss)
I1018 23:51:50.135648  3328 sgd_solver.cpp:106] Iteration 2033, lr = 0.00284183
I1018 23:51:59.348160  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_2041.caffemodel
I1018 23:51:59.590107  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2041.solverstate
I1018 23:51:59.671998  3328 solver.cpp:362] Iteration 2041, Testing net (#0)
I1018 23:51:59.672030  3328 net.cpp:723] Ignoring source layer train-data
I1018 23:52:10.542939  3328 solver.cpp:429]     Test net output #0: accuracy = 0.911133
I1018 23:52:10.542990  3328 solver.cpp:429]     Test net output #1: loss = 0.213004 (* 1 = 0.213004 loss)
I1018 23:52:26.221563  3328 solver.cpp:242] Iteration 2052 (0.52653 iter/s, 36.0853s/19 iter), loss = 0.170075
I1018 23:52:26.221623  3328 solver.cpp:261]     Train net output #0: loss = 0.200259 (* 1 = 0.200259 loss)
I1018 23:52:26.221642  3328 sgd_solver.cpp:106] Iteration 2052, lr = 0.00282166
I1018 23:52:51.396911  3328 solver.cpp:242] Iteration 2071 (0.754721 iter/s, 25.1749s/19 iter), loss = 0.211735
I1018 23:52:51.403575  3328 solver.cpp:261]     Train net output #0: loss = 0.232698 (* 1 = 0.232698 loss)
I1018 23:52:51.403617  3328 sgd_solver.cpp:106] Iteration 2071, lr = 0.00280149
I1018 23:53:16.371103  3328 solver.cpp:242] Iteration 2090 (0.761001 iter/s, 24.9671s/19 iter), loss = 0.19254
I1018 23:53:16.371162  3328 solver.cpp:261]     Train net output #0: loss = 0.163416 (* 1 = 0.163416 loss)
I1018 23:53:16.371179  3328 sgd_solver.cpp:106] Iteration 2090, lr = 0.00278132
I1018 23:53:41.719754  3328 solver.cpp:242] Iteration 2109 (0.749561 iter/s, 25.3482s/19 iter), loss = 0.16318
I1018 23:53:41.719871  3328 solver.cpp:261]     Train net output #0: loss = 0.209915 (* 1 = 0.209915 loss)
I1018 23:53:41.719889  3328 sgd_solver.cpp:106] Iteration 2109, lr = 0.00276115
I1018 23:54:06.815260  3328 solver.cpp:242] Iteration 2128 (0.757124 iter/s, 25.095s/19 iter), loss = 0.206306
I1018 23:54:06.815318  3328 solver.cpp:261]     Train net output #0: loss = 0.136319 (* 1 = 0.136319 loss)
I1018 23:54:06.815337  3328 sgd_solver.cpp:106] Iteration 2128, lr = 0.00274098
I1018 23:54:14.122828  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1018 23:54:32.292593  3328 solver.cpp:242] Iteration 2147 (0.745775 iter/s, 25.4768s/19 iter), loss = 0.176819
I1018 23:54:32.292677  3328 solver.cpp:261]     Train net output #0: loss = 0.206721 (* 1 = 0.206721 loss)
I1018 23:54:32.292698  3328 sgd_solver.cpp:106] Iteration 2147, lr = 0.00272081
I1018 23:54:57.199174  3328 solver.cpp:242] Iteration 2166 (0.762866 iter/s, 24.9061s/19 iter), loss = 0.19046
I1018 23:54:57.199306  3328 solver.cpp:261]     Train net output #0: loss = 0.138725 (* 1 = 0.138725 loss)
I1018 23:54:57.199326  3328 sgd_solver.cpp:106] Iteration 2166, lr = 0.00270064
I1018 23:55:22.136176  3328 solver.cpp:242] Iteration 2185 (0.761937 iter/s, 24.9364s/19 iter), loss = 0.164833
I1018 23:55:22.136260  3328 solver.cpp:261]     Train net output #0: loss = 0.173738 (* 1 = 0.173738 loss)
I1018 23:55:22.136281  3328 sgd_solver.cpp:106] Iteration 2185, lr = 0.00268047
I1018 23:55:38.326011  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_2198.caffemodel
I1018 23:55:38.546177  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2198.solverstate
I1018 23:55:38.598781  3328 solver.cpp:362] Iteration 2198, Testing net (#0)
I1018 23:55:38.598812  3328 net.cpp:723] Ignoring source layer train-data
I1018 23:55:49.571710  3328 solver.cpp:429]     Test net output #0: accuracy = 0.91875
I1018 23:55:49.571758  3328 solver.cpp:429]     Test net output #1: loss = 0.196497 (* 1 = 0.196497 loss)
I1018 23:55:58.726891  3328 solver.cpp:242] Iteration 2204 (0.519267 iter/s, 36.59s/19 iter), loss = 0.192924
I1018 23:55:58.726949  3328 solver.cpp:261]     Train net output #0: loss = 0.207368 (* 1 = 0.207368 loss)
I1018 23:55:58.726968  3328 sgd_solver.cpp:106] Iteration 2204, lr = 0.0026603
I1018 23:56:23.831558  3328 solver.cpp:242] Iteration 2223 (0.756846 iter/s, 25.1042s/19 iter), loss = 0.194308
I1018 23:56:23.832660  3328 solver.cpp:261]     Train net output #0: loss = 0.230564 (* 1 = 0.230564 loss)
I1018 23:56:23.832681  3328 sgd_solver.cpp:106] Iteration 2223, lr = 0.00264013
I1018 23:56:49.169575  3328 solver.cpp:242] Iteration 2242 (0.749906 iter/s, 25.3365s/19 iter), loss = 0.190245
I1018 23:56:49.169631  3328 solver.cpp:261]     Train net output #0: loss = 0.164378 (* 1 = 0.164378 loss)
I1018 23:56:49.169649  3328 sgd_solver.cpp:106] Iteration 2242, lr = 0.00261996
I1018 23:57:14.420224  3328 solver.cpp:242] Iteration 2261 (0.75247 iter/s, 25.2502s/19 iter), loss = 0.158416
I1018 23:57:14.427573  3328 solver.cpp:261]     Train net output #0: loss = 0.117127 (* 1 = 0.117127 loss)
I1018 23:57:14.427616  3328 sgd_solver.cpp:106] Iteration 2261, lr = 0.00259979
I1018 23:57:39.467581  3328 solver.cpp:242] Iteration 2280 (0.758798 iter/s, 25.0396s/19 iter), loss = 0.171593
I1018 23:57:39.467648  3328 solver.cpp:261]     Train net output #0: loss = 0.152908 (* 1 = 0.152908 loss)
I1018 23:57:39.467665  3328 sgd_solver.cpp:106] Iteration 2280, lr = 0.00257962
I1018 23:58:04.823590  3328 solver.cpp:242] Iteration 2299 (0.749343 iter/s, 25.3555s/19 iter), loss = 0.139527
I1018 23:58:04.825942  3328 solver.cpp:261]     Train net output #0: loss = 0.162355 (* 1 = 0.162355 loss)
I1018 23:58:04.825964  3328 sgd_solver.cpp:106] Iteration 2299, lr = 0.00255945
I1018 23:58:29.739558  3328 solver.cpp:242] Iteration 2318 (0.762648 iter/s, 24.9132s/19 iter), loss = 0.150268
I1018 23:58:29.739619  3328 solver.cpp:261]     Train net output #0: loss = 0.100997 (* 1 = 0.100997 loss)
I1018 23:58:29.739639  3328 sgd_solver.cpp:106] Iteration 2318, lr = 0.00253928
I1018 23:58:55.002310  3328 solver.cpp:242] Iteration 2337 (0.752109 iter/s, 25.2623s/19 iter), loss = 0.193274
I1018 23:58:55.002413  3328 solver.cpp:261]     Train net output #0: loss = 0.207792 (* 1 = 0.207792 loss)
I1018 23:58:55.002431  3328 sgd_solver.cpp:106] Iteration 2337, lr = 0.00251911
I1018 23:59:17.814249  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_2355.caffemodel
I1018 23:59:17.982561  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2355.solverstate
I1018 23:59:18.077083  3328 solver.cpp:362] Iteration 2355, Testing net (#0)
I1018 23:59:18.077119  3328 net.cpp:723] Ignoring source layer train-data
I1018 23:59:29.096902  3328 solver.cpp:429]     Test net output #0: accuracy = 0.913672
I1018 23:59:29.097002  3328 solver.cpp:429]     Test net output #1: loss = 0.214309 (* 1 = 0.214309 loss)
I1018 23:59:31.778514  3328 solver.cpp:242] Iteration 2356 (0.516648 iter/s, 36.7755s/19 iter), loss = 0.251532
I1018 23:59:31.778575  3328 solver.cpp:261]     Train net output #0: loss = 0.30925 (* 1 = 0.30925 loss)
I1018 23:59:31.778592  3328 sgd_solver.cpp:106] Iteration 2356, lr = 0.00249894
I1018 23:59:45.965924  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1018 23:59:56.614959  3328 solver.cpp:242] Iteration 2375 (0.765019 iter/s, 24.836s/19 iter), loss = 0.157808
I1018 23:59:56.615022  3328 solver.cpp:261]     Train net output #0: loss = 0.0963089 (* 1 = 0.0963089 loss)
I1018 23:59:56.615041  3328 sgd_solver.cpp:106] Iteration 2375, lr = 0.00247877
I1019 00:00:21.969323  3328 solver.cpp:242] Iteration 2394 (0.749392 iter/s, 25.3539s/19 iter), loss = 0.171481
I1019 00:00:21.969477  3328 solver.cpp:261]     Train net output #0: loss = 0.167191 (* 1 = 0.167191 loss)
I1019 00:00:21.969496  3328 sgd_solver.cpp:106] Iteration 2394, lr = 0.0024586
I1019 00:00:46.970654  3328 solver.cpp:242] Iteration 2413 (0.759976 iter/s, 25.0008s/19 iter), loss = 0.154616
I1019 00:00:46.970712  3328 solver.cpp:261]     Train net output #0: loss = 0.138881 (* 1 = 0.138881 loss)
I1019 00:00:46.970731  3328 sgd_solver.cpp:106] Iteration 2413, lr = 0.00243843
I1019 00:01:12.297441  3328 solver.cpp:242] Iteration 2432 (0.750208 iter/s, 25.3263s/19 iter), loss = 0.196804
I1019 00:01:12.303561  3328 solver.cpp:261]     Train net output #0: loss = 0.256925 (* 1 = 0.256925 loss)
I1019 00:01:12.303598  3328 sgd_solver.cpp:106] Iteration 2432, lr = 0.00241826
I1019 00:01:37.479567  3328 solver.cpp:242] Iteration 2451 (0.754699 iter/s, 25.1756s/19 iter), loss = 0.18796
I1019 00:01:37.479632  3328 solver.cpp:261]     Train net output #0: loss = 0.21187 (* 1 = 0.21187 loss)
I1019 00:01:37.479650  3328 sgd_solver.cpp:106] Iteration 2451, lr = 0.00239809
I1019 00:02:02.459573  3328 solver.cpp:242] Iteration 2470 (0.760623 iter/s, 24.9795s/19 iter), loss = 0.170353
I1019 00:02:02.459707  3328 solver.cpp:261]     Train net output #0: loss = 0.160991 (* 1 = 0.160991 loss)
I1019 00:02:02.459728  3328 sgd_solver.cpp:106] Iteration 2470, lr = 0.00237792
I1019 00:02:27.749954  3328 solver.cpp:242] Iteration 2489 (0.75129 iter/s, 25.2898s/19 iter), loss = 0.144983
I1019 00:02:27.750012  3328 solver.cpp:261]     Train net output #0: loss = 0.16712 (* 1 = 0.16712 loss)
I1019 00:02:27.750030  3328 sgd_solver.cpp:106] Iteration 2489, lr = 0.00235775
I1019 00:02:52.609585  3328 solver.cpp:242] Iteration 2508 (0.764305 iter/s, 24.8592s/19 iter), loss = 0.20291
I1019 00:02:52.619421  3328 solver.cpp:261]     Train net output #0: loss = 0.212714 (* 1 = 0.212714 loss)
I1019 00:02:52.619460  3328 sgd_solver.cpp:106] Iteration 2508, lr = 0.00233758
I1019 00:02:56.718269  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_2512.caffemodel
I1019 00:02:56.906941  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2512.solverstate
I1019 00:02:57.011554  3328 solver.cpp:362] Iteration 2512, Testing net (#0)
I1019 00:02:57.011600  3328 net.cpp:723] Ignoring source layer train-data
I1019 00:03:07.852802  3328 solver.cpp:429]     Test net output #0: accuracy = 0.917773
I1019 00:03:07.852850  3328 solver.cpp:429]     Test net output #1: loss = 0.205335 (* 1 = 0.205335 loss)
I1019 00:03:28.994418  3328 solver.cpp:242] Iteration 2527 (0.522345 iter/s, 36.3744s/19 iter), loss = 0.176849
I1019 00:03:29.002586  3328 solver.cpp:261]     Train net output #0: loss = 0.150697 (* 1 = 0.150697 loss)
I1019 00:03:29.002624  3328 sgd_solver.cpp:106] Iteration 2527, lr = 0.00231741
I1019 00:03:54.317998  3328 solver.cpp:242] Iteration 2546 (0.750542 iter/s, 25.315s/19 iter), loss = 0.160898
I1019 00:03:54.318066  3328 solver.cpp:261]     Train net output #0: loss = 0.135075 (* 1 = 0.135075 loss)
I1019 00:03:54.318084  3328 sgd_solver.cpp:106] Iteration 2546, lr = 0.00229724
I1019 00:04:19.135900  3328 solver.cpp:242] Iteration 2565 (0.765591 iter/s, 24.8174s/19 iter), loss = 0.14314
I1019 00:04:19.142824  3328 solver.cpp:261]     Train net output #0: loss = 0.148631 (* 1 = 0.148631 loss)
I1019 00:04:19.142860  3328 sgd_solver.cpp:106] Iteration 2565, lr = 0.00227707
I1019 00:04:44.257388  3328 solver.cpp:242] Iteration 2584 (0.756545 iter/s, 25.1142s/19 iter), loss = 0.1847
I1019 00:04:44.257452  3328 solver.cpp:261]     Train net output #0: loss = 0.180169 (* 1 = 0.180169 loss)
I1019 00:04:44.257469  3328 sgd_solver.cpp:106] Iteration 2584, lr = 0.0022569
I1019 00:05:09.260545  3328 solver.cpp:242] Iteration 2603 (0.759918 iter/s, 25.0027s/19 iter), loss = 0.150754
I1019 00:05:09.260651  3328 solver.cpp:261]     Train net output #0: loss = 0.16101 (* 1 = 0.16101 loss)
I1019 00:05:09.260670  3328 sgd_solver.cpp:106] Iteration 2603, lr = 0.00223673
I1019 00:05:16.727551  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1019 00:05:34.243640  3328 solver.cpp:242] Iteration 2622 (0.760529 iter/s, 24.9826s/19 iter), loss = 0.145292
I1019 00:05:34.243700  3328 solver.cpp:261]     Train net output #0: loss = 0.158058 (* 1 = 0.158058 loss)
I1019 00:05:34.243718  3328 sgd_solver.cpp:106] Iteration 2622, lr = 0.00221656
I1019 00:05:59.328186  3328 solver.cpp:242] Iteration 2641 (0.757452 iter/s, 25.0841s/19 iter), loss = 0.153875
I1019 00:05:59.328999  3328 solver.cpp:261]     Train net output #0: loss = 0.176657 (* 1 = 0.176657 loss)
I1019 00:05:59.329020  3328 sgd_solver.cpp:106] Iteration 2641, lr = 0.00219639
I1019 00:06:24.476146  3328 solver.cpp:242] Iteration 2660 (0.755564 iter/s, 25.1468s/19 iter), loss = 0.177954
I1019 00:06:24.476207  3328 solver.cpp:261]     Train net output #0: loss = 0.175543 (* 1 = 0.175543 loss)
I1019 00:06:24.476224  3328 sgd_solver.cpp:106] Iteration 2660, lr = 0.00217622
I1019 00:06:35.267483  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_2669.caffemodel
I1019 00:06:35.490798  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2669.solverstate
I1019 00:06:35.555348  3328 solver.cpp:362] Iteration 2669, Testing net (#0)
I1019 00:06:35.555384  3328 net.cpp:723] Ignoring source layer train-data
I1019 00:06:46.605782  3328 solver.cpp:429]     Test net output #0: accuracy = 0.924219
I1019 00:06:46.605834  3328 solver.cpp:429]     Test net output #1: loss = 0.185583 (* 1 = 0.185583 loss)
I1019 00:07:00.954872  3328 solver.cpp:242] Iteration 2679 (0.52086 iter/s, 36.4781s/19 iter), loss = 0.105285
I1019 00:07:00.954931  3328 solver.cpp:261]     Train net output #0: loss = 0.115397 (* 1 = 0.115397 loss)
I1019 00:07:00.954948  3328 sgd_solver.cpp:106] Iteration 2679, lr = 0.00215605
I1019 00:07:26.203372  3328 solver.cpp:242] Iteration 2698 (0.752533 iter/s, 25.2481s/19 iter), loss = 0.122056
I1019 00:07:26.213801  3328 solver.cpp:261]     Train net output #0: loss = 0.0631484 (* 1 = 0.0631484 loss)
I1019 00:07:26.213843  3328 sgd_solver.cpp:106] Iteration 2698, lr = 0.00213588
I1019 00:07:51.682552  3328 solver.cpp:242] Iteration 2717 (0.746023 iter/s, 25.4684s/19 iter), loss = 0.171792
I1019 00:07:51.682615  3328 solver.cpp:261]     Train net output #0: loss = 0.169734 (* 1 = 0.169734 loss)
I1019 00:07:51.682633  3328 sgd_solver.cpp:106] Iteration 2717, lr = 0.00211571
I1019 00:08:16.975574  3328 solver.cpp:242] Iteration 2736 (0.751209 iter/s, 25.2926s/19 iter), loss = 0.166647
I1019 00:08:16.975709  3328 solver.cpp:261]     Train net output #0: loss = 0.137845 (* 1 = 0.137845 loss)
I1019 00:08:16.975731  3328 sgd_solver.cpp:106] Iteration 2736, lr = 0.00209554
I1019 00:08:42.293105  3328 solver.cpp:242] Iteration 2755 (0.750484 iter/s, 25.317s/19 iter), loss = 0.142885
I1019 00:08:42.293164  3328 solver.cpp:261]     Train net output #0: loss = 0.172575 (* 1 = 0.172575 loss)
I1019 00:08:42.293182  3328 sgd_solver.cpp:106] Iteration 2755, lr = 0.00207537
I1019 00:09:07.438205  3328 solver.cpp:242] Iteration 2774 (0.755628 iter/s, 25.1447s/19 iter), loss = 0.109617
I1019 00:09:07.438313  3328 solver.cpp:261]     Train net output #0: loss = 0.135802 (* 1 = 0.135802 loss)
I1019 00:09:07.438331  3328 sgd_solver.cpp:106] Iteration 2774, lr = 0.0020552
I1019 00:09:32.475136  3328 solver.cpp:242] Iteration 2793 (0.758894 iter/s, 25.0364s/19 iter), loss = 0.165519
I1019 00:09:32.475198  3328 solver.cpp:261]     Train net output #0: loss = 0.115468 (* 1 = 0.115468 loss)
I1019 00:09:32.475217  3328 sgd_solver.cpp:106] Iteration 2793, lr = 0.00203503
I1019 00:09:57.759125  3328 solver.cpp:242] Iteration 2812 (0.751477 iter/s, 25.2835s/19 iter), loss = 0.145973
I1019 00:09:57.763314  3328 solver.cpp:261]     Train net output #0: loss = 0.254151 (* 1 = 0.254151 loss)
I1019 00:09:57.763344  3328 sgd_solver.cpp:106] Iteration 2812, lr = 0.00201486
I1019 00:10:14.819959  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_2826.caffemodel
I1019 00:10:15.036865  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2826.solverstate
I1019 00:10:15.170373  3328 solver.cpp:362] Iteration 2826, Testing net (#0)
I1019 00:10:15.170405  3328 net.cpp:723] Ignoring source layer train-data
I1019 00:10:26.020278  3328 solver.cpp:429]     Test net output #0: accuracy = 0.9125
I1019 00:10:26.020346  3328 solver.cpp:429]     Test net output #1: loss = 0.214756 (* 1 = 0.214756 loss)
I1019 00:10:33.805418  3328 solver.cpp:242] Iteration 2831 (0.527169 iter/s, 36.0416s/19 iter), loss = 0.152004
I1019 00:10:33.807924  3328 solver.cpp:261]     Train net output #0: loss = 0.109004 (* 1 = 0.109004 loss)
I1019 00:10:33.807945  3328 sgd_solver.cpp:106] Iteration 2831, lr = 0.00199469
I1019 00:10:48.124733  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1019 00:10:59.199560  3328 solver.cpp:242] Iteration 2850 (0.748289 iter/s, 25.3912s/19 iter), loss = 0.113941
I1019 00:10:59.199627  3328 solver.cpp:261]     Train net output #0: loss = 0.0879763 (* 1 = 0.0879763 loss)
I1019 00:10:59.199645  3328 sgd_solver.cpp:106] Iteration 2850, lr = 0.00197452
I1019 00:11:24.226773  3328 solver.cpp:242] Iteration 2869 (0.759187 iter/s, 25.0268s/19 iter), loss = 0.124788
I1019 00:11:24.235569  3328 solver.cpp:261]     Train net output #0: loss = 0.145535 (* 1 = 0.145535 loss)
I1019 00:11:24.235608  3328 sgd_solver.cpp:106] Iteration 2869, lr = 0.00195435
I1019 00:11:49.743563  3328 solver.cpp:242] Iteration 2888 (0.744876 iter/s, 25.5076s/19 iter), loss = 0.199926
I1019 00:11:49.743628  3328 solver.cpp:261]     Train net output #0: loss = 0.133778 (* 1 = 0.133778 loss)
I1019 00:11:49.743646  3328 sgd_solver.cpp:106] Iteration 2888, lr = 0.00193418
I1019 00:12:15.127573  3328 solver.cpp:242] Iteration 2907 (0.748516 iter/s, 25.3835s/19 iter), loss = 0.103716
I1019 00:12:15.127774  3328 solver.cpp:261]     Train net output #0: loss = 0.13222 (* 1 = 0.13222 loss)
I1019 00:12:15.127795  3328 sgd_solver.cpp:106] Iteration 2907, lr = 0.00191401
I1019 00:12:40.502214  3328 solver.cpp:242] Iteration 2926 (0.748797 iter/s, 25.374s/19 iter), loss = 0.123453
I1019 00:12:40.502276  3328 solver.cpp:261]     Train net output #0: loss = 0.0968263 (* 1 = 0.0968263 loss)
I1019 00:12:40.502295  3328 sgd_solver.cpp:106] Iteration 2926, lr = 0.00189384
I1019 00:13:05.702795  3328 solver.cpp:242] Iteration 2945 (0.753965 iter/s, 25.2001s/19 iter), loss = 0.116526
I1019 00:13:05.702906  3328 solver.cpp:261]     Train net output #0: loss = 0.107466 (* 1 = 0.107466 loss)
I1019 00:13:05.702924  3328 sgd_solver.cpp:106] Iteration 2945, lr = 0.00187367
I1019 00:13:30.907131  3328 solver.cpp:242] Iteration 2964 (0.753854 iter/s, 25.2038s/19 iter), loss = 0.0953508
I1019 00:13:30.907191  3328 solver.cpp:261]     Train net output #0: loss = 0.0769791 (* 1 = 0.0769791 loss)
I1019 00:13:30.907208  3328 sgd_solver.cpp:106] Iteration 2964, lr = 0.0018535
I1019 00:13:55.036684  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_2983.caffemodel
I1019 00:13:55.471035  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2983.solverstate
I1019 00:13:55.597340  3328 solver.cpp:362] Iteration 2983, Testing net (#0)
I1019 00:13:55.597378  3328 net.cpp:723] Ignoring source layer train-data
I1019 00:14:06.443114  3328 solver.cpp:429]     Test net output #0: accuracy = 0.927344
I1019 00:14:06.443166  3328 solver.cpp:429]     Test net output #1: loss = 0.185855 (* 1 = 0.185855 loss)
I1019 00:14:07.518003  3328 solver.cpp:242] Iteration 2983 (0.51898 iter/s, 36.6102s/19 iter), loss = 0.127712
I1019 00:14:07.518069  3328 solver.cpp:261]     Train net output #0: loss = 0.12721 (* 1 = 0.12721 loss)
I1019 00:14:07.518087  3328 sgd_solver.cpp:106] Iteration 2983, lr = 0.00183333
I1019 00:14:32.864063  3328 solver.cpp:242] Iteration 3002 (0.749637 iter/s, 25.3456s/19 iter), loss = 0.121827
I1019 00:14:32.864437  3328 solver.cpp:261]     Train net output #0: loss = 0.0940313 (* 1 = 0.0940313 loss)
I1019 00:14:32.864456  3328 sgd_solver.cpp:106] Iteration 3002, lr = 0.00181316
I1019 00:14:58.300642  3328 solver.cpp:242] Iteration 3021 (0.746978 iter/s, 25.4358s/19 iter), loss = 0.130474
I1019 00:14:58.300724  3328 solver.cpp:261]     Train net output #0: loss = 0.148249 (* 1 = 0.148249 loss)
I1019 00:14:58.300743  3328 sgd_solver.cpp:106] Iteration 3021, lr = 0.00179299
I1019 00:15:23.554853  3328 solver.cpp:242] Iteration 3040 (0.752364 iter/s, 25.2537s/19 iter), loss = 0.135493
I1019 00:15:23.556535  3328 solver.cpp:261]     Train net output #0: loss = 0.118093 (* 1 = 0.118093 loss)
I1019 00:15:23.556560  3328 sgd_solver.cpp:106] Iteration 3040, lr = 0.00177282
I1019 00:15:48.735571  3328 solver.cpp:242] Iteration 3059 (0.754607 iter/s, 25.1787s/19 iter), loss = 0.113639
I1019 00:15:48.735638  3328 solver.cpp:261]     Train net output #0: loss = 0.0868433 (* 1 = 0.0868433 loss)
I1019 00:15:48.735657  3328 sgd_solver.cpp:106] Iteration 3059, lr = 0.00175265
I1019 00:16:14.034040  3328 solver.cpp:242] Iteration 3078 (0.751047 iter/s, 25.298s/19 iter), loss = 0.14551
I1019 00:16:14.034189  3328 solver.cpp:261]     Train net output #0: loss = 0.105983 (* 1 = 0.105983 loss)
I1019 00:16:14.034207  3328 sgd_solver.cpp:106] Iteration 3078, lr = 0.00173248
I1019 00:16:21.163537  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1019 00:16:39.151165  3328 solver.cpp:242] Iteration 3097 (0.756472 iter/s, 25.1166s/19 iter), loss = 0.14923
I1019 00:16:39.151226  3328 solver.cpp:261]     Train net output #0: loss = 0.176248 (* 1 = 0.176248 loss)
I1019 00:16:39.151245  3328 sgd_solver.cpp:106] Iteration 3097, lr = 0.00171231
I1019 00:17:04.152685  3328 solver.cpp:242] Iteration 3116 (0.759967 iter/s, 25.0011s/19 iter), loss = 0.11858
I1019 00:17:04.152791  3328 solver.cpp:261]     Train net output #0: loss = 0.162884 (* 1 = 0.162884 loss)
I1019 00:17:04.152811  3328 sgd_solver.cpp:106] Iteration 3116, lr = 0.00169214
I1019 00:17:29.619570  3328 solver.cpp:242] Iteration 3135 (0.746081 iter/s, 25.4664s/19 iter), loss = 0.111527
I1019 00:17:29.619637  3328 solver.cpp:261]     Train net output #0: loss = 0.169561 (* 1 = 0.169561 loss)
I1019 00:17:29.619714  3328 sgd_solver.cpp:106] Iteration 3135, lr = 0.00167197
I1019 00:17:35.162364  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_3140.caffemodel
I1019 00:17:36.406885  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3140.solverstate
I1019 00:17:36.458653  3328 solver.cpp:362] Iteration 3140, Testing net (#0)
I1019 00:17:36.458688  3328 net.cpp:723] Ignoring source layer train-data
I1019 00:17:46.840270  3328 solver.cpp:429]     Test net output #0: accuracy = 0.924609
I1019 00:17:46.840317  3328 solver.cpp:429]     Test net output #1: loss = 0.188141 (* 1 = 0.188141 loss)
I1019 00:18:06.413765  3328 solver.cpp:242] Iteration 3154 (0.516395 iter/s, 36.7936s/19 iter), loss = 0.102491
I1019 00:18:06.413880  3328 solver.cpp:261]     Train net output #0: loss = 0.110301 (* 1 = 0.110301 loss)
I1019 00:18:06.413899  3328 sgd_solver.cpp:106] Iteration 3154, lr = 0.0016518
I1019 00:18:31.879568  3328 solver.cpp:242] Iteration 3173 (0.746114 iter/s, 25.4653s/19 iter), loss = 0.120258
I1019 00:18:31.879634  3328 solver.cpp:261]     Train net output #0: loss = 0.099945 (* 1 = 0.099945 loss)
I1019 00:18:31.879652  3328 sgd_solver.cpp:106] Iteration 3173, lr = 0.00163163
I1019 00:18:56.776681  3328 solver.cpp:242] Iteration 3192 (0.763155 iter/s, 24.8967s/19 iter), loss = 0.130429
I1019 00:18:56.776787  3328 solver.cpp:261]     Train net output #0: loss = 0.112503 (* 1 = 0.112503 loss)
I1019 00:18:56.776804  3328 sgd_solver.cpp:106] Iteration 3192, lr = 0.00161146
I1019 00:19:21.921496  3328 solver.cpp:242] Iteration 3211 (0.755638 iter/s, 25.1443s/19 iter), loss = 0.101529
I1019 00:19:21.921556  3328 solver.cpp:261]     Train net output #0: loss = 0.0754539 (* 1 = 0.0754539 loss)
I1019 00:19:21.921574  3328 sgd_solver.cpp:106] Iteration 3211, lr = 0.0015913
I1019 00:19:48.877524  3328 solver.cpp:242] Iteration 3230 (0.704864 iter/s, 26.9555s/19 iter), loss = 0.162687
I1019 00:19:48.877928  3328 solver.cpp:261]     Train net output #0: loss = 0.0811609 (* 1 = 0.0811609 loss)
I1019 00:19:48.877948  3328 sgd_solver.cpp:106] Iteration 3230, lr = 0.00157113
I1019 00:20:14.087594  3328 solver.cpp:242] Iteration 3249 (0.753691 iter/s, 25.2093s/19 iter), loss = 0.141951
I1019 00:20:14.087671  3328 solver.cpp:261]     Train net output #0: loss = 0.0863542 (* 1 = 0.0863542 loss)
I1019 00:20:14.087689  3328 sgd_solver.cpp:106] Iteration 3249, lr = 0.00155096
I1019 00:20:39.310513  3328 solver.cpp:242] Iteration 3268 (0.753297 iter/s, 25.2225s/19 iter), loss = 0.0970127
I1019 00:20:39.319584  3328 solver.cpp:261]     Train net output #0: loss = 0.108262 (* 1 = 0.108262 loss)
I1019 00:20:39.319633  3328 sgd_solver.cpp:106] Iteration 3268, lr = 0.00153079
I1019 00:21:04.776412  3328 solver.cpp:242] Iteration 3287 (0.746372 iter/s, 25.4565s/19 iter), loss = 0.118752
I1019 00:21:04.776471  3328 solver.cpp:261]     Train net output #0: loss = 0.11475 (* 1 = 0.11475 loss)
I1019 00:21:04.776489  3328 sgd_solver.cpp:106] Iteration 3287, lr = 0.00151062
I1019 00:21:16.627305  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_3297.caffemodel
I1019 00:21:16.810698  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3297.solverstate
I1019 00:21:16.886678  3328 solver.cpp:362] Iteration 3297, Testing net (#0)
I1019 00:21:16.886715  3328 net.cpp:723] Ignoring source layer train-data
I1019 00:21:27.766486  3328 solver.cpp:429]     Test net output #0: accuracy = 0.909961
I1019 00:21:27.766540  3328 solver.cpp:429]     Test net output #1: loss = 0.221457 (* 1 = 0.221457 loss)
I1019 00:21:40.654233  3328 solver.cpp:242] Iteration 3306 (0.529584 iter/s, 35.8772s/19 iter), loss = 0.102912
I1019 00:21:40.654299  3328 solver.cpp:261]     Train net output #0: loss = 0.0910534 (* 1 = 0.0910534 loss)
I1019 00:21:40.654316  3328 sgd_solver.cpp:106] Iteration 3306, lr = 0.00149045
I1019 00:21:55.214246  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1019 00:22:06.099181  3328 solver.cpp:242] Iteration 3325 (0.746723 iter/s, 25.4445s/19 iter), loss = 0.123495
I1019 00:22:06.099243  3328 solver.cpp:261]     Train net output #0: loss = 0.113122 (* 1 = 0.113122 loss)
I1019 00:22:06.099261  3328 sgd_solver.cpp:106] Iteration 3325, lr = 0.00147028
I1019 00:22:31.241106  3328 solver.cpp:242] Iteration 3344 (0.755723 iter/s, 25.1415s/19 iter), loss = 0.116105
I1019 00:22:31.241564  3328 solver.cpp:261]     Train net output #0: loss = 0.1391 (* 1 = 0.1391 loss)
I1019 00:22:31.241583  3328 sgd_solver.cpp:106] Iteration 3344, lr = 0.00145011
I1019 00:22:56.331579  3328 solver.cpp:242] Iteration 3363 (0.757285 iter/s, 25.0896s/19 iter), loss = 0.113963
I1019 00:22:56.331666  3328 solver.cpp:261]     Train net output #0: loss = 0.0550308 (* 1 = 0.0550308 loss)
I1019 00:22:56.331692  3328 sgd_solver.cpp:106] Iteration 3363, lr = 0.00142994
I1019 00:23:21.783566  3328 solver.cpp:242] Iteration 3382 (0.746517 iter/s, 25.4515s/19 iter), loss = 0.131843
I1019 00:23:21.786242  3328 solver.cpp:261]     Train net output #0: loss = 0.0980753 (* 1 = 0.0980753 loss)
I1019 00:23:21.786267  3328 sgd_solver.cpp:106] Iteration 3382, lr = 0.00140977
I1019 00:23:46.959579  3328 solver.cpp:242] Iteration 3401 (0.754778 iter/s, 25.173s/19 iter), loss = 0.112188
I1019 00:23:46.959659  3328 solver.cpp:261]     Train net output #0: loss = 0.0687843 (* 1 = 0.0687843 loss)
I1019 00:23:46.959683  3328 sgd_solver.cpp:106] Iteration 3401, lr = 0.0013896
I1019 00:24:12.465478  3328 solver.cpp:242] Iteration 3420 (0.744939 iter/s, 25.5054s/19 iter), loss = 0.134894
I1019 00:24:12.465592  3328 solver.cpp:261]     Train net output #0: loss = 0.103017 (* 1 = 0.103017 loss)
I1019 00:24:12.465610  3328 sgd_solver.cpp:106] Iteration 3420, lr = 0.00136943
I1019 00:24:38.397696  3328 solver.cpp:242] Iteration 3439 (0.732694 iter/s, 25.9317s/19 iter), loss = 0.11803
I1019 00:24:38.397773  3328 solver.cpp:261]     Train net output #0: loss = 0.0939453 (* 1 = 0.0939453 loss)
I1019 00:24:38.397790  3328 sgd_solver.cpp:106] Iteration 3439, lr = 0.00134926
I1019 00:24:57.432166  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_3454.caffemodel
I1019 00:24:57.613162  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3454.solverstate
I1019 00:24:57.688570  3328 solver.cpp:362] Iteration 3454, Testing net (#0)
I1019 00:24:57.688607  3328 net.cpp:723] Ignoring source layer train-data
I1019 00:25:08.513438  3328 solver.cpp:429]     Test net output #0: accuracy = 0.90625
I1019 00:25:08.513489  3328 solver.cpp:429]     Test net output #1: loss = 0.242305 (* 1 = 0.242305 loss)
I1019 00:25:15.048136  3328 solver.cpp:242] Iteration 3458 (0.51842 iter/s, 36.6498s/19 iter), loss = 0.125084
I1019 00:25:15.048207  3328 solver.cpp:261]     Train net output #0: loss = 0.0882002 (* 1 = 0.0882002 loss)
I1019 00:25:15.048228  3328 sgd_solver.cpp:106] Iteration 3458, lr = 0.00132909
I1019 00:25:40.630295  3328 solver.cpp:242] Iteration 3477 (0.742719 iter/s, 25.5817s/19 iter), loss = 0.112119
I1019 00:25:40.630404  3328 solver.cpp:261]     Train net output #0: loss = 0.171793 (* 1 = 0.171793 loss)
I1019 00:25:40.630421  3328 sgd_solver.cpp:106] Iteration 3477, lr = 0.00130892
I1019 00:26:05.692139  3328 solver.cpp:242] Iteration 3496 (0.758139 iter/s, 25.0614s/19 iter), loss = 0.118487
I1019 00:26:05.692200  3328 solver.cpp:261]     Train net output #0: loss = 0.124453 (* 1 = 0.124453 loss)
I1019 00:26:05.692219  3328 sgd_solver.cpp:106] Iteration 3496, lr = 0.00128875
I1019 00:26:30.888695  3328 solver.cpp:242] Iteration 3515 (0.754085 iter/s, 25.1961s/19 iter), loss = 0.0768813
I1019 00:26:30.890671  3328 solver.cpp:261]     Train net output #0: loss = 0.0706032 (* 1 = 0.0706032 loss)
I1019 00:26:30.890693  3328 sgd_solver.cpp:106] Iteration 3515, lr = 0.00126858
I1019 00:26:56.213593  3328 solver.cpp:242] Iteration 3534 (0.75032 iter/s, 25.3225s/19 iter), loss = 0.122901
I1019 00:26:56.213654  3328 solver.cpp:261]     Train net output #0: loss = 0.115838 (* 1 = 0.115838 loss)
I1019 00:26:56.213672  3328 sgd_solver.cpp:106] Iteration 3534, lr = 0.00124841
I1019 00:27:21.119535  3328 solver.cpp:242] Iteration 3553 (0.762884 iter/s, 24.9055s/19 iter), loss = 0.115898
I1019 00:27:21.119732  3328 solver.cpp:261]     Train net output #0: loss = 0.102974 (* 1 = 0.102974 loss)
I1019 00:27:21.119751  3328 sgd_solver.cpp:106] Iteration 3553, lr = 0.00122824
I1019 00:27:28.147094  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1019 00:27:46.329020  3328 solver.cpp:242] Iteration 3572 (0.753702 iter/s, 25.2089s/19 iter), loss = 0.176737
I1019 00:27:46.329088  3328 solver.cpp:261]     Train net output #0: loss = 0.193656 (* 1 = 0.193656 loss)
I1019 00:27:46.329109  3328 sgd_solver.cpp:106] Iteration 3572, lr = 0.00120807
I1019 00:28:11.314421  3328 solver.cpp:242] Iteration 3591 (0.760458 iter/s, 24.985s/19 iter), loss = 0.100381
I1019 00:28:11.314533  3328 solver.cpp:261]     Train net output #0: loss = 0.0972941 (* 1 = 0.0972941 loss)
I1019 00:28:11.314553  3328 sgd_solver.cpp:106] Iteration 3591, lr = 0.0011879
I1019 00:28:36.050885  3328 solver.cpp:242] Iteration 3610 (0.768112 iter/s, 24.736s/19 iter), loss = 0.0793961
I1019 00:28:36.050946  3328 solver.cpp:261]     Train net output #0: loss = 0.0690792 (* 1 = 0.0690792 loss)
I1019 00:28:36.050964  3328 sgd_solver.cpp:106] Iteration 3610, lr = 0.00116773
I1019 00:28:36.067224  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_3611.caffemodel
I1019 00:28:36.420572  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3611.solverstate
I1019 00:28:36.506949  3328 solver.cpp:362] Iteration 3611, Testing net (#0)
I1019 00:28:36.506984  3328 net.cpp:723] Ignoring source layer train-data
I1019 00:28:47.833359  3328 solver.cpp:429]     Test net output #0: accuracy = 0.911914
I1019 00:28:47.833461  3328 solver.cpp:429]     Test net output #1: loss = 0.226709 (* 1 = 0.226709 loss)
I1019 00:29:13.064308  3328 solver.cpp:242] Iteration 3629 (0.513336 iter/s, 37.0128s/19 iter), loss = 0.0965029
I1019 00:29:13.064369  3328 solver.cpp:261]     Train net output #0: loss = 0.0919373 (* 1 = 0.0919373 loss)
I1019 00:29:13.064388  3328 sgd_solver.cpp:106] Iteration 3629, lr = 0.00114756
I1019 00:29:38.078362  3328 solver.cpp:242] Iteration 3648 (0.759587 iter/s, 25.0136s/19 iter), loss = 0.109533
I1019 00:29:38.078471  3328 solver.cpp:261]     Train net output #0: loss = 0.120871 (* 1 = 0.120871 loss)
I1019 00:29:38.078490  3328 sgd_solver.cpp:106] Iteration 3648, lr = 0.00112739
I1019 00:30:03.578593  3328 solver.cpp:242] Iteration 3667 (0.745106 iter/s, 25.4997s/19 iter), loss = 0.0803762
I1019 00:30:03.578652  3328 solver.cpp:261]     Train net output #0: loss = 0.0464181 (* 1 = 0.0464181 loss)
I1019 00:30:03.578672  3328 sgd_solver.cpp:106] Iteration 3667, lr = 0.00110722
I1019 00:30:28.427572  3328 solver.cpp:242] Iteration 3686 (0.764633 iter/s, 24.8485s/19 iter), loss = 0.136144
I1019 00:30:28.427676  3328 solver.cpp:261]     Train net output #0: loss = 0.169057 (* 1 = 0.169057 loss)
I1019 00:30:28.427695  3328 sgd_solver.cpp:106] Iteration 3686, lr = 0.00108705
I1019 00:30:53.373823  3328 solver.cpp:242] Iteration 3705 (0.761652 iter/s, 24.9458s/19 iter), loss = 0.0826758
I1019 00:30:53.373909  3328 solver.cpp:261]     Train net output #0: loss = 0.0752011 (* 1 = 0.0752011 loss)
I1019 00:30:53.373929  3328 sgd_solver.cpp:106] Iteration 3705, lr = 0.00106688
I1019 00:31:18.215564  3328 solver.cpp:242] Iteration 3724 (0.764855 iter/s, 24.8413s/19 iter), loss = 0.0944167
I1019 00:31:18.215678  3328 solver.cpp:261]     Train net output #0: loss = 0.0918907 (* 1 = 0.0918907 loss)
I1019 00:31:18.215698  3328 sgd_solver.cpp:106] Iteration 3724, lr = 0.00104671
I1019 00:31:43.139560  3328 solver.cpp:242] Iteration 3743 (0.762331 iter/s, 24.9235s/19 iter), loss = 0.126217
I1019 00:31:43.139623  3328 solver.cpp:261]     Train net output #0: loss = 0.055006 (* 1 = 0.055006 loss)
I1019 00:31:43.139642  3328 sgd_solver.cpp:106] Iteration 3743, lr = 0.00102654
I1019 00:32:08.251590  3328 solver.cpp:242] Iteration 3762 (0.756622 iter/s, 25.1116s/19 iter), loss = 0.103394
I1019 00:32:08.252663  3328 solver.cpp:261]     Train net output #0: loss = 0.11094 (* 1 = 0.11094 loss)
I1019 00:32:08.252692  3328 sgd_solver.cpp:106] Iteration 3762, lr = 0.00100637
I1019 00:32:14.993261  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_3768.caffemodel
I1019 00:32:15.145612  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3768.solverstate
I1019 00:32:15.244468  3328 solver.cpp:362] Iteration 3768, Testing net (#0)
I1019 00:32:15.244503  3328 net.cpp:723] Ignoring source layer train-data
I1019 00:32:26.141558  3328 solver.cpp:429]     Test net output #0: accuracy = 0.920313
I1019 00:32:26.141608  3328 solver.cpp:429]     Test net output #1: loss = 0.195544 (* 1 = 0.195544 loss)
I1019 00:32:44.387739  3328 solver.cpp:242] Iteration 3781 (0.525812 iter/s, 36.1346s/19 iter), loss = 0.10606
I1019 00:32:44.387858  3328 solver.cpp:261]     Train net output #0: loss = 0.0858245 (* 1 = 0.0858245 loss)
I1019 00:32:44.387879  3328 sgd_solver.cpp:106] Iteration 3781, lr = 0.0009862
I1019 00:32:58.363306  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1019 00:33:09.571555  3328 solver.cpp:242] Iteration 3800 (0.754467 iter/s, 25.1833s/19 iter), loss = 0.111749
I1019 00:33:09.571635  3328 solver.cpp:261]     Train net output #0: loss = 0.0994273 (* 1 = 0.0994273 loss)
I1019 00:33:09.571656  3328 sgd_solver.cpp:106] Iteration 3800, lr = 0.00096603
I1019 00:33:34.815577  3328 solver.cpp:242] Iteration 3819 (0.752667 iter/s, 25.2436s/19 iter), loss = 0.0959902
I1019 00:33:34.816092  3328 solver.cpp:261]     Train net output #0: loss = 0.156642 (* 1 = 0.156642 loss)
I1019 00:33:34.816112  3328 sgd_solver.cpp:106] Iteration 3819, lr = 0.00094586
I1019 00:33:59.720389  3328 solver.cpp:242] Iteration 3838 (0.762931 iter/s, 24.9039s/19 iter), loss = 0.101914
I1019 00:33:59.720451  3328 solver.cpp:261]     Train net output #0: loss = 0.115617 (* 1 = 0.115617 loss)
I1019 00:33:59.720469  3328 sgd_solver.cpp:106] Iteration 3838, lr = 0.00092569
I1019 00:34:25.296984  3328 solver.cpp:242] Iteration 3857 (0.742879 iter/s, 25.5762s/19 iter), loss = 0.0735346
I1019 00:34:25.299943  3328 solver.cpp:261]     Train net output #0: loss = 0.06621 (* 1 = 0.06621 loss)
I1019 00:34:25.299973  3328 sgd_solver.cpp:106] Iteration 3857, lr = 0.00090552
I1019 00:34:50.195421  3328 solver.cpp:242] Iteration 3876 (0.763201 iter/s, 24.8951s/19 iter), loss = 0.0963598
I1019 00:34:50.195485  3328 solver.cpp:261]     Train net output #0: loss = 0.120392 (* 1 = 0.120392 loss)
I1019 00:34:50.213517  3328 sgd_solver.cpp:106] Iteration 3876, lr = 0.00088535
I1019 00:35:15.073714  3328 solver.cpp:242] Iteration 3895 (0.76373 iter/s, 24.8779s/19 iter), loss = 0.0863048
I1019 00:35:15.075690  3328 solver.cpp:261]     Train net output #0: loss = 0.125816 (* 1 = 0.125816 loss)
I1019 00:35:15.075711  3328 sgd_solver.cpp:106] Iteration 3895, lr = 0.00086518
I1019 00:35:40.305089  3328 solver.cpp:242] Iteration 3914 (0.753099 iter/s, 25.2291s/19 iter), loss = 0.0979751
I1019 00:35:40.305152  3328 solver.cpp:261]     Train net output #0: loss = 0.0967241 (* 1 = 0.0967241 loss)
I1019 00:35:40.305171  3328 sgd_solver.cpp:106] Iteration 3914, lr = 0.000845011
I1019 00:35:53.511184  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_3925.caffemodel
I1019 00:35:53.779714  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3925.solverstate
I1019 00:35:53.863368  3328 solver.cpp:362] Iteration 3925, Testing net (#0)
I1019 00:35:53.863404  3328 net.cpp:723] Ignoring source layer train-data
I1019 00:36:04.714612  3328 solver.cpp:429]     Test net output #0: accuracy = 0.918555
I1019 00:36:04.714679  3328 solver.cpp:429]     Test net output #1: loss = 0.21269 (* 1 = 0.21269 loss)
I1019 00:36:16.589946  3328 solver.cpp:242] Iteration 3933 (0.523642 iter/s, 36.2843s/19 iter), loss = 0.0983369
I1019 00:36:16.590003  3328 solver.cpp:261]     Train net output #0: loss = 0.0684918 (* 1 = 0.0684918 loss)
I1019 00:36:16.590020  3328 sgd_solver.cpp:106] Iteration 3933, lr = 0.000824841
I1019 00:36:42.147569  3328 solver.cpp:242] Iteration 3952 (0.743429 iter/s, 25.5572s/19 iter), loss = 0.0892072
I1019 00:36:42.147774  3328 solver.cpp:261]     Train net output #0: loss = 0.0642629 (* 1 = 0.0642629 loss)
I1019 00:36:42.147794  3328 sgd_solver.cpp:106] Iteration 3952, lr = 0.000804671
I1019 00:37:06.957164  3328 solver.cpp:242] Iteration 3971 (0.765849 iter/s, 24.8091s/19 iter), loss = 0.0856531
I1019 00:37:06.957226  3328 solver.cpp:261]     Train net output #0: loss = 0.0485985 (* 1 = 0.0485985 loss)
I1019 00:37:06.957243  3328 sgd_solver.cpp:106] Iteration 3971, lr = 0.000784501
I1019 00:37:32.089797  3328 solver.cpp:242] Iteration 3990 (0.756001 iter/s, 25.1322s/19 iter), loss = 0.0978909
I1019 00:37:32.091984  3328 solver.cpp:261]     Train net output #0: loss = 0.121613 (* 1 = 0.121613 loss)
I1019 00:37:32.092007  3328 sgd_solver.cpp:106] Iteration 3990, lr = 0.000764331
I1019 00:37:57.475711  3328 solver.cpp:242] Iteration 4009 (0.748521 iter/s, 25.3834s/19 iter), loss = 0.115055
I1019 00:37:57.475786  3328 solver.cpp:261]     Train net output #0: loss = 0.0955868 (* 1 = 0.0955868 loss)
I1019 00:37:57.475806  3328 sgd_solver.cpp:106] Iteration 4009, lr = 0.000744161
I1019 00:38:23.359561  3328 solver.cpp:242] Iteration 4028 (0.73406 iter/s, 25.8834s/19 iter), loss = 0.106313
I1019 00:38:23.359670  3328 solver.cpp:261]     Train net output #0: loss = 0.060346 (* 1 = 0.060346 loss)
I1019 00:38:23.359689  3328 sgd_solver.cpp:106] Iteration 4028, lr = 0.000723991
I1019 00:38:30.057024  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1019 00:38:48.650161  3328 solver.cpp:242] Iteration 4047 (0.75128 iter/s, 25.2902s/19 iter), loss = 0.106526
I1019 00:38:48.650223  3328 solver.cpp:261]     Train net output #0: loss = 0.0925578 (* 1 = 0.0925578 loss)
I1019 00:38:48.650240  3328 sgd_solver.cpp:106] Iteration 4047, lr = 0.000703822
I1019 00:39:14.027577  3328 solver.cpp:242] Iteration 4066 (0.748709 iter/s, 25.377s/19 iter), loss = 0.0839497
I1019 00:39:14.027686  3328 solver.cpp:261]     Train net output #0: loss = 0.0719116 (* 1 = 0.0719116 loss)
I1019 00:39:14.027705  3328 sgd_solver.cpp:106] Iteration 4066, lr = 0.000683652
I1019 00:39:33.713392  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_4082.caffemodel
I1019 00:39:35.412880  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4082.solverstate
I1019 00:39:35.464792  3328 solver.cpp:362] Iteration 4082, Testing net (#0)
I1019 00:39:35.464828  3328 net.cpp:723] Ignoring source layer train-data
I1019 00:39:45.984308  3328 solver.cpp:429]     Test net output #0: accuracy = 0.917773
I1019 00:39:45.986626  3328 solver.cpp:429]     Test net output #1: loss = 0.220873 (* 1 = 0.220873 loss)
I1019 00:39:51.259562  3328 solver.cpp:242] Iteration 4085 (0.510322 iter/s, 37.2314s/19 iter), loss = 0.0813988
I1019 00:39:51.259621  3328 solver.cpp:261]     Train net output #0: loss = 0.0587384 (* 1 = 0.0587384 loss)
I1019 00:39:51.259640  3328 sgd_solver.cpp:106] Iteration 4085, lr = 0.000663482
I1019 00:40:16.689774  3328 solver.cpp:242] Iteration 4104 (0.747154 iter/s, 25.4298s/19 iter), loss = 0.0869689
I1019 00:40:16.689885  3328 solver.cpp:261]     Train net output #0: loss = 0.0657661 (* 1 = 0.0657661 loss)
I1019 00:40:16.689903  3328 sgd_solver.cpp:106] Iteration 4104, lr = 0.000643312
I1019 00:40:41.442353  3328 solver.cpp:242] Iteration 4123 (0.76761 iter/s, 24.7521s/19 iter), loss = 0.105526
I1019 00:40:41.442417  3328 solver.cpp:261]     Train net output #0: loss = 0.090799 (* 1 = 0.090799 loss)
I1019 00:40:41.442435  3328 sgd_solver.cpp:106] Iteration 4123, lr = 0.000623142
I1019 00:41:06.765388  3328 solver.cpp:242] Iteration 4142 (0.750317 iter/s, 25.3226s/19 iter), loss = 0.11834
I1019 00:41:06.768664  3328 solver.cpp:261]     Train net output #0: loss = 0.0613139 (* 1 = 0.0613139 loss)
I1019 00:41:06.768692  3328 sgd_solver.cpp:106] Iteration 4142, lr = 0.000602973
I1019 00:41:31.927585  3328 solver.cpp:242] Iteration 4161 (0.755209 iter/s, 25.1586s/19 iter), loss = 0.0866084
I1019 00:41:31.927644  3328 solver.cpp:261]     Train net output #0: loss = 0.0812737 (* 1 = 0.0812737 loss)
I1019 00:41:31.927661  3328 sgd_solver.cpp:106] Iteration 4161, lr = 0.000582803
I1019 00:41:56.884204  3328 solver.cpp:242] Iteration 4180 (0.761333 iter/s, 24.9562s/19 iter), loss = 0.0783809
I1019 00:41:56.886260  3328 solver.cpp:261]     Train net output #0: loss = 0.0929061 (* 1 = 0.0929061 loss)
I1019 00:41:56.886282  3328 sgd_solver.cpp:106] Iteration 4180, lr = 0.000562633
I1019 00:42:22.220345  3328 solver.cpp:242] Iteration 4199 (0.749987 iter/s, 25.3338s/19 iter), loss = 0.102288
I1019 00:42:22.220404  3328 solver.cpp:261]     Train net output #0: loss = 0.100333 (* 1 = 0.100333 loss)
I1019 00:42:22.220422  3328 sgd_solver.cpp:106] Iteration 4199, lr = 0.000542463
I1019 00:42:47.363091  3328 solver.cpp:242] Iteration 4218 (0.755697 iter/s, 25.1423s/19 iter), loss = 0.0726126
I1019 00:42:47.363214  3328 solver.cpp:261]     Train net output #0: loss = 0.0511749 (* 1 = 0.0511749 loss)
I1019 00:42:47.363234  3328 sgd_solver.cpp:106] Iteration 4218, lr = 0.000522293
I1019 00:43:12.537547  3328 solver.cpp:242] Iteration 4237 (0.754747 iter/s, 25.174s/19 iter), loss = 0.11405
I1019 00:43:12.537608  3328 solver.cpp:261]     Train net output #0: loss = 0.138926 (* 1 = 0.138926 loss)
I1019 00:43:12.537626  3328 sgd_solver.cpp:106] Iteration 4237, lr = 0.000502123
I1019 00:43:14.054180  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_4239.caffemodel
I1019 00:43:14.240283  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4239.solverstate
I1019 00:43:14.321295  3328 solver.cpp:362] Iteration 4239, Testing net (#0)
I1019 00:43:14.321336  3328 net.cpp:723] Ignoring source layer train-data
I1019 00:43:26.123095  3328 solver.cpp:429]     Test net output #0: accuracy = 0.931836
I1019 00:43:26.123204  3328 solver.cpp:429]     Test net output #1: loss = 0.180288 (* 1 = 0.180288 loss)
I1019 00:43:49.903563  3328 solver.cpp:242] Iteration 4256 (0.508491 iter/s, 37.3655s/19 iter), loss = 0.0972836
I1019 00:43:49.903621  3328 solver.cpp:261]     Train net output #0: loss = 0.0996616 (* 1 = 0.0996616 loss)
I1019 00:43:49.903640  3328 sgd_solver.cpp:106] Iteration 4256, lr = 0.000481953
I1019 00:44:03.537492  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1019 00:44:14.835464  3328 solver.cpp:242] Iteration 4275 (0.762088 iter/s, 24.9315s/19 iter), loss = 0.0769874
I1019 00:44:14.835544  3328 solver.cpp:261]     Train net output #0: loss = 0.0783669 (* 1 = 0.0783669 loss)
I1019 00:44:14.835564  3328 sgd_solver.cpp:106] Iteration 4275, lr = 0.000461783
I1019 00:44:40.188325  3328 solver.cpp:242] Iteration 4294 (0.749435 iter/s, 25.3524s/19 iter), loss = 0.0706422
I1019 00:44:40.188433  3328 solver.cpp:261]     Train net output #0: loss = 0.0752569 (* 1 = 0.0752569 loss)
I1019 00:44:40.188452  3328 sgd_solver.cpp:106] Iteration 4294, lr = 0.000441613
I1019 00:45:05.030858  3328 solver.cpp:242] Iteration 4313 (0.764831 iter/s, 24.8421s/19 iter), loss = 0.0670098
I1019 00:45:05.030939  3328 solver.cpp:261]     Train net output #0: loss = 0.0493889 (* 1 = 0.0493889 loss)
I1019 00:45:05.031023  3328 sgd_solver.cpp:106] Iteration 4313, lr = 0.000421444
I1019 00:45:29.967957  3328 solver.cpp:242] Iteration 4332 (0.76193 iter/s, 24.9367s/19 iter), loss = 0.0671224
I1019 00:45:29.968750  3328 solver.cpp:261]     Train net output #0: loss = 0.0801178 (* 1 = 0.0801178 loss)
I1019 00:45:29.968770  3328 sgd_solver.cpp:106] Iteration 4332, lr = 0.000401274
I1019 00:45:55.552414  3328 solver.cpp:242] Iteration 4351 (0.742671 iter/s, 25.5833s/19 iter), loss = 0.0691912
I1019 00:45:55.552474  3328 solver.cpp:261]     Train net output #0: loss = 0.0549423 (* 1 = 0.0549423 loss)
I1019 00:45:55.552491  3328 sgd_solver.cpp:106] Iteration 4351, lr = 0.000381104
I1019 00:46:20.418292  3328 solver.cpp:242] Iteration 4370 (0.764111 iter/s, 24.8655s/19 iter), loss = 0.0702406
I1019 00:46:20.418876  3328 solver.cpp:261]     Train net output #0: loss = 0.0768406 (* 1 = 0.0768406 loss)
I1019 00:46:20.418900  3328 sgd_solver.cpp:106] Iteration 4370, lr = 0.000360934
I1019 00:46:45.447571  3328 solver.cpp:242] Iteration 4389 (0.759139 iter/s, 25.0284s/19 iter), loss = 0.088856
I1019 00:46:45.447636  3328 solver.cpp:261]     Train net output #0: loss = 0.0836339 (* 1 = 0.0836339 loss)
I1019 00:46:45.447654  3328 sgd_solver.cpp:106] Iteration 4389, lr = 0.000340764
I1019 00:46:53.664233  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_4396.caffemodel
I1019 00:46:53.936890  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4396.solverstate
I1019 00:46:54.044234  3328 solver.cpp:362] Iteration 4396, Testing net (#0)
I1019 00:46:54.044270  3328 net.cpp:723] Ignoring source layer train-data
I1019 00:47:05.180157  3328 solver.cpp:429]     Test net output #0: accuracy = 0.93125
I1019 00:47:05.183588  3328 solver.cpp:429]     Test net output #1: loss = 0.188823 (* 1 = 0.188823 loss)
I1019 00:47:22.055196  3328 solver.cpp:242] Iteration 4408 (0.519025 iter/s, 36.6071s/19 iter), loss = 0.0870889
I1019 00:47:22.055251  3328 solver.cpp:261]     Train net output #0: loss = 0.102638 (* 1 = 0.102638 loss)
I1019 00:47:22.055269  3328 sgd_solver.cpp:106] Iteration 4408, lr = 0.000320595
I1019 00:47:47.243894  3328 solver.cpp:242] Iteration 4427 (0.754319 iter/s, 25.1883s/19 iter), loss = 0.0589722
I1019 00:47:47.248519  3328 solver.cpp:261]     Train net output #0: loss = 0.0547054 (* 1 = 0.0547054 loss)
I1019 00:47:47.248550  3328 sgd_solver.cpp:106] Iteration 4427, lr = 0.000300425
I1019 00:48:12.743562  3328 solver.cpp:242] Iteration 4446 (0.745253 iter/s, 25.4947s/19 iter), loss = 0.07775
I1019 00:48:12.743626  3328 solver.cpp:261]     Train net output #0: loss = 0.0422509 (* 1 = 0.0422509 loss)
I1019 00:48:12.743644  3328 sgd_solver.cpp:106] Iteration 4446, lr = 0.000280255
I1019 00:48:37.567559  3328 solver.cpp:242] Iteration 4465 (0.765401 iter/s, 24.8236s/19 iter), loss = 0.102033
I1019 00:48:37.567667  3328 solver.cpp:261]     Train net output #0: loss = 0.141872 (* 1 = 0.141872 loss)
I1019 00:48:37.567685  3328 sgd_solver.cpp:106] Iteration 4465, lr = 0.000260085
I1019 00:49:02.364548  3328 solver.cpp:242] Iteration 4484 (0.766236 iter/s, 24.7965s/19 iter), loss = 0.0764274
I1019 00:49:02.364609  3328 solver.cpp:261]     Train net output #0: loss = 0.0762741 (* 1 = 0.0762741 loss)
I1019 00:49:02.364627  3328 sgd_solver.cpp:106] Iteration 4484, lr = 0.000239915
I1019 00:49:27.828338  3328 solver.cpp:242] Iteration 4503 (0.74617 iter/s, 25.4634s/19 iter), loss = 0.092832
I1019 00:49:27.828452  3328 solver.cpp:261]     Train net output #0: loss = 0.133498 (* 1 = 0.133498 loss)
I1019 00:49:27.828470  3328 sgd_solver.cpp:106] Iteration 4503, lr = 0.000219745
I1019 00:49:34.494570  3328 blocking_queue.cpp:50] Data layer prefetch queue empty
I1019 00:49:52.745993  3328 solver.cpp:242] Iteration 4522 (0.762526 iter/s, 24.9172s/19 iter), loss = 0.0704546
I1019 00:49:52.746079  3328 solver.cpp:261]     Train net output #0: loss = 0.0721542 (* 1 = 0.0721542 loss)
I1019 00:49:52.746101  3328 sgd_solver.cpp:106] Iteration 4522, lr = 0.000199575
I1019 00:50:17.795559  3328 solver.cpp:242] Iteration 4541 (0.758509 iter/s, 25.0491s/19 iter), loss = 0.0781191
I1019 00:50:17.795706  3328 solver.cpp:261]     Train net output #0: loss = 0.0809653 (* 1 = 0.0809653 loss)
I1019 00:50:17.795724  3328 sgd_solver.cpp:106] Iteration 4541, lr = 0.000179406
I1019 00:50:32.653285  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_4553.caffemodel
I1019 00:50:32.887526  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4553.solverstate
I1019 00:50:33.001986  3328 solver.cpp:362] Iteration 4553, Testing net (#0)
I1019 00:50:33.002017  3328 net.cpp:723] Ignoring source layer train-data
I1019 00:50:43.943662  3328 solver.cpp:429]     Test net output #0: accuracy = 0.932227
I1019 00:50:43.943717  3328 solver.cpp:429]     Test net output #1: loss = 0.186166 (* 1 = 0.186166 loss)
I1019 00:50:54.431946  3328 solver.cpp:242] Iteration 4560 (0.518619 iter/s, 36.6357s/19 iter), loss = 0.0781461
I1019 00:50:54.435109  3328 solver.cpp:261]     Train net output #0: loss = 0.0621336 (* 1 = 0.0621336 loss)
I1019 00:50:54.435139  3328 sgd_solver.cpp:106] Iteration 4560, lr = 0.000159236
I1019 00:51:19.324254  3328 solver.cpp:242] Iteration 4579 (0.763396 iter/s, 24.8888s/19 iter), loss = 0.0664332
I1019 00:51:19.324328  3328 solver.cpp:261]     Train net output #0: loss = 0.0638747 (* 1 = 0.0638747 loss)
I1019 00:51:19.324349  3328 sgd_solver.cpp:106] Iteration 4579, lr = 0.000139066
I1019 00:51:44.682286  3328 solver.cpp:242] Iteration 4598 (0.749282 iter/s, 25.3576s/19 iter), loss = 0.0791937
I1019 00:51:44.682417  3328 solver.cpp:261]     Train net output #0: loss = 0.0865867 (* 1 = 0.0865867 loss)
I1019 00:51:44.682437  3328 sgd_solver.cpp:106] Iteration 4598, lr = 0.000118896
I1019 00:52:09.616984  3328 solver.cpp:242] Iteration 4617 (0.762005 iter/s, 24.9342s/19 iter), loss = 0.0799769
I1019 00:52:09.617048  3328 solver.cpp:261]     Train net output #0: loss = 0.0677613 (* 1 = 0.0677613 loss)
I1019 00:52:09.617068  3328 sgd_solver.cpp:106] Iteration 4617, lr = 9.87262e-05
I1019 00:52:35.137362  3328 solver.cpp:242] Iteration 4636 (0.744515 iter/s, 25.52s/19 iter), loss = 0.0844357
I1019 00:52:35.143555  3328 solver.cpp:261]     Train net output #0: loss = 0.111246 (* 1 = 0.111246 loss)
I1019 00:52:35.143591  3328 sgd_solver.cpp:106] Iteration 4636, lr = 7.85562e-05
I1019 00:53:00.360198  3328 solver.cpp:242] Iteration 4655 (0.753481 iter/s, 25.2163s/19 iter), loss = 0.079009
I1019 00:53:00.360265  3328 solver.cpp:261]     Train net output #0: loss = 0.0764725 (* 1 = 0.0764725 loss)
I1019 00:53:00.360283  3328 sgd_solver.cpp:106] Iteration 4655, lr = 5.83863e-05
I1019 00:53:25.108065  3328 solver.cpp:242] Iteration 4674 (0.767756 iter/s, 24.7475s/19 iter), loss = 0.0807657
I1019 00:53:25.108171  3328 solver.cpp:261]     Train net output #0: loss = 0.111165 (* 1 = 0.111165 loss)
I1019 00:53:25.108191  3328 sgd_solver.cpp:106] Iteration 4674, lr = 3.82164e-05
I1019 00:53:50.599563  3328 solver.cpp:242] Iteration 4693 (0.74536 iter/s, 25.491s/19 iter), loss = 0.0602717
I1019 00:53:50.599632  3328 solver.cpp:261]     Train net output #0: loss = 0.0725774 (* 1 = 0.0725774 loss)
I1019 00:53:50.599652  3328 sgd_solver.cpp:106] Iteration 4693, lr = 1.80468e-05
I1019 00:54:11.938199  3328 solver.cpp:479] Snapshotting to binary proto file snapshot_iter_4710.caffemodel
I1019 00:54:12.126571  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4710.solverstate
I1019 00:54:12.199301  3328 solver.cpp:362] Iteration 4710, Testing net (#0)
I1019 00:54:12.199347  3328 net.cpp:723] Ignoring source layer train-data
I1019 00:54:23.270478  3328 solver.cpp:429]     Test net output #0: accuracy = 0.931641
I1019 00:54:23.270550  3328 solver.cpp:429]     Test net output #1: loss = 0.189344 (* 1 = 0.189344 loss)
I1019 00:54:23.270560  3328 solver.cpp:347] Optimization Done.
I1019 00:54:23.270568  3328 caffe.cpp:234] Optimization Done.
